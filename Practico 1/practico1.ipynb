{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\4171189080.py:2: DtypeWarning: Columns (22,32,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('permisos_construccion.csv')\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset desde un archivo CSV\n",
    "df = pd.read_csv('permisos_construccion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Calcular y mostrar la cantidad de filas y columnas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas: 198910\n",
      "Cantidad de columnas: 43\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de filas y columnas\n",
    "filas, columnas = df.shape\n",
    "\n",
    "# Mostrar la cantidad de filas y columnas\n",
    "print(f'Cantidad de filas: {filas}')\n",
    "print(f'Cantidad de columnas: {columnas}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Observar y mostrar las primeras 5 filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Permit Number  Permit Type  Permit Type Definition Permit Creation Date  \\\n",
      "0       M788927            8  otc alterations permit           05/23/2017   \n",
      "1  201305318356            8  otc alterations permit           05/31/2013   \n",
      "2  201705106205            8  otc alterations permit           05/10/2017   \n",
      "3  201410279983            8  otc alterations permit           10/27/2014   \n",
      "4  201310280388            8  otc alterations permit           10/28/2013   \n",
      "\n",
      "  Block   Lot  Street Number Street Number Suffix Street Name Street Suffix  \\\n",
      "0  0215   001           1333                  NaN       jOnEs            St   \n",
      "1  1810  017A           1483                  NaN        43rD            Av   \n",
      "2  5700   027            431                  NaN    pReNtIsS            St   \n",
      "3  0661   005           2020                  NaN        bUsH            St   \n",
      "4  3642  051A            871                  NaN        cApP            St   \n",
      "\n",
      "   ...  Existing Construction Type Existing Construction Type Description  \\\n",
      "0  ...                         NaN                                    NaN   \n",
      "1  ...                         5.0                         wood frame (5)   \n",
      "2  ...                         5.0                         wood frame (5)   \n",
      "3  ...                         5.0                         wood frame (5)   \n",
      "4  ...                         5.0                         wood frame (5)   \n",
      "\n",
      "  Proposed Construction Type Proposed Construction Type Description  \\\n",
      "0                        NaN                                    NaN   \n",
      "1                        5.0                         wood frame (5)   \n",
      "2                        5.0                         wood frame (5)   \n",
      "3                        5.0                         wood frame (5)   \n",
      "4                        5.0                         wood frame (5)   \n",
      "\n",
      "  Site Permit Supervisor District Neighborhoods - Analysis Boundaries  \\\n",
      "0         NaN                 3.0                            Nob Hill   \n",
      "1         NaN                 4.0                     Sunset/Parkside   \n",
      "2         NaN                 9.0                      Bernal Heights   \n",
      "3         NaN                 5.0                     Pacific Heights   \n",
      "4         NaN                 9.0                             Mission   \n",
      "\n",
      "   Zipcode                                   Location      Record ID  \n",
      "0  94109.0   (37.79362102799777, -122.41488237355445)  1464153232862  \n",
      "1  94122.0  (37.759041020475465, -122.50286985467523)  1306559115258  \n",
      "2  94110.0   (37.73778863007536, -122.41197863877355)  1462579187173  \n",
      "3  94115.0   (37.78762264983362, -122.43099126735969)   136037778128  \n",
      "4  94110.0   (37.75275550565926, -122.41707462095194)  1322242163712  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras 5 filas del DataFrame\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Evaluar la existencia de datos faltantes y duplicados. Cuantificarlos y calcular el porcentaje sobre el total de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos faltantes por columna:\n",
      "Permit Number                                  0\n",
      "Permit Type                                    0\n",
      "Permit Type Definition                         0\n",
      "Permit Creation Date                           0\n",
      "Block                                          0\n",
      "Lot                                            0\n",
      "Street Number                                  0\n",
      "Street Number Suffix                      196694\n",
      "Street Name                                    0\n",
      "Street Suffix                               2768\n",
      "Unit                                      169430\n",
      "Unit Suffix                               196949\n",
      "Description                                  290\n",
      "Current Status                                 0\n",
      "Current Status Date                            0\n",
      "Filed Date                                     0\n",
      "Issued Date                                14942\n",
      "Completed Date                            101715\n",
      "First Construction Document Date           14948\n",
      "Structural Notification                   191988\n",
      "Number of Existing Stories                 42788\n",
      "Number of Proposed Stories                 42871\n",
      "Voluntary Soft-Story Retrofit             198875\n",
      "Fire Only Permit                          180082\n",
      "Permit Expiration Date                     51884\n",
      "Estimated Cost                             38068\n",
      "Revised Cost                                6066\n",
      "Existing Use                               41117\n",
      "Existing Units                             51543\n",
      "Proposed Use                               42441\n",
      "Proposed Units                             50915\n",
      "Plansets                                   37311\n",
      "TIDF Compliance                           198908\n",
      "Existing Construction Type                 43369\n",
      "Existing Construction Type Description     43370\n",
      "Proposed Construction Type                 43165\n",
      "Proposed Construction Type Description     43165\n",
      "Site Permit                               193550\n",
      "Supervisor District                         1719\n",
      "Neighborhoods - Analysis Boundaries         1725\n",
      "Zipcode                                     1716\n",
      "Location                                    1700\n",
      "Record ID                                      0\n",
      "dtype: int64\n",
      "\n",
      "Porcentaje de datos faltantes por columna (%):\n",
      "Permit Number                              0.000000\n",
      "Permit Type                                0.000000\n",
      "Permit Type Definition                     0.000000\n",
      "Permit Creation Date                       0.000000\n",
      "Block                                      0.000000\n",
      "Lot                                        0.000000\n",
      "Street Number                              0.000000\n",
      "Street Number Suffix                      98.885928\n",
      "Street Name                                0.000000\n",
      "Street Suffix                              1.391584\n",
      "Unit                                      85.179227\n",
      "Unit Suffix                               99.014127\n",
      "Description                                0.145795\n",
      "Current Status                             0.000000\n",
      "Current Status Date                        0.000000\n",
      "Filed Date                                 0.000000\n",
      "Issued Date                                7.511940\n",
      "Completed Date                            51.136192\n",
      "First Construction Document Date           7.514957\n",
      "Structural Notification                   96.520034\n",
      "Number of Existing Stories                21.511236\n",
      "Number of Proposed Stories                21.552964\n",
      "Voluntary Soft-Story Retrofit             99.982404\n",
      "Fire Only Permit                          90.534413\n",
      "Permit Expiration Date                    26.084159\n",
      "Estimated Cost                            19.138304\n",
      "Revised Cost                               3.049620\n",
      "Existing Use                              20.671158\n",
      "Existing Units                            25.912724\n",
      "Proposed Use                              21.336785\n",
      "Proposed Units                            25.597004\n",
      "Plansets                                  18.757730\n",
      "TIDF Compliance                           99.998995\n",
      "Existing Construction Type                21.803328\n",
      "Existing Construction Type Description    21.803831\n",
      "Proposed Construction Type                21.700769\n",
      "Proposed Construction Type Description    21.700769\n",
      "Site Permit                               97.305314\n",
      "Supervisor District                        0.864210\n",
      "Neighborhoods - Analysis Boundaries        0.867226\n",
      "Zipcode                                    0.862702\n",
      "Location                                   0.854658\n",
      "Record ID                                  0.000000\n",
      "dtype: float64\n",
      "\n",
      "Cantidad de filas duplicadas: 0\n",
      "\n",
      "Porcentaje de filas duplicadas: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluar datos faltantes\n",
    "datos_faltantes = df.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de datos faltantes sobre el total de filas\n",
    "porcentaje_faltantes = (datos_faltantes / len(df)) * 100\n",
    "\n",
    "# Mostrar datos faltantes y sus porcentajes\n",
    "print('Datos faltantes por columna:')\n",
    "print(datos_faltantes)\n",
    "print('\\nPorcentaje de datos faltantes por columna (%):')\n",
    "print(porcentaje_faltantes)\n",
    "\n",
    "# Evaluar datos duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "\n",
    "# Mostrar la cantidad de filas duplicadas\n",
    "print(f'\\nCantidad de filas duplicadas: {duplicados}')\n",
    "\n",
    "# Calcular el porcentaje de filas duplicadas sobre el total de filas\n",
    "porcentaje_duplicados = (duplicados / len(df)) * 100\n",
    "\n",
    "# Mostrar el porcentaje de filas duplicadas\n",
    "print(f'\\nPorcentaje de filas duplicadas: {porcentaje_duplicados} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Para los datos faltantes, evaluar posibles motivos de esto en cada caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos en la columna Street Number Suffix:\n",
      "[nan 'B' 'A' 'V' 'D' 'K' 'C' 'F' 'H' 'E' 'L' 'J' 'R' 'P' 'I' 'N' 'G' '½'\n",
      " '0']\n",
      "Valores faltantes en la columna 196694 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Street Suffix:\n",
      "['St' 'Av' 'Bl' nan 'Wy' 'Dr' 'Hy' 'Tr' 'Rd' 'Ct' 'Pl' 'Pk' 'Ln' 'Cr' 'Pz'\n",
      " 'Al' 'No' 'Rw' 'Wk' 'So' 'Hl' 'Sw']\n",
      "Valores faltantes en la columna 2768 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Unit:\n",
      "[      nan 0.000e+00 5.010e+02 3.000e+00 7.000e+00 2.000e+00 2.160e+02\n",
      " 2.030e+02 2.020e+02 6.000e+00 1.000e+00 1.100e+01 1.300e+01 3.700e+01\n",
      " 5.050e+02 3.210e+02 1.060e+02 4.000e+00 2.370e+02 1.170e+02 3.100e+01\n",
      " 4.230e+02 3.010e+02 1.050e+02 5.100e+01 2.010e+02 1.040e+02 9.180e+02\n",
      " 1.010e+02 1.401e+03 5.000e+00 3.050e+02 7.010e+02 8.010e+02 1.370e+03\n",
      " 7.050e+02 4.070e+02 1.005e+03 3.600e+02 8.300e+02 8.020e+02 2.040e+02\n",
      " 1.632e+03 1.004e+03 2.360e+02 1.020e+02 4.010e+02 5.070e+02 6.180e+02\n",
      " 1.704e+03 1.602e+03 3.020e+02 6.080e+02 4.100e+02 2.130e+02 4.060e+02\n",
      " 2.200e+01 3.830e+02 9.010e+02 6.170e+02 4.090e+02 3.040e+02 4.020e+02\n",
      " 1.700e+03 1.600e+01 3.270e+02 8.000e+00 1.000e+01 1.150e+03 2.090e+02\n",
      " 3.080e+02 1.116e+03 4.180e+02 2.230e+02 1.030e+02 1.007e+03 7.080e+02\n",
      " 1.233e+03 1.404e+03 2.700e+01 9.000e+00 2.501e+03 4.400e+01 6.070e+02\n",
      " 6.400e+02 5.903e+03 8.160e+02 1.408e+03 4.120e+02 1.700e+01 3.170e+02\n",
      " 3.110e+02 3.101e+03 3.030e+02 2.150e+02 1.800e+01 6.020e+02 1.900e+01\n",
      " 6.010e+02 2.500e+02 3.090e+02 3.500e+01 6.040e+02 1.200e+01 2.100e+01\n",
      " 1.402e+03 4.040e+02 6.030e+02 2.060e+02 8.080e+02 3.400e+01 4.080e+02\n",
      " 9.060e+02 4.150e+02 1.400e+01 3.190e+02 1.201e+03 2.300e+01 1.105e+03\n",
      " 3.260e+02 4.300e+01 3.070e+02 1.703e+03 3.600e+01 2.080e+02 7.030e+02\n",
      " 1.110e+02 1.160e+02 2.900e+03 3.300e+01 2.500e+01 5.480e+02 2.270e+02\n",
      " 4.140e+02 2.203e+03 3.390e+02 1.150e+02 8.170e+02 2.240e+02 2.050e+02\n",
      " 2.800e+01 1.372e+03 2.872e+03 7.600e+01 2.180e+02 2.900e+01 5.020e+02\n",
      " 1.305e+03 4.050e+02 1.202e+03 4.700e+01 7.070e+02 1.080e+02 3.150e+02\n",
      " 1.101e+03 4.006e+03 1.370e+02 3.000e+01 1.407e+03 5.040e+02 4.360e+02\n",
      " 1.015e+03 6.100e+01 5.570e+02 4.030e+02 1.100e+02 6.120e+02 1.207e+03\n",
      " 5.340e+02 1.260e+02 1.608e+03 6.520e+02 4.100e+01 3.160e+02 8.040e+02\n",
      " 2.402e+03 1.120e+02 1.415e+03 1.102e+03 5.300e+01 8.070e+02 1.135e+03\n",
      " 6.230e+02 1.302e+03 1.152e+03 3.290e+02 3.312e+03 3.320e+02 5.700e+02\n",
      " 1.501e+03 5.220e+02 4.901e+03 7.000e+01 1.070e+02 9.040e+02 1.103e+03\n",
      " 3.060e+02 3.200e+01 2.000e+02 1.301e+03 3.800e+01 5.030e+02 5.900e+01\n",
      " 1.208e+03 2.210e+02 2.034e+03 3.230e+02 2.604e+03 1.290e+02 9.050e+02\n",
      " 2.070e+02 4.800e+01 5.213e+03 1.050e+03 4.900e+01 4.690e+02 1.500e+01\n",
      " 4.310e+03 3.680e+02 2.502e+03 5.440e+02 5.120e+02 7.170e+02 2.301e+03\n",
      " 4.110e+02 2.000e+01 2.260e+02 8.420e+02 1.106e+03 1.432e+03 1.601e+03\n",
      " 2.110e+02 2.400e+01 3.000e+02 4.260e+02 3.140e+02 9.090e+02 8.460e+02\n",
      " 3.100e+02 2.100e+02 1.702e+03 5.090e+02 5.580e+02 3.705e+03 4.190e+02\n",
      " 1.792e+03 5.080e+02 1.902e+03 3.202e+03 5.150e+02 3.120e+02 8.240e+02\n",
      " 7.020e+02 1.312e+03 2.190e+02 4.620e+02 7.040e+02 5.204e+03 6.060e+02\n",
      " 2.192e+03 1.604e+03 7.900e+01 3.446e+03 1.140e+03 6.220e+02 3.220e+02\n",
      " 8.090e+02 7.100e+02 4.200e+01 6.510e+02 1.180e+02 1.059e+03 1.090e+02\n",
      " 6.300e+02 2.280e+02 3.200e+02 6.160e+02 9.310e+02 2.650e+03 4.520e+02\n",
      " 1.211e+03 1.690e+02 1.441e+03 1.901e+03 1.115e+03 1.214e+03 4.500e+01\n",
      " 1.250e+02 1.204e+03 5.520e+02 5.602e+03 1.108e+03 1.114e+03 1.420e+02\n",
      " 7.150e+02 3.640e+02 1.006e+03 8.060e+02 4.320e+02 6.340e+02 4.510e+02\n",
      " 8.100e+02 2.610e+02 9.900e+01 9.140e+02 2.202e+03 5.590e+02 9.520e+02\n",
      " 5.550e+02 6.560e+02 1.110e+03 9.030e+02 1.130e+02 1.240e+02 4.706e+03\n",
      " 4.130e+02 2.300e+03 9.020e+02 9.100e+02 8.220e+02 2.600e+01 2.601e+03\n",
      " 1.610e+03 1.505e+03 9.470e+02 2.401e+03 2.570e+02 1.001e+03 1.796e+03\n",
      " 7.090e+02 1.024e+03 6.140e+02 6.050e+02 4.720e+02 1.203e+03 1.511e+03\n",
      " 2.201e+03 2.005e+03 7.250e+02 2.003e+03 1.032e+03 5.060e+02 5.306e+03\n",
      " 5.100e+02 1.003e+03 2.888e+03 8.050e+02 3.540e+02 3.350e+02 1.009e+03\n",
      " 1.107e+03 7.060e+02 2.404e+03 5.700e+01 4.600e+01 1.516e+03 1.210e+03\n",
      " 3.180e+02 4.540e+02 1.431e+03 2.140e+03 3.900e+01 6.800e+01 1.717e+03\n",
      " 1.403e+03 1.140e+02 7.260e+02 6.150e+02 5.000e+01 1.503e+03 2.390e+02\n",
      " 3.903e+03 1.418e+03 1.412e+03 3.130e+02 2.204e+03 5.170e+02 2.214e+03\n",
      " 1.607e+03 4.000e+01 2.101e+03 7.210e+02 2.773e+03 8.230e+02 1.904e+03\n",
      " 1.805e+03 8.570e+02 7.130e+02 1.000e+02 4.409e+03 1.104e+03 5.230e+02\n",
      " 5.180e+02 4.570e+02 3.300e+02 5.005e+03 1.002e+03 1.109e+03 1.200e+02\n",
      " 2.001e+03 6.000e+02 2.725e+03 4.200e+02 1.530e+02 1.519e+03 7.500e+01\n",
      " 6.290e+02 5.412e+03 1.220e+02 1.606e+03 1.800e+03 1.025e+03 1.603e+03\n",
      " 1.409e+03 6.100e+02 2.470e+02 5.190e+02 1.303e+03 4.000e+02 1.249e+03\n",
      " 1.701e+03 1.517e+03 2.904e+03 1.014e+03 5.350e+02 9.000e+02 7.110e+02\n",
      " 2.002e+03 1.309e+03 4.160e+02 7.000e+02 9.650e+02 4.310e+02 9.120e+02\n",
      " 3.330e+02 5.600e+01 2.166e+03 6.003e+03 8.400e+02 1.380e+02 1.406e+03\n",
      " 3.250e+02 8.030e+02 1.221e+03 1.502e+03 5.113e+03 2.704e+03 7.520e+02\n",
      " 6.130e+02 4.280e+02 2.109e+03 9.570e+02 4.600e+02 8.520e+02 7.140e+02\n",
      " 2.350e+02 1.514e+03 1.450e+03 3.510e+02 4.340e+02 4.220e+02 8.700e+01\n",
      " 2.290e+02 6.200e+01 7.200e+01 5.110e+02 2.223e+03 3.560e+02 9.210e+02\n",
      " 1.570e+02 8.400e+01 6.490e+02 2.410e+02 1.124e+03 5.130e+02 9.070e+02\n",
      " 3.460e+02 8.100e+01 6.090e+02 1.618e+03 9.420e+02 3.004e+03 5.370e+02\n",
      " 3.240e+02 2.534e+03 6.250e+02 4.210e+03 5.313e+03 1.230e+03 2.140e+02\n",
      " 1.016e+03 3.103e+03 5.000e+02 3.105e+03 1.047e+03 6.110e+02 3.510e+03\n",
      " 1.304e+03 3.256e+03 5.330e+02 6.210e+02 5.500e+01 1.167e+03 6.470e+02\n",
      " 1.504e+03 1.022e+03 1.449e+03 5.206e+03 5.103e+03 4.309e+03 9.220e+02\n",
      " 6.190e+02 2.031e+03 5.160e+02 4.109e+03 2.530e+02 1.605e+03 1.613e+03\n",
      " 1.500e+03 6.000e+01 2.200e+02 2.303e+03 2.317e+03 4.001e+03 2.220e+02\n",
      " 7.690e+02 2.102e+03 2.801e+03 1.308e+03 2.120e+02 6.360e+02 2.803e+03\n",
      " 1.500e+02 4.300e+02 9.080e+02 3.412e+03 4.460e+02 1.424e+03 1.132e+03\n",
      " 5.604e+03 3.370e+02 3.005e+03 1.543e+03 3.704e+03 2.905e+03 1.043e+03\n",
      " 2.221e+03 4.480e+02 2.400e+03 7.360e+02 7.400e+01 4.410e+03 7.200e+02\n",
      " 1.131e+03 1.000e+03 1.480e+02 2.340e+02 1.411e+03 8.750e+02 7.240e+02\n",
      " 8.120e+02 5.530e+02 3.450e+02 1.801e+03 3.280e+02 1.414e+03 7.320e+02\n",
      " 5.112e+03 4.500e+02 2.805e+03 4.240e+02 1.251e+03 9.000e+01 3.440e+02\n",
      " 8.180e+02 9.200e+02 5.560e+02 6.570e+02 5.270e+02 8.320e+02 1.520e+02\n",
      " 3.401e+03 1.580e+02 6.500e+02 1.026e+03 1.112e+03 1.230e+02 2.070e+03\n",
      " 4.410e+02 9.160e+02 3.801e+03 1.212e+03 7.120e+02 2.103e+03 3.360e+02\n",
      " 9.320e+02 7.160e+02 5.400e+01 1.011e+03 4.660e+02 5.413e+03 4.110e+03\n",
      " 6.004e+03 2.526e+03 9.300e+02 3.580e+02 5.140e+02 3.861e+03 1.802e+03\n",
      " 2.170e+02 1.806e+03 9.110e+02 5.312e+03 1.510e+03 1.540e+02 1.508e+03\n",
      " 1.790e+03 8.590e+02 4.730e+02 6.260e+02 1.253e+03 1.270e+02 1.307e+03\n",
      " 7.800e+01 7.570e+02 3.254e+03 4.113e+03 5.200e+02 2.207e+03 1.206e+03\n",
      " 1.300e+02 6.310e+02 5.310e+02 1.317e+03 4.380e+02 7.230e+02 1.410e+02\n",
      " 1.360e+02 5.212e+03 2.800e+02 6.900e+01 4.170e+02 1.310e+03 9.390e+02\n",
      " 1.506e+03 8.000e+02 2.700e+03 2.250e+02 5.106e+03 1.120e+03 3.201e+03\n",
      " 1.808e+03 6.700e+01 8.720e+02 4.209e+03 5.210e+02 4.270e+02 4.004e+03\n",
      " 1.609e+03 1.190e+02 7.370e+02]\n",
      "Valores faltantes en la columna 169430 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Unit Suffix:\n",
      "[nan 'C' \"RESID'L\" 'D' 'E' 'WEST' 'F' 'HOA' 'A' 'UPPER UNIT' 'B' 'H'\n",
      " 'EAST' 'GPHA' '1/F' 'FRONT' 'Garage' 'UPPER' 'LOWER UNIT' 'O' 'N'\n",
      " 'RESDL/REAR' 'CHILD DEV' 'RESIDENTIA' 'REAR UNIT' 'COMMERCIAL' 'BLDG 157'\n",
      " 'RETAIL 1' 'W' 'M301' 'C132' 'J' 'M' 'COMML' 'BLDG 3E' 'OFFICE' '-A'\n",
      " 'COML' 'FRONT BLDG' 'REAR' 'C-2001' 'M202' 'BLDG 1' 'C101' 'LOWER COML'\n",
      " 'FRNT BLDG' 'PH-1' 'P' 'Y' 'LEVEL ONE' '1ST FLOOR' 'TH1' 'C103' 'C1'\n",
      " 'LOWER' 'FRONT UNIT' 'R-1' 'K' 'G' 'C102' 'COMML-3' 'TH2' 'C-1' 'A102'\n",
      " 'S' 'T' 'Commercial' 'COMMON ARE' 'BLDG 229' 'UPPR COMML' 'CU-3' 'I'\n",
      " '1/F FRONT' 'STORE' 'REAR BLDG' 'R' 'BLDG 449' 'OFFICE 2/F' 'B-A'\n",
      " 'COMML 1' 'PH-4' 'M1' 'COM-1' 'BLD 7' '1503B' '-B' 'Parcel B'\n",
      " 'FRNT RIGHT' 'STUDIO/TEC' 'TENTATIVE' 'RESIDENCE' 'PH1A' 'COMML-2' '0'\n",
      " 'BLDG C' 'BLDG 3F' 'M101' 'C-2' \"COM'L\" '1/2' 'C-4' 'D4' 'U' 'RESIDL 3/F'\n",
      " 'LEASE OFF' 'Parcel C' 'L' 'C100' 'PH2B' 'LEAS OFFIC' 'REAR G/F' '407'\n",
      " 'BLDG 201' 'U-PH3' 'BLDG 3' '3/F' 'PH' 'UTILITY' '3RD FLOOR' 'FRNT ENTRA'\n",
      " 'PH C' '3/F FRONT' 'BSM OFFICE' '2/F' 'MIDDLE' 'BLDG. 3' '1A-4' 'COMML-1'\n",
      " 'BASEMENT' 'PH1E' 'BLDG A' 'HMETER' 'PARKING' 'TOP' 'PARCEL A' 'BLDG E'\n",
      " 'UPPER LEVE' 'W122' 'THEATRE' 'CU-2' 'D3' 'COM-2' 'A104' 'BLDG 2'\n",
      " 'BLDG D' 'PH1C' 'FC1' 'CML A' \"RES'L\" 'B20H' 'PIER 3' 'PIER 2' '#R-2'\n",
      " 'BLDG B' 'UP FRT BLD' 'Parcel D' 'Parcel A' \"COM'L 1/F\" 'RETAIL 2'\n",
      " 'LEVEL 4' 'PH1' 'A100' '2ND FLOOR' \"COMM'\" 'PIER 1']\n",
      "Valores faltantes en la columna 196949 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Description:\n",
      "['street space'\n",
      " 'remodel kitchen: replace countertop, cabinets, sink, stove, hardwood floor & lighting.'\n",
      " 'replacement of 4 windows; 2 located in lightwell and 2 at front. replaceing existing vinyl windows with new wood-clad windows. no horizontal mullion in living room window'\n",
      " ...\n",
      " 'replace rotten wooden moldings in kind front stairs less than 50% replace'\n",
      " 'revision to pa 2016-0926-8773; remove (e) storefront & doors, remove floor, ceiling & wall finishes for new. new storefront, (n) wall & ceiling finishes, (n) flooring with waterproofing in a (n) alcove. mep under pa#201503100377'\n",
      " '16th floor - (4) evacuation plans.']\n",
      "Valores faltantes en la columna 290 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Issued Date:\n",
      "['05/23/2017' '06/03/2013' '05/11/2017' ... '05/24/2016' '06/05/2015'\n",
      " '12/12/2015']\n",
      "Valores faltantes en la columna 14942 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Completed Date:\n",
      "[nan '08/28/2013' '12/31/2014' ... '01/04/2013' '03/23/2013' '11/02/2014']\n",
      "Valores faltantes en la columna 101715 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna First Construction Document Date:\n",
      "['05/23/2017' '06/03/2013' '05/11/2017' ... '02/04/2016' '05/24/2016'\n",
      " '06/05/2015']\n",
      "Valores faltantes en la columna 14948 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Structural Notification:\n",
      "[nan 'Y']\n",
      "Valores faltantes en la columna 191988 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Number of Existing Stories:\n",
      "[ nan  2.   3.   1.   4.  40.   5.   9.  18.   6.  30.  24.  23.  12.\n",
      " 29.  38.  42.  20.  25.   8.   7.  11.  52.  10.  43.  16.  14.  48.\n",
      "  0.  21.  33.  22.  27.  37.  13.  32.  31.  15.  39.  58.  19.  17.\n",
      " 26.  63.  34.  36.  35.  28.  50.  41.  44.  45.  53.  47.  49.  60.\n",
      " 46.  61.  55.  62.  54.   1.5 56.  78.   2.5]\n",
      "Valores faltantes en la columna 42788 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Number of Proposed Stories:\n",
      "[ nan  2.   3.   1.   4.   5.  40.   9.  18.   6.  30.  24.  23.  12.\n",
      " 29.  38.  42.  20.  25.   8.   7.  11.  52.  10.  43.  16.  14.  48.\n",
      " 21.  33.  63.  22.  27.  19.  37.  13.  32.  31.  15.  39.  58.  17.\n",
      " 26.  34.  36.  35.  28.  50.   0.  41.  44.  45.  53.  46.  47.  55.\n",
      " 60.  49.  56.  61.  62.  54.   1.5 78.   2.5]\n",
      "Valores faltantes en la columna 42871 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Voluntary Soft-Story Retrofit:\n",
      "[nan 'Y']\n",
      "Valores faltantes en la columna 198875 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Fire Only Permit:\n",
      "[nan 'Y']\n",
      "Valores faltantes en la columna 180082 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Permit Expiration Date:\n",
      "[nan '05/29/2014' '05/06/2018' ... '11/22/2022' '09/12/2022' '01/06/2020']\n",
      "Valores faltantes en la columna 51884 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Estimated Cost:\n",
      "[    nan  12000.   1000. ...   9131.  15602. 648405.]\n",
      "Valores faltantes en la columna 38068 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Revised Cost:\n",
      "[1.000000e+00 1.200000e+04 2.000000e+03 ... 1.560200e+04 6.484050e+05\n",
      " 9.280092e+05]\n",
      "Valores faltantes en la columna 6066 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Existing Use:\n",
      "[nan '1 family dwelling' '2 family dwelling' 'apartments' 'office'\n",
      " 'retail sales' 'nursing home non amb' 'workshop commercial'\n",
      " 'food/beverage hndlng' 'artist live/work' 'theater' 'school'\n",
      " 'tourist hotel/motel' 'filling/service stn' 'prkng garage/private'\n",
      " 'residential hotel' 'auto repairs' 'lending institution' 'vacant lot'\n",
      " 'church' 'storage shed' 'mortuary' 'clinics-medic/dental' 'manufacturing'\n",
      " 'animal sale or care' 'warehouse,no frnitur' 'misc group residns.'\n",
      " 'health studios & gym' 'sfpd or sffd station' 'parking lot'\n",
      " 'christmas tree lot' 'warehouse, furniture' 'dry cleaners' 'club'\n",
      " 'wholesale sales' 'recreation bldg' 'nite club' 'power plant'\n",
      " 'prkng garage/public' 'garment shops' 'massage parlor'\n",
      " 'day care home gt 12' 'barber/beauty salon' 'ambulance service' 'antenna'\n",
      " 'social care facility' 'public assmbly other' 'hospital'\n",
      " 'nursing home gt 6' 'museum' 'automobile sales' 'sound studio'\n",
      " 'laundry/laundromat' 'printing plant' 'day care center'\n",
      " 'radio & tv stations' 'library' 'nursery(floral)' 'moving & storage'\n",
      " 'greenhouse' 'stadium' 'sewage plant' 'amusement center' 'child care'\n",
      " 'dance hall' 'adult entertainment' 'muni carbarn' 'day care, non-res'\n",
      " 'phone xchnge/equip' 'jail' 'convalescent home' 'sign' 'storage tanks'\n",
      " 'tower' 'fence/retaining wall' 'day care home 7 - 12'\n",
      " 'nursing home lte 6' 'swimming pool' 'car wash' 'chemical processing'\n",
      " 'paint store' 'building materials' 'day care home lt 7'\n",
      " 'dairies/dairy equip.' \"prson'l svc tutor\" 'accessory cottage'\n",
      " 'muni driver restroom' 'meat/produce marts' 'temple'\n",
      " 'workshop residential' 'bath house' 'orphanage' 'r-3(dwg) nursing'\n",
      " 'roofing materials']\n",
      "Valores faltantes en la columna 41117 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Existing Units:\n",
      "[      nan 1.000e+00 2.000e+00 4.000e+00 3.000e+00 0.000e+00 2.900e+01\n",
      " 8.000e+00 6.000e+00 3.100e+01 5.300e+01 1.500e+01 2.580e+02 5.100e+01\n",
      " 9.200e+01 4.480e+02 5.000e+00 7.000e+00 1.860e+02 5.290e+02 3.600e+01\n",
      " 1.100e+01 1.300e+01 2.400e+01 1.200e+01 1.150e+02 7.200e+01 7.400e+01\n",
      " 1.610e+02 2.200e+01 3.700e+01 1.700e+02 6.000e+01 4.900e+01 8.200e+01\n",
      " 1.400e+01 6.500e+01 4.040e+02 1.800e+01 1.900e+01 1.910e+02 1.350e+02\n",
      " 1.560e+02 1.600e+01 8.800e+01 9.000e+00 2.800e+01 4.090e+02 1.000e+01\n",
      " 4.000e+01 1.980e+02 2.540e+02 7.600e+01 2.970e+02 5.800e+01 2.000e+01\n",
      " 1.390e+02 1.130e+02 2.980e+02 4.860e+02 3.900e+01 6.400e+01 4.200e+02\n",
      " 2.100e+01 1.420e+02 3.300e+01 1.600e+02 2.270e+02 1.280e+02 6.700e+01\n",
      " 2.330e+02 2.000e+02 3.000e+01 2.600e+01 2.300e+01 3.400e+01 1.260e+02\n",
      " 7.500e+01 1.100e+02 4.700e+01 2.700e+01 7.800e+01 1.500e+02 1.850e+02\n",
      " 1.170e+02 4.300e+01 1.160e+02 8.100e+01 4.500e+01 1.990e+02 7.000e+01\n",
      " 5.000e+01 1.070e+02 1.870e+02 2.390e+02 2.500e+02 5.440e+02 9.000e+01\n",
      " 1.700e+01 3.800e+01 2.180e+02 1.010e+03 8.700e+01 1.186e+03 6.900e+01\n",
      " 1.580e+02 1.010e+02 5.200e+01 1.040e+02 2.500e+01 6.850e+02 4.140e+02\n",
      " 5.900e+01 5.550e+02 3.200e+01 4.100e+01 2.880e+02 5.500e+01 4.200e+01\n",
      " 8.500e+01 6.100e+01 1.690e+02 8.400e+02 1.530e+02 1.900e+02 4.150e+02\n",
      " 5.540e+02 1.320e+02 1.140e+02 2.650e+02 5.400e+01 6.600e+01 3.290e+02\n",
      " 3.500e+01 1.300e+02 2.850e+02 6.690e+02 1.650e+02 4.400e+01 1.340e+02\n",
      " 1.080e+02 1.230e+02 1.550e+02 1.500e+03 8.400e+01 4.800e+01 2.960e+02\n",
      " 4.600e+01 1.540e+02 7.300e+01 9.800e+01 3.880e+02 3.930e+02 3.200e+02\n",
      " 1.200e+02 8.900e+01 1.060e+02 2.910e+02 6.300e+01 9.900e+01 3.560e+02\n",
      " 8.600e+01 3.150e+02 8.300e+01 9.600e+01 2.820e+02 2.060e+02 4.180e+02\n",
      " 1.380e+02 6.620e+02 6.800e+01 1.310e+02 5.600e+01 2.810e+02 1.920e+02\n",
      " 9.100e+01 1.450e+02 3.620e+02 4.470e+02 5.490e+02 2.730e+02 1.030e+02\n",
      " 8.000e+01 3.640e+02 1.620e+02 4.490e+02 1.370e+02 1.210e+02 2.340e+02\n",
      " 7.900e+01 1.120e+02 3.500e+02 3.000e+02 1.050e+02 1.960e+02 5.700e+01\n",
      " 2.600e+02 1.640e+02 1.730e+02 1.800e+02 1.490e+02 1.000e+02 2.020e+02\n",
      " 3.990e+02 7.100e+01 2.760e+02 2.080e+02 3.130e+02 1.400e+02 4.020e+02\n",
      " 1.220e+02 3.550e+02 1.270e+02 1.570e+02 2.400e+02 4.000e+02 5.470e+02\n",
      " 7.700e+01 4.080e+02 2.440e+02 3.040e+02 1.750e+02 1.360e+02 4.340e+02\n",
      " 1.907e+03 2.200e+02 2.570e+02 5.000e+02 6.200e+01 1.940e+02 3.300e+02\n",
      " 2.120e+02 1.740e+02 2.450e+02 2.790e+02 3.600e+02 4.310e+02 2.320e+02\n",
      " 1.470e+02 1.660e+02 4.050e+02 1.020e+02 1.510e+02 2.630e+02 2.990e+02\n",
      " 1.820e+02 1.880e+02 2.260e+02 2.590e+02 1.480e+02 2.680e+02 9.300e+01\n",
      " 2.360e+02 1.790e+02 9.500e+01 4.430e+02 7.190e+02 1.250e+02 9.700e+01\n",
      " 2.530e+02 1.005e+03 3.610e+02 1.110e+02 1.720e+02 1.430e+02 1.240e+02\n",
      " 4.170e+02 3.390e+02 4.100e+02 1.710e+02 9.400e+01 4.520e+02 4.400e+02\n",
      " 4.190e+02 7.540e+02 2.040e+02 1.680e+02 4.420e+02 1.330e+02 1.180e+02\n",
      " 2.550e+02 2.620e+02 1.732e+03 1.090e+02 4.160e+02 6.810e+02 7.200e+02\n",
      " 4.800e+02 1.290e+02 2.490e+02 4.500e+02 1.190e+02 3.900e+02 3.700e+02\n",
      " 1.460e+02 4.440e+02 2.430e+02 2.240e+02 3.240e+02 2.030e+02 3.480e+02\n",
      " 2.210e+02 9.480e+02 3.820e+02 3.250e+02 2.690e+02 2.050e+02 2.480e+02\n",
      " 4.030e+02 5.010e+02 1.440e+02 3.260e+02 1.000e+03 1.004e+03 1.830e+02\n",
      " 2.740e+02 5.430e+02 1.970e+02 1.890e+02 5.500e+02 2.470e+02 2.110e+02\n",
      " 1.590e+02 2.770e+02 2.890e+02 3.760e+02 1.930e+02 2.370e+02 1.950e+02\n",
      " 1.410e+02 5.460e+02 4.990e+02 6.700e+02 6.640e+02 3.000e-01 4.770e+02\n",
      " 7.220e+02 3.960e+02 1.780e+02 3.980e+02 5.120e+02 6.240e+02 5.510e+02\n",
      " 8.050e+02 1.499e+03 3.590e+02 5.400e+02 2.410e+02 6.740e+02]\n",
      "Valores faltantes en la columna 51543 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Proposed Use:\n",
      "[nan '1 family dwelling' '2 family dwelling' 'apartments' 'office'\n",
      " 'retail sales' 'nursing home non amb' 'workshop commercial'\n",
      " 'food/beverage hndlng' 'artist live/work' 'theater' 'school'\n",
      " 'tourist hotel/motel' 'filling/service stn' 'residential hotel'\n",
      " 'clinics-medic/dental' 'lending institution' 'church'\n",
      " 'prkng garage/private' 'mortuary' 'warehouse,no frnitur'\n",
      " 'animal sale or care' 'misc group residns.' 'greenhouse'\n",
      " 'public assmbly other' 'auto repairs' 'sfpd or sffd station'\n",
      " 'parking lot' 'christmas tree lot' 'vacant lot' 'club' 'child care'\n",
      " 'day care center' 'wholesale sales' 'recreation bldg'\n",
      " 'health studios & gym' 'nite club' 'power plant' 'prkng garage/public'\n",
      " 'barber/beauty salon' 'day care home gt 12' 'manufacturing'\n",
      " 'ambulance service' 'antenna' 'laundry/laundromat' 'social care facility'\n",
      " 'storage shed' 'hospital' 'nursing home gt 6' 'museum' 'automobile sales'\n",
      " 'sound studio' 'printing plant' 'radio & tv stations' 'library'\n",
      " 'massage parlor' 'moving & storage' 'stadium' 'warehouse, furniture'\n",
      " 'sewage plant' 'amusement center' 'garment shops' 'phone xchnge/equip'\n",
      " 'dance hall' 'nursery(floral)' 'muni carbarn' 'day care, non-res'\n",
      " 'dry cleaners' 'jail' 'accessory cottage' 'convalescent home' 'car wash'\n",
      " 'sign' 'storage tanks' 'tower' 'fence/retaining wall'\n",
      " 'day care home 7 - 12' 'workshop residential' \"prson'l svc tutor\"\n",
      " 'adult entertainment' 'muni driver restroom' 'nursing home lte 6'\n",
      " 'swimming pool' 'chemical processing' 'paint store' 'building materials'\n",
      " 'bath house' 'day care home lt 7' 'dairies/dairy equip.'\n",
      " 'meat/produce marts' 'temple' 'orphanage' 'r-3(dwg) nursing'\n",
      " 'roofing materials' 'not applicable']\n",
      "Valores faltantes en la columna 42441 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Proposed Units:\n",
      "[      nan 1.000e+00 2.000e+00 4.000e+00 3.000e+00 0.000e+00 9.000e+00\n",
      " 2.900e+01 8.000e+00 6.000e+00 3.100e+01 5.300e+01 1.500e+01 2.580e+02\n",
      " 5.100e+01 9.200e+01 4.480e+02 5.000e+00 7.000e+00 1.860e+02 5.290e+02\n",
      " 3.600e+01 1.100e+01 1.300e+01 2.400e+01 1.200e+01 1.150e+02 7.200e+01\n",
      " 7.400e+01 1.610e+02 1.900e+01 2.600e+01 3.700e+01 1.700e+02 5.500e+02\n",
      " 6.000e+01 4.900e+01 8.200e+01 1.400e+01 6.500e+01 4.040e+02 1.800e+01\n",
      " 1.910e+02 1.350e+02 1.560e+02 5.200e+01 1.600e+01 8.800e+01 4.090e+02\n",
      " 1.000e+01 4.000e+01 1.980e+02 2.540e+02 7.600e+01 2.970e+02 5.800e+01\n",
      " 2.000e+01 1.390e+02 2.100e+01 1.130e+02 2.980e+02 4.860e+02 3.900e+01\n",
      " 6.400e+01 4.200e+02 1.420e+02 3.300e+01 1.600e+02 2.270e+02 1.380e+02\n",
      " 1.280e+02 6.700e+01 2.330e+02 2.800e+01 2.000e+02 3.000e+01 2.300e+01\n",
      " 3.400e+01 1.820e+02 1.260e+02 7.500e+01 1.100e+02 4.700e+01 2.700e+01\n",
      " 7.800e+01 1.500e+02 1.850e+02 1.170e+02 2.200e+01 4.300e+01 1.160e+02\n",
      " 8.100e+01 4.500e+01 2.030e+02 7.000e+01 5.000e+01 1.070e+02 1.870e+02\n",
      " 2.390e+02 2.500e+02 1.700e+01 4.080e+02 5.440e+02 9.000e+01 3.800e+01\n",
      " 2.180e+02 2.590e+02 1.010e+03 8.700e+01 1.186e+03 6.900e+01 2.960e+02\n",
      " 1.580e+02 1.010e+02 9.400e+01 7.900e+01 1.040e+02 2.500e+01 8.500e+01\n",
      " 4.310e+02 2.250e+02 6.850e+02 4.140e+02 5.900e+01 5.550e+02 3.200e+01\n",
      " 4.100e+01 2.880e+02 5.500e+01 4.200e+01 8.900e+01 6.100e+01 1.690e+02\n",
      " 8.400e+02 2.800e+02 1.530e+02 1.900e+02 4.150e+02 5.540e+02 1.320e+02\n",
      " 1.140e+02 5.400e+01 2.730e+02 6.600e+01 3.290e+02 3.500e+01 1.310e+02\n",
      " 2.850e+02 6.690e+02 1.650e+02 4.400e+01 1.340e+02 1.080e+02 1.720e+02\n",
      " 1.230e+02 1.550e+02 1.500e+03 8.400e+01 4.340e+02 1.300e+02 4.800e+01\n",
      " 4.600e+01 2.620e+02 1.540e+02 7.300e+01 9.800e+01 3.880e+02 3.930e+02\n",
      " 3.200e+02 1.200e+02 1.060e+02 9.300e+01 2.910e+02 6.300e+01 9.900e+01\n",
      " 3.560e+02 8.600e+01 3.150e+02 8.300e+01 9.600e+01 2.820e+02 2.060e+02\n",
      " 4.180e+02 6.620e+02 1.620e+02 6.800e+01 5.600e+01 2.810e+02 2.080e+02\n",
      " 9.500e+01 1.920e+02 9.100e+01 1.450e+02 3.620e+02 4.470e+02 5.490e+02\n",
      " 1.030e+02 8.000e+01 1.430e+02 3.640e+02 4.490e+02 1.370e+02 1.210e+02\n",
      " 2.340e+02 1.120e+02 3.500e+02 3.000e+02 1.050e+02 1.960e+02 5.700e+01\n",
      " 2.600e+02 1.640e+02 1.730e+02 1.990e+02 1.800e+02 1.490e+02 1.000e+02\n",
      " 2.020e+02 1.740e+02 3.990e+02 7.100e+01 2.760e+02 3.130e+02 1.400e+02\n",
      " 4.020e+02 1.220e+02 3.610e+02 1.270e+02 1.570e+02 1.110e+02 1.090e+02\n",
      " 2.400e+02 4.000e+02 5.470e+02 1.360e+02 7.700e+01 2.440e+02 3.040e+02\n",
      " 1.750e+02 1.907e+03 2.200e+02 2.630e+02 5.460e+02 2.570e+02 5.000e+02\n",
      " 6.200e+01 1.940e+02 2.560e+02 3.300e+02 2.120e+02 2.450e+02 2.790e+02\n",
      " 3.600e+02 4.030e+02 2.320e+02 1.470e+02 1.660e+02 4.050e+02 4.790e+02\n",
      " 1.020e+02 1.510e+02 2.990e+02 1.880e+02 2.260e+02 1.480e+02 1.290e+02\n",
      " 3.900e+02 2.680e+02 3.190e+02 3.840e+02 5.400e+02 2.360e+02 1.790e+02\n",
      " 4.440e+02 1.250e+02 9.700e+01 2.530e+02 1.014e+03 1.005e+03 4.700e+02\n",
      " 1.240e+02 1.520e+02 4.170e+02 3.390e+02 4.100e+02 1.710e+02 6.740e+02\n",
      " 1.680e+02 4.520e+02 3.510e+02 4.400e+02 2.670e+02 4.190e+02 7.540e+02\n",
      " 2.040e+02 5.450e+02 4.420e+02 1.330e+02 1.180e+02 2.550e+02 2.650e+02\n",
      " 1.950e+02 1.732e+03 5.280e+02 4.160e+02 6.810e+02 7.190e+02 4.010e+02\n",
      " 7.220e+02 1.890e+02 2.490e+02 2.300e+02 2.130e+02 4.500e+02 1.190e+02\n",
      " 3.700e+02 1.460e+02 2.430e+02 2.240e+02 5.010e+02 3.240e+02 3.480e+02\n",
      " 3.160e+02 2.210e+02 9.480e+02 3.820e+02 3.250e+02 2.690e+02 2.050e+02\n",
      " 2.480e+02 3.260e+02 4.750e+02 1.440e+02 1.000e+03 1.830e+02 2.740e+02\n",
      " 5.430e+02 1.970e+02 7.200e+02 2.470e+02 2.110e+02 1.590e+02 3.030e+02\n",
      " 2.770e+02 2.890e+02 5.040e+02 3.760e+02 1.930e+02 2.370e+02 1.410e+02\n",
      " 4.990e+02 6.760e+02 6.700e+02 6.640e+02 3.550e+02 4.770e+02 3.960e+02\n",
      " 1.780e+02 3.980e+02 5.120e+02 6.240e+02 3.120e+02 5.510e+02 1.499e+03\n",
      " 3.590e+02 1.911e+03 3.050e+02 1.199e+03 2.410e+02]\n",
      "Valores faltantes en la columna 50915 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Plansets:\n",
      "[   nan 2.e+00 0.e+00 3.e+00 4.e+00 2.e+01 9.e+03 6.e+00 1.e+00]\n",
      "Valores faltantes en la columna 37311 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna TIDF Compliance:\n",
      "[nan 'P' 'Y']\n",
      "Valores faltantes en la columna 198908 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Existing Construction Type:\n",
      "[        nan  5.0000e+00  3.0000e+00  1.0000e+00  2.0000e+00  4.0000e+00\n",
      " -9.9999e+04  9.9999e+04]\n",
      "Valores faltantes en la columna 43369 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Existing Construction Type Description:\n",
      "[nan 'wood frame (5)' 'constr type 3' 'constr type 1' 'constr type 2'\n",
      " 'constr type 4' ' constr type 1 ' ' constr type 3 ' ' wood frame (5) ']\n",
      "Valores faltantes en la columna 43370 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Proposed Construction Type:\n",
      "[nan  5.  3.  2.  1.  4.]\n",
      "Valores faltantes en la columna 43165 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Proposed Construction Type Description:\n",
      "[nan 'wood frame (5)' 'constr type 3' 'constr type 2' 'constr type 1'\n",
      " 'constr type 4']\n",
      "Valores faltantes en la columna 43165 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Site Permit:\n",
      "[nan 'Y']\n",
      "Valores faltantes en la columna 193550 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Supervisor District:\n",
      "['3.0' '4.0' '9.0' '5.0' '8.0' '2.0' '6.0' '10.0' '1.0' '7.0' '11.0' nan\n",
      " 'quince' 7.0 5.0 3.0 11.0 4.0 8.0 2.0 9.0 6.0 1.0 10.0 'veinte' 'diez']\n",
      "Valores faltantes en la columna 1719 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Neighborhoods - Analysis Boundaries:\n",
      "['Nob Hill' 'Sunset/Parkside' 'Bernal Heights' 'Pacific Heights' 'Mission'\n",
      " 'Castro/Upper Market' 'Financial District/South Beach' 'Chinatown'\n",
      " 'South of Market' 'Inner Richmond' 'Bayview Hunters Point'\n",
      " 'Outer Richmond' 'Marina' 'North Beach' 'Russian Hill' 'Haight Ashbury'\n",
      " 'Presidio Heights' 'Glen Park' 'West of Twin Peaks' 'Excelsior'\n",
      " 'Noe Valley' 'Potrero Hill' 'Twin Peaks' 'Seacliff' 'Hayes Valley'\n",
      " 'Western Addition' 'Outer Mission' 'Inner Sunset'\n",
      " 'Oceanview/Merced/Ingleside' 'Tenderloin' 'Lakeshore' 'Lone Mountain/USF'\n",
      " 'Mission Bay' nan 'Visitacion Valley' 'Portola' 'Japantown'\n",
      " 'McLaren Park' 'Treasure Island' 'Lincoln Park' 'Presidio'\n",
      " 'Golden Gate Park']\n",
      "Valores faltantes en la columna 1725 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Zipcode:\n",
      "[94109. 94122. 94110. 94115. 94114. 94105. 94111. 94107. 94118. 94124.\n",
      " 94108. 94121. 94123. 94133. 94117. 94131. 94127. 94103. 94132. 94112.\n",
      " 94116. 94102. 94158. 94104.    nan 94134. 94130. 94129.]\n",
      "Valores faltantes en la columna 1716 de un total de 198910 filas\n",
      "\n",
      "Valores únicos en la columna Location:\n",
      "['(37.79362102799777, -122.41488237355445)'\n",
      " '(37.759041020475465, -122.50286985467523)'\n",
      " '(37.73778863007536, -122.41197863877355)' ...\n",
      " '(37.759969704877626, -122.49117697122442)'\n",
      " '(37.71192805393076, -122.4500944316179)'\n",
      " '(37.75260530951628, -122.40400191084352)']\n",
      "Valores faltantes en la columna 1700 de un total de 198910 filas\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los valores únicos para cada columna que le falten datos\n",
    "cantidad_filas = df.shape[0]\n",
    "\n",
    "for column in df.columns:\n",
    "    valores_unicos = df[column].unique()\n",
    "    valores_faltantes = df[column].isnull().sum()\n",
    "\n",
    "    if (valores_faltantes > 0):\n",
    "        print(f'\\nValores únicos en la columna {column}:')\n",
    "        print(valores_unicos)\n",
    "        print(f'Valores faltantes en la columna {valores_faltantes} de un total de {cantidad_filas} filas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los datos obtenidos anteriormente de las columnas que tienen datos vacíos y sus valores únicos deducimos los siguientes posibles motivos:\n",
    "\n",
    "- Street Number Suffix: los datos vacíos pueden ser porque no se conocen o no apliquen para esta dirección. Esto se dedujo porque hay muchos vacíos.\n",
    "- Street Suffix: los datos vacíos pueden ser porque no se conocen o no apliquen para esta dirección. Igualmente son pocos los faltantes.\n",
    "- Unit: los datos vacíos pueden ser porque no se conocen o no apliquen para este edificio. Esto se dedujo porque hay muchos vacíos y hay mucha variedad de valores únicos.\n",
    "- Unit Suffix: los datos vacíos pueden ser porque no se conocen o no apliquen para este edificio. Esto se dedujo porque hay muchos vacíos y hay mucha variedad de valores únicos.\n",
    "- Descripción: no se ingresó, por lo tanto no se conoce. Son muy pocos los vacíos.\n",
    "- Issued Date: tal vez hubo errores de no ingresar la fecha, los faltantes son pocos. Tal vez el permiso no se expidió aún.\n",
    "- Completed Date: los faltantes de esta columna deberían corresponder a las construcciones que aún no finalizaron.\n",
    "- First Construction Document Date: los faltantes deberían ser de aquellas obras en las que aún no se inicio la construcción.\n",
    "- Structural Notification: hay una gran cantidad de datos faltantes, lo que significa que la gran mayoría de los permisos no tendrían que cumplir o tener en cuenta alguna notificación estructural.\n",
    "- Number of Existing Stories: los datos faltantes podrían darse porque la construcción aún no ha comenzado y no tiene pisos actualmente. También, como se aclara en la metadata, este atributo no aplica para ciertos permisos. Este item aplicaría más para remodelaciones.\n",
    "- Number of Proposed Stories: al igual que en los pisos existentes, los propuestos podrían no aplicar para ciertos permisos.\n",
    "- Voluntary Soft-Story Retrofit: la mayoría de los datos son vacíos, esto puede ser porque solo unos pocos permisos cuentan con la protección contra terremotos.\n",
    "- Fire Only Permit: Al igual que en la anterior, son pocos los permisos relacionados a la prevención de incendios.\n",
    "- Permit Expiration Date: los faltantes en esta columna podrían ser porque simplemente los permisos no tienen una fecha de vencimiento o la misma es a futuro en el largo plazo.\n",
    "- Estimated Cost: los faltantes aquí pueden ser debido a costos bajos que se omitieron, otros que son dificiles o no se tomo el trabajo de estimar.\n",
    "- Revised Cost: aquí los faltantes son menos, quizás debido a una instancia obligatoria o recomendada de revisar el costo estimado.\n",
    "- Existing Use: los faltantes en esta columna pueden ser debido a que la construcción aun no existe o no está terminada, o por usos diversos.\n",
    "- Existing Units: los faltantes pueden ser debido a que la construcción aún no existe o no aplican las 'unidades' al permiso en cuestión.\n",
    "- Proposed Use: los faltantes pueden ser porque el/los uso/s no está/n claro/s o no tiene uno específico.\n",
    "- Proposed Units: los que faltan podrían ser porque se considera que no corresponde la división por unidades en esos permisos.\n",
    "- Plansets: los faltantes podrían ser por falta de planos formales de construcción o que estén por fuera del permiso.\n",
    "- TIDF Compliance: la mayoría faltan, y puede ser debido al desconocimiento de este requerimiento legal (por ser nuevo)\n",
    "- Existing Construction Type: los que faltan pueden ser porque el tipo de construcción no está en las categorías existentes o no se le encuentra el tipo.\n",
    "- Existing Construction Type Description: el mismo motivo que el anterior.\n",
    "- Proposed Construction Type: igual al anterior\n",
    "- Proposed Construction Type Description: igual al anterior\n",
    "- Site Permit: tienen que ser valores verdadero o falso. Por lo tanto, los vacíos son porque no tiene permiso para construir en el sitio.\n",
    "- Supervisor District: igual a los anteriores\n",
    "- Neighborhoods - Analysis Boundaries: igual a los anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Para variables discretas, evaluar los posibles valores de cada variable (valores únicos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos en la columna Permit Number:\n",
      "['M788927' '201305318356' '201705106205' ... '201607293741' '201701066691'\n",
      " '201604255599']\n",
      "\n",
      "Valores únicos en la columna Permit Type:\n",
      "[8 2 4 3 6 1 7 5]\n",
      "\n",
      "Valores únicos en la columna Permit Type Definition:\n",
      "['otc alterations permit' 'new construction wood frame' 'sign - erect'\n",
      " 'additions alterations or repairs' 'demolitions' 'new construction'\n",
      " 'wall or painted sign' 'grade or quarry or fill or excavate'\n",
      " ' otc alterations permit ' ' new construction '\n",
      " 'otc alterations permit #' 'new construction #'\n",
      " ' additions alterations or repairs ']\n",
      "\n",
      "Valores únicos en la columna Permit Creation Date:\n",
      "['05/23/2017' '05/31/2013' '05/10/2017' ... '2017-02-10' '2016-11-14'\n",
      " '2013-03-06']\n",
      "\n",
      "Valores únicos en la columna Block:\n",
      "['0215' '1810' '5700' ... '4976' '6125' '6757']\n",
      "\n",
      "Valores únicos en la columna Lot:\n",
      "['001' '017A' '027' ... '018X' '031H' '030E']\n",
      "\n",
      "Valores únicos en la columna Street Number:\n",
      "[1333 1483  431 ... 4183 6237 4848]\n",
      "\n",
      "Valores únicos en la columna Street Number Suffix:\n",
      "[nan 'B' 'A' 'V' 'D' 'K' 'C' 'F' 'H' 'E' 'L' 'J' 'R' 'P' 'I' 'N' 'G' '½'\n",
      " '0']\n",
      "\n",
      "Valores únicos en la columna Street Name:\n",
      "['jOnEs' '43rD' 'pReNtIsS' ... 'iGnAcIo' 'fErN' 'rIo']\n",
      "\n",
      "Valores únicos en la columna Street Suffix:\n",
      "['St' 'Av' 'Bl' nan 'Wy' 'Dr' 'Hy' 'Tr' 'Rd' 'Ct' 'Pl' 'Pk' 'Ln' 'Cr' 'Pz'\n",
      " 'Al' 'No' 'Rw' 'Wk' 'So' 'Hl' 'Sw']\n",
      "\n",
      "Valores únicos en la columna Unit:\n",
      "[      nan 0.000e+00 5.010e+02 3.000e+00 7.000e+00 2.000e+00 2.160e+02\n",
      " 2.030e+02 2.020e+02 6.000e+00 1.000e+00 1.100e+01 1.300e+01 3.700e+01\n",
      " 5.050e+02 3.210e+02 1.060e+02 4.000e+00 2.370e+02 1.170e+02 3.100e+01\n",
      " 4.230e+02 3.010e+02 1.050e+02 5.100e+01 2.010e+02 1.040e+02 9.180e+02\n",
      " 1.010e+02 1.401e+03 5.000e+00 3.050e+02 7.010e+02 8.010e+02 1.370e+03\n",
      " 7.050e+02 4.070e+02 1.005e+03 3.600e+02 8.300e+02 8.020e+02 2.040e+02\n",
      " 1.632e+03 1.004e+03 2.360e+02 1.020e+02 4.010e+02 5.070e+02 6.180e+02\n",
      " 1.704e+03 1.602e+03 3.020e+02 6.080e+02 4.100e+02 2.130e+02 4.060e+02\n",
      " 2.200e+01 3.830e+02 9.010e+02 6.170e+02 4.090e+02 3.040e+02 4.020e+02\n",
      " 1.700e+03 1.600e+01 3.270e+02 8.000e+00 1.000e+01 1.150e+03 2.090e+02\n",
      " 3.080e+02 1.116e+03 4.180e+02 2.230e+02 1.030e+02 1.007e+03 7.080e+02\n",
      " 1.233e+03 1.404e+03 2.700e+01 9.000e+00 2.501e+03 4.400e+01 6.070e+02\n",
      " 6.400e+02 5.903e+03 8.160e+02 1.408e+03 4.120e+02 1.700e+01 3.170e+02\n",
      " 3.110e+02 3.101e+03 3.030e+02 2.150e+02 1.800e+01 6.020e+02 1.900e+01\n",
      " 6.010e+02 2.500e+02 3.090e+02 3.500e+01 6.040e+02 1.200e+01 2.100e+01\n",
      " 1.402e+03 4.040e+02 6.030e+02 2.060e+02 8.080e+02 3.400e+01 4.080e+02\n",
      " 9.060e+02 4.150e+02 1.400e+01 3.190e+02 1.201e+03 2.300e+01 1.105e+03\n",
      " 3.260e+02 4.300e+01 3.070e+02 1.703e+03 3.600e+01 2.080e+02 7.030e+02\n",
      " 1.110e+02 1.160e+02 2.900e+03 3.300e+01 2.500e+01 5.480e+02 2.270e+02\n",
      " 4.140e+02 2.203e+03 3.390e+02 1.150e+02 8.170e+02 2.240e+02 2.050e+02\n",
      " 2.800e+01 1.372e+03 2.872e+03 7.600e+01 2.180e+02 2.900e+01 5.020e+02\n",
      " 1.305e+03 4.050e+02 1.202e+03 4.700e+01 7.070e+02 1.080e+02 3.150e+02\n",
      " 1.101e+03 4.006e+03 1.370e+02 3.000e+01 1.407e+03 5.040e+02 4.360e+02\n",
      " 1.015e+03 6.100e+01 5.570e+02 4.030e+02 1.100e+02 6.120e+02 1.207e+03\n",
      " 5.340e+02 1.260e+02 1.608e+03 6.520e+02 4.100e+01 3.160e+02 8.040e+02\n",
      " 2.402e+03 1.120e+02 1.415e+03 1.102e+03 5.300e+01 8.070e+02 1.135e+03\n",
      " 6.230e+02 1.302e+03 1.152e+03 3.290e+02 3.312e+03 3.320e+02 5.700e+02\n",
      " 1.501e+03 5.220e+02 4.901e+03 7.000e+01 1.070e+02 9.040e+02 1.103e+03\n",
      " 3.060e+02 3.200e+01 2.000e+02 1.301e+03 3.800e+01 5.030e+02 5.900e+01\n",
      " 1.208e+03 2.210e+02 2.034e+03 3.230e+02 2.604e+03 1.290e+02 9.050e+02\n",
      " 2.070e+02 4.800e+01 5.213e+03 1.050e+03 4.900e+01 4.690e+02 1.500e+01\n",
      " 4.310e+03 3.680e+02 2.502e+03 5.440e+02 5.120e+02 7.170e+02 2.301e+03\n",
      " 4.110e+02 2.000e+01 2.260e+02 8.420e+02 1.106e+03 1.432e+03 1.601e+03\n",
      " 2.110e+02 2.400e+01 3.000e+02 4.260e+02 3.140e+02 9.090e+02 8.460e+02\n",
      " 3.100e+02 2.100e+02 1.702e+03 5.090e+02 5.580e+02 3.705e+03 4.190e+02\n",
      " 1.792e+03 5.080e+02 1.902e+03 3.202e+03 5.150e+02 3.120e+02 8.240e+02\n",
      " 7.020e+02 1.312e+03 2.190e+02 4.620e+02 7.040e+02 5.204e+03 6.060e+02\n",
      " 2.192e+03 1.604e+03 7.900e+01 3.446e+03 1.140e+03 6.220e+02 3.220e+02\n",
      " 8.090e+02 7.100e+02 4.200e+01 6.510e+02 1.180e+02 1.059e+03 1.090e+02\n",
      " 6.300e+02 2.280e+02 3.200e+02 6.160e+02 9.310e+02 2.650e+03 4.520e+02\n",
      " 1.211e+03 1.690e+02 1.441e+03 1.901e+03 1.115e+03 1.214e+03 4.500e+01\n",
      " 1.250e+02 1.204e+03 5.520e+02 5.602e+03 1.108e+03 1.114e+03 1.420e+02\n",
      " 7.150e+02 3.640e+02 1.006e+03 8.060e+02 4.320e+02 6.340e+02 4.510e+02\n",
      " 8.100e+02 2.610e+02 9.900e+01 9.140e+02 2.202e+03 5.590e+02 9.520e+02\n",
      " 5.550e+02 6.560e+02 1.110e+03 9.030e+02 1.130e+02 1.240e+02 4.706e+03\n",
      " 4.130e+02 2.300e+03 9.020e+02 9.100e+02 8.220e+02 2.600e+01 2.601e+03\n",
      " 1.610e+03 1.505e+03 9.470e+02 2.401e+03 2.570e+02 1.001e+03 1.796e+03\n",
      " 7.090e+02 1.024e+03 6.140e+02 6.050e+02 4.720e+02 1.203e+03 1.511e+03\n",
      " 2.201e+03 2.005e+03 7.250e+02 2.003e+03 1.032e+03 5.060e+02 5.306e+03\n",
      " 5.100e+02 1.003e+03 2.888e+03 8.050e+02 3.540e+02 3.350e+02 1.009e+03\n",
      " 1.107e+03 7.060e+02 2.404e+03 5.700e+01 4.600e+01 1.516e+03 1.210e+03\n",
      " 3.180e+02 4.540e+02 1.431e+03 2.140e+03 3.900e+01 6.800e+01 1.717e+03\n",
      " 1.403e+03 1.140e+02 7.260e+02 6.150e+02 5.000e+01 1.503e+03 2.390e+02\n",
      " 3.903e+03 1.418e+03 1.412e+03 3.130e+02 2.204e+03 5.170e+02 2.214e+03\n",
      " 1.607e+03 4.000e+01 2.101e+03 7.210e+02 2.773e+03 8.230e+02 1.904e+03\n",
      " 1.805e+03 8.570e+02 7.130e+02 1.000e+02 4.409e+03 1.104e+03 5.230e+02\n",
      " 5.180e+02 4.570e+02 3.300e+02 5.005e+03 1.002e+03 1.109e+03 1.200e+02\n",
      " 2.001e+03 6.000e+02 2.725e+03 4.200e+02 1.530e+02 1.519e+03 7.500e+01\n",
      " 6.290e+02 5.412e+03 1.220e+02 1.606e+03 1.800e+03 1.025e+03 1.603e+03\n",
      " 1.409e+03 6.100e+02 2.470e+02 5.190e+02 1.303e+03 4.000e+02 1.249e+03\n",
      " 1.701e+03 1.517e+03 2.904e+03 1.014e+03 5.350e+02 9.000e+02 7.110e+02\n",
      " 2.002e+03 1.309e+03 4.160e+02 7.000e+02 9.650e+02 4.310e+02 9.120e+02\n",
      " 3.330e+02 5.600e+01 2.166e+03 6.003e+03 8.400e+02 1.380e+02 1.406e+03\n",
      " 3.250e+02 8.030e+02 1.221e+03 1.502e+03 5.113e+03 2.704e+03 7.520e+02\n",
      " 6.130e+02 4.280e+02 2.109e+03 9.570e+02 4.600e+02 8.520e+02 7.140e+02\n",
      " 2.350e+02 1.514e+03 1.450e+03 3.510e+02 4.340e+02 4.220e+02 8.700e+01\n",
      " 2.290e+02 6.200e+01 7.200e+01 5.110e+02 2.223e+03 3.560e+02 9.210e+02\n",
      " 1.570e+02 8.400e+01 6.490e+02 2.410e+02 1.124e+03 5.130e+02 9.070e+02\n",
      " 3.460e+02 8.100e+01 6.090e+02 1.618e+03 9.420e+02 3.004e+03 5.370e+02\n",
      " 3.240e+02 2.534e+03 6.250e+02 4.210e+03 5.313e+03 1.230e+03 2.140e+02\n",
      " 1.016e+03 3.103e+03 5.000e+02 3.105e+03 1.047e+03 6.110e+02 3.510e+03\n",
      " 1.304e+03 3.256e+03 5.330e+02 6.210e+02 5.500e+01 1.167e+03 6.470e+02\n",
      " 1.504e+03 1.022e+03 1.449e+03 5.206e+03 5.103e+03 4.309e+03 9.220e+02\n",
      " 6.190e+02 2.031e+03 5.160e+02 4.109e+03 2.530e+02 1.605e+03 1.613e+03\n",
      " 1.500e+03 6.000e+01 2.200e+02 2.303e+03 2.317e+03 4.001e+03 2.220e+02\n",
      " 7.690e+02 2.102e+03 2.801e+03 1.308e+03 2.120e+02 6.360e+02 2.803e+03\n",
      " 1.500e+02 4.300e+02 9.080e+02 3.412e+03 4.460e+02 1.424e+03 1.132e+03\n",
      " 5.604e+03 3.370e+02 3.005e+03 1.543e+03 3.704e+03 2.905e+03 1.043e+03\n",
      " 2.221e+03 4.480e+02 2.400e+03 7.360e+02 7.400e+01 4.410e+03 7.200e+02\n",
      " 1.131e+03 1.000e+03 1.480e+02 2.340e+02 1.411e+03 8.750e+02 7.240e+02\n",
      " 8.120e+02 5.530e+02 3.450e+02 1.801e+03 3.280e+02 1.414e+03 7.320e+02\n",
      " 5.112e+03 4.500e+02 2.805e+03 4.240e+02 1.251e+03 9.000e+01 3.440e+02\n",
      " 8.180e+02 9.200e+02 5.560e+02 6.570e+02 5.270e+02 8.320e+02 1.520e+02\n",
      " 3.401e+03 1.580e+02 6.500e+02 1.026e+03 1.112e+03 1.230e+02 2.070e+03\n",
      " 4.410e+02 9.160e+02 3.801e+03 1.212e+03 7.120e+02 2.103e+03 3.360e+02\n",
      " 9.320e+02 7.160e+02 5.400e+01 1.011e+03 4.660e+02 5.413e+03 4.110e+03\n",
      " 6.004e+03 2.526e+03 9.300e+02 3.580e+02 5.140e+02 3.861e+03 1.802e+03\n",
      " 2.170e+02 1.806e+03 9.110e+02 5.312e+03 1.510e+03 1.540e+02 1.508e+03\n",
      " 1.790e+03 8.590e+02 4.730e+02 6.260e+02 1.253e+03 1.270e+02 1.307e+03\n",
      " 7.800e+01 7.570e+02 3.254e+03 4.113e+03 5.200e+02 2.207e+03 1.206e+03\n",
      " 1.300e+02 6.310e+02 5.310e+02 1.317e+03 4.380e+02 7.230e+02 1.410e+02\n",
      " 1.360e+02 5.212e+03 2.800e+02 6.900e+01 4.170e+02 1.310e+03 9.390e+02\n",
      " 1.506e+03 8.000e+02 2.700e+03 2.250e+02 5.106e+03 1.120e+03 3.201e+03\n",
      " 1.808e+03 6.700e+01 8.720e+02 4.209e+03 5.210e+02 4.270e+02 4.004e+03\n",
      " 1.609e+03 1.190e+02 7.370e+02]\n",
      "\n",
      "Valores únicos en la columna Unit Suffix:\n",
      "[nan 'C' \"RESID'L\" 'D' 'E' 'WEST' 'F' 'HOA' 'A' 'UPPER UNIT' 'B' 'H'\n",
      " 'EAST' 'GPHA' '1/F' 'FRONT' 'Garage' 'UPPER' 'LOWER UNIT' 'O' 'N'\n",
      " 'RESDL/REAR' 'CHILD DEV' 'RESIDENTIA' 'REAR UNIT' 'COMMERCIAL' 'BLDG 157'\n",
      " 'RETAIL 1' 'W' 'M301' 'C132' 'J' 'M' 'COMML' 'BLDG 3E' 'OFFICE' '-A'\n",
      " 'COML' 'FRONT BLDG' 'REAR' 'C-2001' 'M202' 'BLDG 1' 'C101' 'LOWER COML'\n",
      " 'FRNT BLDG' 'PH-1' 'P' 'Y' 'LEVEL ONE' '1ST FLOOR' 'TH1' 'C103' 'C1'\n",
      " 'LOWER' 'FRONT UNIT' 'R-1' 'K' 'G' 'C102' 'COMML-3' 'TH2' 'C-1' 'A102'\n",
      " 'S' 'T' 'Commercial' 'COMMON ARE' 'BLDG 229' 'UPPR COMML' 'CU-3' 'I'\n",
      " '1/F FRONT' 'STORE' 'REAR BLDG' 'R' 'BLDG 449' 'OFFICE 2/F' 'B-A'\n",
      " 'COMML 1' 'PH-4' 'M1' 'COM-1' 'BLD 7' '1503B' '-B' 'Parcel B'\n",
      " 'FRNT RIGHT' 'STUDIO/TEC' 'TENTATIVE' 'RESIDENCE' 'PH1A' 'COMML-2' '0'\n",
      " 'BLDG C' 'BLDG 3F' 'M101' 'C-2' \"COM'L\" '1/2' 'C-4' 'D4' 'U' 'RESIDL 3/F'\n",
      " 'LEASE OFF' 'Parcel C' 'L' 'C100' 'PH2B' 'LEAS OFFIC' 'REAR G/F' '407'\n",
      " 'BLDG 201' 'U-PH3' 'BLDG 3' '3/F' 'PH' 'UTILITY' '3RD FLOOR' 'FRNT ENTRA'\n",
      " 'PH C' '3/F FRONT' 'BSM OFFICE' '2/F' 'MIDDLE' 'BLDG. 3' '1A-4' 'COMML-1'\n",
      " 'BASEMENT' 'PH1E' 'BLDG A' 'HMETER' 'PARKING' 'TOP' 'PARCEL A' 'BLDG E'\n",
      " 'UPPER LEVE' 'W122' 'THEATRE' 'CU-2' 'D3' 'COM-2' 'A104' 'BLDG 2'\n",
      " 'BLDG D' 'PH1C' 'FC1' 'CML A' \"RES'L\" 'B20H' 'PIER 3' 'PIER 2' '#R-2'\n",
      " 'BLDG B' 'UP FRT BLD' 'Parcel D' 'Parcel A' \"COM'L 1/F\" 'RETAIL 2'\n",
      " 'LEVEL 4' 'PH1' 'A100' '2ND FLOOR' \"COMM'\" 'PIER 1']\n",
      "\n",
      "Valores únicos en la columna Description:\n",
      "['street space'\n",
      " 'remodel kitchen: replace countertop, cabinets, sink, stove, hardwood floor & lighting.'\n",
      " 'replacement of 4 windows; 2 located in lightwell and 2 at front. replaceing existing vinyl windows with new wood-clad windows. no horizontal mullion in living room window'\n",
      " ...\n",
      " 'replace rotten wooden moldings in kind front stairs less than 50% replace'\n",
      " 'revision to pa 2016-0926-8773; remove (e) storefront & doors, remove floor, ceiling & wall finishes for new. new storefront, (n) wall & ceiling finishes, (n) flooring with waterproofing in a (n) alcove. mep under pa#201503100377'\n",
      " '16th floor - (4) evacuation plans.']\n",
      "\n",
      "Valores únicos en la columna Current Status:\n",
      "['issued' 'complete' 'filed' 'approved' 'withdrawn' 'reinstated'\n",
      " 'cancelled' 'revoked' 'expired' 'plancheck' 'suspend' 'incomplete'\n",
      " 'disapproved' 'appeal']\n",
      "\n",
      "Valores únicos en la columna Current Status Date:\n",
      "['05/23/2017' '08/28/2013' '05/11/2017' ... '03/23/2013' '07/15/2017'\n",
      " '11/02/2014']\n",
      "\n",
      "Valores únicos en la columna Filed Date:\n",
      "['05/23/2017' '05/31/2013' '05/10/2017' ... '05/02/2013' '02/04/2016'\n",
      " '11/17/2015']\n",
      "\n",
      "Valores únicos en la columna Issued Date:\n",
      "['05/23/2017' '06/03/2013' '05/11/2017' ... '05/24/2016' '06/05/2015'\n",
      " '12/12/2015']\n",
      "\n",
      "Valores únicos en la columna Completed Date:\n",
      "[nan '08/28/2013' '12/31/2014' ... '01/04/2013' '03/23/2013' '11/02/2014']\n",
      "\n",
      "Valores únicos en la columna First Construction Document Date:\n",
      "['05/23/2017' '06/03/2013' '05/11/2017' ... '02/04/2016' '05/24/2016'\n",
      " '06/05/2015']\n",
      "\n",
      "Valores únicos en la columna Structural Notification:\n",
      "[nan 'Y']\n",
      "\n",
      "Valores únicos en la columna Number of Existing Stories:\n",
      "[ nan  2.   3.   1.   4.  40.   5.   9.  18.   6.  30.  24.  23.  12.\n",
      " 29.  38.  42.  20.  25.   8.   7.  11.  52.  10.  43.  16.  14.  48.\n",
      "  0.  21.  33.  22.  27.  37.  13.  32.  31.  15.  39.  58.  19.  17.\n",
      " 26.  63.  34.  36.  35.  28.  50.  41.  44.  45.  53.  47.  49.  60.\n",
      " 46.  61.  55.  62.  54.   1.5 56.  78.   2.5]\n",
      "\n",
      "Valores únicos en la columna Number of Proposed Stories:\n",
      "[ nan  2.   3.   1.   4.   5.  40.   9.  18.   6.  30.  24.  23.  12.\n",
      " 29.  38.  42.  20.  25.   8.   7.  11.  52.  10.  43.  16.  14.  48.\n",
      " 21.  33.  63.  22.  27.  19.  37.  13.  32.  31.  15.  39.  58.  17.\n",
      " 26.  34.  36.  35.  28.  50.   0.  41.  44.  45.  53.  46.  47.  55.\n",
      " 60.  49.  56.  61.  62.  54.   1.5 78.   2.5]\n",
      "\n",
      "Valores únicos en la columna Voluntary Soft-Story Retrofit:\n",
      "[nan 'Y']\n",
      "\n",
      "Valores únicos en la columna Fire Only Permit:\n",
      "[nan 'Y']\n",
      "\n",
      "Valores únicos en la columna Permit Expiration Date:\n",
      "[nan '05/29/2014' '05/06/2018' ... '11/22/2022' '09/12/2022' '01/06/2020']\n",
      "\n",
      "Valores únicos en la columna Estimated Cost:\n",
      "[    nan  12000.   1000. ...   9131.  15602. 648405.]\n",
      "\n",
      "Valores únicos en la columna Revised Cost:\n",
      "[1.000000e+00 1.200000e+04 2.000000e+03 ... 1.560200e+04 6.484050e+05\n",
      " 9.280092e+05]\n",
      "\n",
      "Valores únicos en la columna Existing Use:\n",
      "[nan '1 family dwelling' '2 family dwelling' 'apartments' 'office'\n",
      " 'retail sales' 'nursing home non amb' 'workshop commercial'\n",
      " 'food/beverage hndlng' 'artist live/work' 'theater' 'school'\n",
      " 'tourist hotel/motel' 'filling/service stn' 'prkng garage/private'\n",
      " 'residential hotel' 'auto repairs' 'lending institution' 'vacant lot'\n",
      " 'church' 'storage shed' 'mortuary' 'clinics-medic/dental' 'manufacturing'\n",
      " 'animal sale or care' 'warehouse,no frnitur' 'misc group residns.'\n",
      " 'health studios & gym' 'sfpd or sffd station' 'parking lot'\n",
      " 'christmas tree lot' 'warehouse, furniture' 'dry cleaners' 'club'\n",
      " 'wholesale sales' 'recreation bldg' 'nite club' 'power plant'\n",
      " 'prkng garage/public' 'garment shops' 'massage parlor'\n",
      " 'day care home gt 12' 'barber/beauty salon' 'ambulance service' 'antenna'\n",
      " 'social care facility' 'public assmbly other' 'hospital'\n",
      " 'nursing home gt 6' 'museum' 'automobile sales' 'sound studio'\n",
      " 'laundry/laundromat' 'printing plant' 'day care center'\n",
      " 'radio & tv stations' 'library' 'nursery(floral)' 'moving & storage'\n",
      " 'greenhouse' 'stadium' 'sewage plant' 'amusement center' 'child care'\n",
      " 'dance hall' 'adult entertainment' 'muni carbarn' 'day care, non-res'\n",
      " 'phone xchnge/equip' 'jail' 'convalescent home' 'sign' 'storage tanks'\n",
      " 'tower' 'fence/retaining wall' 'day care home 7 - 12'\n",
      " 'nursing home lte 6' 'swimming pool' 'car wash' 'chemical processing'\n",
      " 'paint store' 'building materials' 'day care home lt 7'\n",
      " 'dairies/dairy equip.' \"prson'l svc tutor\" 'accessory cottage'\n",
      " 'muni driver restroom' 'meat/produce marts' 'temple'\n",
      " 'workshop residential' 'bath house' 'orphanage' 'r-3(dwg) nursing'\n",
      " 'roofing materials']\n",
      "\n",
      "Valores únicos en la columna Existing Units:\n",
      "[      nan 1.000e+00 2.000e+00 4.000e+00 3.000e+00 0.000e+00 2.900e+01\n",
      " 8.000e+00 6.000e+00 3.100e+01 5.300e+01 1.500e+01 2.580e+02 5.100e+01\n",
      " 9.200e+01 4.480e+02 5.000e+00 7.000e+00 1.860e+02 5.290e+02 3.600e+01\n",
      " 1.100e+01 1.300e+01 2.400e+01 1.200e+01 1.150e+02 7.200e+01 7.400e+01\n",
      " 1.610e+02 2.200e+01 3.700e+01 1.700e+02 6.000e+01 4.900e+01 8.200e+01\n",
      " 1.400e+01 6.500e+01 4.040e+02 1.800e+01 1.900e+01 1.910e+02 1.350e+02\n",
      " 1.560e+02 1.600e+01 8.800e+01 9.000e+00 2.800e+01 4.090e+02 1.000e+01\n",
      " 4.000e+01 1.980e+02 2.540e+02 7.600e+01 2.970e+02 5.800e+01 2.000e+01\n",
      " 1.390e+02 1.130e+02 2.980e+02 4.860e+02 3.900e+01 6.400e+01 4.200e+02\n",
      " 2.100e+01 1.420e+02 3.300e+01 1.600e+02 2.270e+02 1.280e+02 6.700e+01\n",
      " 2.330e+02 2.000e+02 3.000e+01 2.600e+01 2.300e+01 3.400e+01 1.260e+02\n",
      " 7.500e+01 1.100e+02 4.700e+01 2.700e+01 7.800e+01 1.500e+02 1.850e+02\n",
      " 1.170e+02 4.300e+01 1.160e+02 8.100e+01 4.500e+01 1.990e+02 7.000e+01\n",
      " 5.000e+01 1.070e+02 1.870e+02 2.390e+02 2.500e+02 5.440e+02 9.000e+01\n",
      " 1.700e+01 3.800e+01 2.180e+02 1.010e+03 8.700e+01 1.186e+03 6.900e+01\n",
      " 1.580e+02 1.010e+02 5.200e+01 1.040e+02 2.500e+01 6.850e+02 4.140e+02\n",
      " 5.900e+01 5.550e+02 3.200e+01 4.100e+01 2.880e+02 5.500e+01 4.200e+01\n",
      " 8.500e+01 6.100e+01 1.690e+02 8.400e+02 1.530e+02 1.900e+02 4.150e+02\n",
      " 5.540e+02 1.320e+02 1.140e+02 2.650e+02 5.400e+01 6.600e+01 3.290e+02\n",
      " 3.500e+01 1.300e+02 2.850e+02 6.690e+02 1.650e+02 4.400e+01 1.340e+02\n",
      " 1.080e+02 1.230e+02 1.550e+02 1.500e+03 8.400e+01 4.800e+01 2.960e+02\n",
      " 4.600e+01 1.540e+02 7.300e+01 9.800e+01 3.880e+02 3.930e+02 3.200e+02\n",
      " 1.200e+02 8.900e+01 1.060e+02 2.910e+02 6.300e+01 9.900e+01 3.560e+02\n",
      " 8.600e+01 3.150e+02 8.300e+01 9.600e+01 2.820e+02 2.060e+02 4.180e+02\n",
      " 1.380e+02 6.620e+02 6.800e+01 1.310e+02 5.600e+01 2.810e+02 1.920e+02\n",
      " 9.100e+01 1.450e+02 3.620e+02 4.470e+02 5.490e+02 2.730e+02 1.030e+02\n",
      " 8.000e+01 3.640e+02 1.620e+02 4.490e+02 1.370e+02 1.210e+02 2.340e+02\n",
      " 7.900e+01 1.120e+02 3.500e+02 3.000e+02 1.050e+02 1.960e+02 5.700e+01\n",
      " 2.600e+02 1.640e+02 1.730e+02 1.800e+02 1.490e+02 1.000e+02 2.020e+02\n",
      " 3.990e+02 7.100e+01 2.760e+02 2.080e+02 3.130e+02 1.400e+02 4.020e+02\n",
      " 1.220e+02 3.550e+02 1.270e+02 1.570e+02 2.400e+02 4.000e+02 5.470e+02\n",
      " 7.700e+01 4.080e+02 2.440e+02 3.040e+02 1.750e+02 1.360e+02 4.340e+02\n",
      " 1.907e+03 2.200e+02 2.570e+02 5.000e+02 6.200e+01 1.940e+02 3.300e+02\n",
      " 2.120e+02 1.740e+02 2.450e+02 2.790e+02 3.600e+02 4.310e+02 2.320e+02\n",
      " 1.470e+02 1.660e+02 4.050e+02 1.020e+02 1.510e+02 2.630e+02 2.990e+02\n",
      " 1.820e+02 1.880e+02 2.260e+02 2.590e+02 1.480e+02 2.680e+02 9.300e+01\n",
      " 2.360e+02 1.790e+02 9.500e+01 4.430e+02 7.190e+02 1.250e+02 9.700e+01\n",
      " 2.530e+02 1.005e+03 3.610e+02 1.110e+02 1.720e+02 1.430e+02 1.240e+02\n",
      " 4.170e+02 3.390e+02 4.100e+02 1.710e+02 9.400e+01 4.520e+02 4.400e+02\n",
      " 4.190e+02 7.540e+02 2.040e+02 1.680e+02 4.420e+02 1.330e+02 1.180e+02\n",
      " 2.550e+02 2.620e+02 1.732e+03 1.090e+02 4.160e+02 6.810e+02 7.200e+02\n",
      " 4.800e+02 1.290e+02 2.490e+02 4.500e+02 1.190e+02 3.900e+02 3.700e+02\n",
      " 1.460e+02 4.440e+02 2.430e+02 2.240e+02 3.240e+02 2.030e+02 3.480e+02\n",
      " 2.210e+02 9.480e+02 3.820e+02 3.250e+02 2.690e+02 2.050e+02 2.480e+02\n",
      " 4.030e+02 5.010e+02 1.440e+02 3.260e+02 1.000e+03 1.004e+03 1.830e+02\n",
      " 2.740e+02 5.430e+02 1.970e+02 1.890e+02 5.500e+02 2.470e+02 2.110e+02\n",
      " 1.590e+02 2.770e+02 2.890e+02 3.760e+02 1.930e+02 2.370e+02 1.950e+02\n",
      " 1.410e+02 5.460e+02 4.990e+02 6.700e+02 6.640e+02 3.000e-01 4.770e+02\n",
      " 7.220e+02 3.960e+02 1.780e+02 3.980e+02 5.120e+02 6.240e+02 5.510e+02\n",
      " 8.050e+02 1.499e+03 3.590e+02 5.400e+02 2.410e+02 6.740e+02]\n",
      "\n",
      "Valores únicos en la columna Proposed Use:\n",
      "[nan '1 family dwelling' '2 family dwelling' 'apartments' 'office'\n",
      " 'retail sales' 'nursing home non amb' 'workshop commercial'\n",
      " 'food/beverage hndlng' 'artist live/work' 'theater' 'school'\n",
      " 'tourist hotel/motel' 'filling/service stn' 'residential hotel'\n",
      " 'clinics-medic/dental' 'lending institution' 'church'\n",
      " 'prkng garage/private' 'mortuary' 'warehouse,no frnitur'\n",
      " 'animal sale or care' 'misc group residns.' 'greenhouse'\n",
      " 'public assmbly other' 'auto repairs' 'sfpd or sffd station'\n",
      " 'parking lot' 'christmas tree lot' 'vacant lot' 'club' 'child care'\n",
      " 'day care center' 'wholesale sales' 'recreation bldg'\n",
      " 'health studios & gym' 'nite club' 'power plant' 'prkng garage/public'\n",
      " 'barber/beauty salon' 'day care home gt 12' 'manufacturing'\n",
      " 'ambulance service' 'antenna' 'laundry/laundromat' 'social care facility'\n",
      " 'storage shed' 'hospital' 'nursing home gt 6' 'museum' 'automobile sales'\n",
      " 'sound studio' 'printing plant' 'radio & tv stations' 'library'\n",
      " 'massage parlor' 'moving & storage' 'stadium' 'warehouse, furniture'\n",
      " 'sewage plant' 'amusement center' 'garment shops' 'phone xchnge/equip'\n",
      " 'dance hall' 'nursery(floral)' 'muni carbarn' 'day care, non-res'\n",
      " 'dry cleaners' 'jail' 'accessory cottage' 'convalescent home' 'car wash'\n",
      " 'sign' 'storage tanks' 'tower' 'fence/retaining wall'\n",
      " 'day care home 7 - 12' 'workshop residential' \"prson'l svc tutor\"\n",
      " 'adult entertainment' 'muni driver restroom' 'nursing home lte 6'\n",
      " 'swimming pool' 'chemical processing' 'paint store' 'building materials'\n",
      " 'bath house' 'day care home lt 7' 'dairies/dairy equip.'\n",
      " 'meat/produce marts' 'temple' 'orphanage' 'r-3(dwg) nursing'\n",
      " 'roofing materials' 'not applicable']\n",
      "\n",
      "Valores únicos en la columna Proposed Units:\n",
      "[      nan 1.000e+00 2.000e+00 4.000e+00 3.000e+00 0.000e+00 9.000e+00\n",
      " 2.900e+01 8.000e+00 6.000e+00 3.100e+01 5.300e+01 1.500e+01 2.580e+02\n",
      " 5.100e+01 9.200e+01 4.480e+02 5.000e+00 7.000e+00 1.860e+02 5.290e+02\n",
      " 3.600e+01 1.100e+01 1.300e+01 2.400e+01 1.200e+01 1.150e+02 7.200e+01\n",
      " 7.400e+01 1.610e+02 1.900e+01 2.600e+01 3.700e+01 1.700e+02 5.500e+02\n",
      " 6.000e+01 4.900e+01 8.200e+01 1.400e+01 6.500e+01 4.040e+02 1.800e+01\n",
      " 1.910e+02 1.350e+02 1.560e+02 5.200e+01 1.600e+01 8.800e+01 4.090e+02\n",
      " 1.000e+01 4.000e+01 1.980e+02 2.540e+02 7.600e+01 2.970e+02 5.800e+01\n",
      " 2.000e+01 1.390e+02 2.100e+01 1.130e+02 2.980e+02 4.860e+02 3.900e+01\n",
      " 6.400e+01 4.200e+02 1.420e+02 3.300e+01 1.600e+02 2.270e+02 1.380e+02\n",
      " 1.280e+02 6.700e+01 2.330e+02 2.800e+01 2.000e+02 3.000e+01 2.300e+01\n",
      " 3.400e+01 1.820e+02 1.260e+02 7.500e+01 1.100e+02 4.700e+01 2.700e+01\n",
      " 7.800e+01 1.500e+02 1.850e+02 1.170e+02 2.200e+01 4.300e+01 1.160e+02\n",
      " 8.100e+01 4.500e+01 2.030e+02 7.000e+01 5.000e+01 1.070e+02 1.870e+02\n",
      " 2.390e+02 2.500e+02 1.700e+01 4.080e+02 5.440e+02 9.000e+01 3.800e+01\n",
      " 2.180e+02 2.590e+02 1.010e+03 8.700e+01 1.186e+03 6.900e+01 2.960e+02\n",
      " 1.580e+02 1.010e+02 9.400e+01 7.900e+01 1.040e+02 2.500e+01 8.500e+01\n",
      " 4.310e+02 2.250e+02 6.850e+02 4.140e+02 5.900e+01 5.550e+02 3.200e+01\n",
      " 4.100e+01 2.880e+02 5.500e+01 4.200e+01 8.900e+01 6.100e+01 1.690e+02\n",
      " 8.400e+02 2.800e+02 1.530e+02 1.900e+02 4.150e+02 5.540e+02 1.320e+02\n",
      " 1.140e+02 5.400e+01 2.730e+02 6.600e+01 3.290e+02 3.500e+01 1.310e+02\n",
      " 2.850e+02 6.690e+02 1.650e+02 4.400e+01 1.340e+02 1.080e+02 1.720e+02\n",
      " 1.230e+02 1.550e+02 1.500e+03 8.400e+01 4.340e+02 1.300e+02 4.800e+01\n",
      " 4.600e+01 2.620e+02 1.540e+02 7.300e+01 9.800e+01 3.880e+02 3.930e+02\n",
      " 3.200e+02 1.200e+02 1.060e+02 9.300e+01 2.910e+02 6.300e+01 9.900e+01\n",
      " 3.560e+02 8.600e+01 3.150e+02 8.300e+01 9.600e+01 2.820e+02 2.060e+02\n",
      " 4.180e+02 6.620e+02 1.620e+02 6.800e+01 5.600e+01 2.810e+02 2.080e+02\n",
      " 9.500e+01 1.920e+02 9.100e+01 1.450e+02 3.620e+02 4.470e+02 5.490e+02\n",
      " 1.030e+02 8.000e+01 1.430e+02 3.640e+02 4.490e+02 1.370e+02 1.210e+02\n",
      " 2.340e+02 1.120e+02 3.500e+02 3.000e+02 1.050e+02 1.960e+02 5.700e+01\n",
      " 2.600e+02 1.640e+02 1.730e+02 1.990e+02 1.800e+02 1.490e+02 1.000e+02\n",
      " 2.020e+02 1.740e+02 3.990e+02 7.100e+01 2.760e+02 3.130e+02 1.400e+02\n",
      " 4.020e+02 1.220e+02 3.610e+02 1.270e+02 1.570e+02 1.110e+02 1.090e+02\n",
      " 2.400e+02 4.000e+02 5.470e+02 1.360e+02 7.700e+01 2.440e+02 3.040e+02\n",
      " 1.750e+02 1.907e+03 2.200e+02 2.630e+02 5.460e+02 2.570e+02 5.000e+02\n",
      " 6.200e+01 1.940e+02 2.560e+02 3.300e+02 2.120e+02 2.450e+02 2.790e+02\n",
      " 3.600e+02 4.030e+02 2.320e+02 1.470e+02 1.660e+02 4.050e+02 4.790e+02\n",
      " 1.020e+02 1.510e+02 2.990e+02 1.880e+02 2.260e+02 1.480e+02 1.290e+02\n",
      " 3.900e+02 2.680e+02 3.190e+02 3.840e+02 5.400e+02 2.360e+02 1.790e+02\n",
      " 4.440e+02 1.250e+02 9.700e+01 2.530e+02 1.014e+03 1.005e+03 4.700e+02\n",
      " 1.240e+02 1.520e+02 4.170e+02 3.390e+02 4.100e+02 1.710e+02 6.740e+02\n",
      " 1.680e+02 4.520e+02 3.510e+02 4.400e+02 2.670e+02 4.190e+02 7.540e+02\n",
      " 2.040e+02 5.450e+02 4.420e+02 1.330e+02 1.180e+02 2.550e+02 2.650e+02\n",
      " 1.950e+02 1.732e+03 5.280e+02 4.160e+02 6.810e+02 7.190e+02 4.010e+02\n",
      " 7.220e+02 1.890e+02 2.490e+02 2.300e+02 2.130e+02 4.500e+02 1.190e+02\n",
      " 3.700e+02 1.460e+02 2.430e+02 2.240e+02 5.010e+02 3.240e+02 3.480e+02\n",
      " 3.160e+02 2.210e+02 9.480e+02 3.820e+02 3.250e+02 2.690e+02 2.050e+02\n",
      " 2.480e+02 3.260e+02 4.750e+02 1.440e+02 1.000e+03 1.830e+02 2.740e+02\n",
      " 5.430e+02 1.970e+02 7.200e+02 2.470e+02 2.110e+02 1.590e+02 3.030e+02\n",
      " 2.770e+02 2.890e+02 5.040e+02 3.760e+02 1.930e+02 2.370e+02 1.410e+02\n",
      " 4.990e+02 6.760e+02 6.700e+02 6.640e+02 3.550e+02 4.770e+02 3.960e+02\n",
      " 1.780e+02 3.980e+02 5.120e+02 6.240e+02 3.120e+02 5.510e+02 1.499e+03\n",
      " 3.590e+02 1.911e+03 3.050e+02 1.199e+03 2.410e+02]\n",
      "\n",
      "Valores únicos en la columna Plansets:\n",
      "[   nan 2.e+00 0.e+00 3.e+00 4.e+00 2.e+01 9.e+03 6.e+00 1.e+00]\n",
      "\n",
      "Valores únicos en la columna TIDF Compliance:\n",
      "[nan 'P' 'Y']\n",
      "\n",
      "Valores únicos en la columna Existing Construction Type:\n",
      "[        nan  5.0000e+00  3.0000e+00  1.0000e+00  2.0000e+00  4.0000e+00\n",
      " -9.9999e+04  9.9999e+04]\n",
      "\n",
      "Valores únicos en la columna Existing Construction Type Description:\n",
      "[nan 'wood frame (5)' 'constr type 3' 'constr type 1' 'constr type 2'\n",
      " 'constr type 4' ' constr type 1 ' ' constr type 3 ' ' wood frame (5) ']\n",
      "\n",
      "Valores únicos en la columna Proposed Construction Type:\n",
      "[nan  5.  3.  2.  1.  4.]\n",
      "\n",
      "Valores únicos en la columna Proposed Construction Type Description:\n",
      "[nan 'wood frame (5)' 'constr type 3' 'constr type 2' 'constr type 1'\n",
      " 'constr type 4']\n",
      "\n",
      "Valores únicos en la columna Site Permit:\n",
      "[nan 'Y']\n",
      "\n",
      "Valores únicos en la columna Supervisor District:\n",
      "['3.0' '4.0' '9.0' '5.0' '8.0' '2.0' '6.0' '10.0' '1.0' '7.0' '11.0' nan\n",
      " 'quince' 7.0 5.0 3.0 11.0 4.0 8.0 2.0 9.0 6.0 1.0 10.0 'veinte' 'diez']\n",
      "\n",
      "Valores únicos en la columna Neighborhoods - Analysis Boundaries:\n",
      "['Nob Hill' 'Sunset/Parkside' 'Bernal Heights' 'Pacific Heights' 'Mission'\n",
      " 'Castro/Upper Market' 'Financial District/South Beach' 'Chinatown'\n",
      " 'South of Market' 'Inner Richmond' 'Bayview Hunters Point'\n",
      " 'Outer Richmond' 'Marina' 'North Beach' 'Russian Hill' 'Haight Ashbury'\n",
      " 'Presidio Heights' 'Glen Park' 'West of Twin Peaks' 'Excelsior'\n",
      " 'Noe Valley' 'Potrero Hill' 'Twin Peaks' 'Seacliff' 'Hayes Valley'\n",
      " 'Western Addition' 'Outer Mission' 'Inner Sunset'\n",
      " 'Oceanview/Merced/Ingleside' 'Tenderloin' 'Lakeshore' 'Lone Mountain/USF'\n",
      " 'Mission Bay' nan 'Visitacion Valley' 'Portola' 'Japantown'\n",
      " 'McLaren Park' 'Treasure Island' 'Lincoln Park' 'Presidio'\n",
      " 'Golden Gate Park']\n",
      "\n",
      "Valores únicos en la columna Zipcode:\n",
      "[94109. 94122. 94110. 94115. 94114. 94105. 94111. 94107. 94118. 94124.\n",
      " 94108. 94121. 94123. 94133. 94117. 94131. 94127. 94103. 94132. 94112.\n",
      " 94116. 94102. 94158. 94104.    nan 94134. 94130. 94129.]\n",
      "\n",
      "Valores únicos en la columna Location:\n",
      "['(37.79362102799777, -122.41488237355445)'\n",
      " '(37.759041020475465, -122.50286985467523)'\n",
      " '(37.73778863007536, -122.41197863877355)' ...\n",
      " '(37.759969704877626, -122.49117697122442)'\n",
      " '(37.71192805393076, -122.4500944316179)'\n",
      " '(37.75260530951628, -122.40400191084352)']\n",
      "\n",
      "Valores únicos en la columna Record ID:\n",
      "[1464153232862 1306559115258 1462579187173 ... 1431897172643 1449660232064\n",
      " 1420790164534]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los valores únicos y vacios para cada columna\n",
    "for column in df.columns:\n",
    "    valores_unicos = df[column].unique()\n",
    "    print(f'\\nValores únicos en la columna {column}:')\n",
    "    print(valores_unicos)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Cuantificar los valores únicos del punto e) y realizar histogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Directorio donde se guardarán los histogramas\n",
    "output_dir = \"histogramas\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Crea el directorio si no existe\n",
    "valores_discretos = ['Permit Type','Permit Type Definition','Current Status', 'Fire Only Permit','TIDF Compliance', 'Existing Construction Type','Existing Construction Type Description','Proposed Construction Type','Proposed Construction Type Description']\n",
    "\n",
    "\n",
    "for column in valores_discretos:\n",
    "    try:\n",
    "        value_counts = df[column].value_counts()\n",
    "\n",
    "        plt.rcParams['font.family'] = 'Arial'\n",
    "        plt.figure(figsize=(16, 14))\n",
    "        plt.barh(value_counts.index, value_counts.values)\n",
    "        plt.title(f'Histograma de {column}')\n",
    "        plt.xlabel('Frecuencia')\n",
    "        plt.ylabel(column)\n",
    "\n",
    "        # Ruta completa del archivo de salida\n",
    "        output_file = os.path.join(output_dir, f\"histograma_{column}.png\")\n",
    "        plt.savefig(output_file)  # Guardar el gráfico en un archivo\n",
    "        plt.close()  # Cerrar la figura para liberar memoria\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la columna {column}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Evaluar la existencia de datos inconsistentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent data found:\n",
      "Column: Supervisor District\n",
      "Inconsistent values: \n",
      "16384      7.0\n",
      "16385      5.0\n",
      "16386      7.0\n",
      "16387      3.0\n",
      "16388     11.0\n",
      "          ... \n",
      "198905     7.0\n",
      "198906    10.0\n",
      "198907    10.0\n",
      "198908     3.0\n",
      "198909     6.0\n",
      "Name: Supervisor District, Length: 148505, dtype: object\n",
      "\n",
      "Datos inconsistentes en la columna 'Supervisor District':\n",
      "2284      quince\n",
      "97312     veinte\n",
      "126129      diez\n",
      "Name: Supervisor District, dtype: object\n",
      "\n",
      "16370    201708043992\n",
      "16371    201611283518\n",
      "16372    201301248729\n",
      "16373    201510291136\n",
      "16374    201701207526\n",
      "16375    201308063640\n",
      "16376    201303263045\n",
      "16377    201602169707\n",
      "16378    201612024057\n",
      "16379    201510230706\n",
      "16380    201705318008\n",
      "16381         M461987\n",
      "16382    201502188590\n",
      "16383         M585487\n",
      "16384    201504163759\n",
      "16385    201505015115\n",
      "16386    201302049375\n",
      "16387    201306058703\n",
      "16388    201504284796\n",
      "16389    201408042919\n",
      "Name: Permit Number, dtype: object\n",
      "Tipos de datos de las columnas:\n",
      "Permit Number                              object\n",
      "Permit Type                                 int64\n",
      "Permit Type Definition                     object\n",
      "Permit Creation Date                       object\n",
      "Block                                      object\n",
      "Lot                                        object\n",
      "Street Number                             float64\n",
      "Street Number Suffix                       object\n",
      "Street Name                                object\n",
      "Street Suffix                              object\n",
      "Unit                                      float64\n",
      "Unit Suffix                                object\n",
      "Description                                object\n",
      "Current Status                             object\n",
      "Current Status Date                        object\n",
      "Filed Date                                 object\n",
      "Issued Date                                object\n",
      "Completed Date                             object\n",
      "First Construction Document Date           object\n",
      "Structural Notification                    object\n",
      "Number of Existing Stories                float64\n",
      "Number of Proposed Stories                float64\n",
      "Voluntary Soft-Story Retrofit              object\n",
      "Fire Only Permit                           object\n",
      "Permit Expiration Date                     object\n",
      "Estimated Cost                            float64\n",
      "Revised Cost                              float64\n",
      "Existing Use                               object\n",
      "Existing Units                            float64\n",
      "Proposed Use                               object\n",
      "Proposed Units                            float64\n",
      "Plansets                                  float64\n",
      "TIDF Compliance                            object\n",
      "Existing Construction Type                float64\n",
      "Existing Construction Type Description     object\n",
      "Proposed Construction Type                float64\n",
      "Proposed Construction Type Description     object\n",
      "Site Permit                                object\n",
      "Supervisor District                        object\n",
      "Neighborhoods - Analysis Boundaries        object\n",
      "Zipcode                                   float64\n",
      "Location                                   object\n",
      "Record ID                                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "inconsistent_data = []\n",
    "\n",
    "# Check for inconsistent data in numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "for column in numeric_columns:\n",
    "    inconsistent_values = df[column].loc[pd.to_numeric(df[column], errors='coerce').isna() & df[column].notna()]\n",
    "    if not inconsistent_values.empty:\n",
    "        inconsistent_data.append((column, inconsistent_values))\n",
    "\n",
    "# Check for inconsistent data in categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    inconsistent_values = df[column].loc[~df[column].apply(lambda x: isinstance(x, str)) & df[column].notna()]\n",
    "    if not inconsistent_values.empty:\n",
    "        inconsistent_data.append((column, inconsistent_values))\n",
    "\n",
    "# Print the inconsistent data\n",
    "if inconsistent_data:\n",
    "    print(\"Inconsistent data found:\")\n",
    "    for column, values in inconsistent_data:\n",
    "        print(f\"Column: {column}\")\n",
    "        print(f\"Inconsistent values: \\n{values}\\n\")\n",
    "else:\n",
    "    print(\"No inconsistent data found.\")\n",
    "\n",
    "\n",
    "# Filtrar y mostrar los datos inconsistentes en la columna 'Supervisor District' \n",
    "inconsistent_supervisor_district = df['Supervisor District'].loc[\n",
    "    pd.to_numeric(df['Supervisor District'], errors='coerce').isna() & df['Supervisor District'].notna()\n",
    "]\n",
    "\n",
    "print(\"Datos inconsistentes en la columna 'Supervisor District':\")\n",
    "print(inconsistent_supervisor_district)\n",
    "\n",
    "print()\n",
    "\n",
    "# Mostrar un rango de filas alrededor de la fila 16384\n",
    "print(df['Permit Number'].iloc[16370:16390])\n",
    "\n",
    "print(\"Tipos de datos de las columnas:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Permit Number\":\n",
      "['M788927' '201305318356' '201705106205' ... '201607293741' '201701066691'\n",
      " '201604255599']\n",
      "Cantidad de valores NaN en la columna \"Permit Number\": 0\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Permit Number\n",
    "valores_unicos = df['Permit Number'].unique()\n",
    "print('Valores únicos en \"Permit Number\":')\n",
    "print(valores_unicos)\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Permit Number'\n",
    "nan_count = df['Permit Number'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Permit Number\": {nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Permit Number\":\n",
      "['201410279983' '201307161925' 'M501607' ... '201305015888' 'M479567'\n",
      " '201507080907']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Permit Number\n",
    "duplicados = df[df.duplicated(subset=['Permit Number'], keep=False)]\n",
    "print('Valores duplicados en \"Permit Number\":')\n",
    "print(duplicados['Permit Number'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta primer columna de Permit Number se dejó así ya que no habían valores NaN. Los duplicados se dejan para analizar luego de analizar todas las demás variables para comparar toda la fila entera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Permit Type\":\n",
      "[8 2 4 3 6 1 7 5]\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Permit Type\n",
    "duplicados = df[df.duplicated(subset=['Permit Type'], keep=False)]\n",
    "print('Valores duplicados en \"Permit Type\":')\n",
    "print(duplicados['Permit Type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la columna Permit Type no parecen haber inconsistencias ya que efectivamente el tipo de permiso se representa numericamente y no faltan datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Permit Type Definition\":\n",
      "['otc alterations permit' 'new construction wood frame' 'sign - erect'\n",
      " 'additions alterations or repairs' 'demolitions' 'new construction'\n",
      " 'wall or painted sign' 'grade or quarry or fill or excavate'\n",
      " ' otc alterations permit ' ' new construction '\n",
      " 'otc alterations permit #' 'new construction #'\n",
      " ' additions alterations or repairs ']\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Permit Type Definition\n",
    "valores_unicos = df['Permit Type Definition'].unique()\n",
    "print('Valores únicos en \"Permit Type Definition\":')\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de duplicados con el valor \"otc alterations permit #\": 0\n"
     ]
    }
   ],
   "source": [
    "# Filtrar las filas que tienen el valor 'otc alterations permit #' en la columna Permit Type Definition\n",
    "filtrados = df[df['Permit Type Definition'] == 'otc alterations permit #']\n",
    "\n",
    "# Contar cuántos de esos registros son duplicados\n",
    "duplicados = filtrados.duplicated().sum()\n",
    "\n",
    "print(f'Cantidad de duplicados con el valor \"otc alterations permit #\": {duplicados}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Permit Type Definition\":\n",
      "['otc alterations permit' 'new construction wood frame' 'sign - erect'\n",
      " 'additions alterations or repairs' 'demolitions' 'new construction'\n",
      " 'wall or painted sign' 'grade or quarry or fill or excavate'\n",
      " ' otc alterations permit ' 'otc alterations permit #'\n",
      " 'new construction #']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Permit Type Definition\n",
    "duplicados = df[df.duplicated(subset=['Permit Type Definition'], keep=False)]\n",
    "print('Valores duplicados en \"Permit Type Definition\":')\n",
    "print(duplicados['Permit Type Definition'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de veces que aparece \"otc alterations permit\": 178836\n",
      "Cantidad de veces que aparece \"otc alterations permit #\": 8\n"
     ]
    }
   ],
   "source": [
    "# Contar cuántas veces aparece el valor 'otc alterations permit' en la columna Permit Type Definition\n",
    "cantidad = df['Permit Type Definition'].value_counts().get('otc alterations permit', 0)\n",
    "\n",
    "print(f'Cantidad de veces que aparece \"otc alterations permit\": {cantidad}')\n",
    "\n",
    "# Contar cuántas veces aparece el valor 'otc alterations permit #' en la columna Permit Type Definition\n",
    "cantidad = df['Permit Type Definition'].value_counts().get('otc alterations permit #', 0)\n",
    "\n",
    "print(f'Cantidad de veces que aparece \"otc alterations permit #\": {cantidad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos después de la corrección en \"Permit Type Definition\":\n",
      "['otc alterations permit' 'new construction wood frame' 'sign - erect'\n",
      " 'additions alterations or repairs' 'demolitions' 'new construction'\n",
      " 'wall or painted sign' 'grade or quarry or fill or excavate']\n"
     ]
    }
   ],
   "source": [
    "# Eliminar espacios al principio y al final, y eliminar asteriscos en la columna Permit Type Definition\n",
    "df['Permit Type Definition'] = df['Permit Type Definition'].str.replace('#', '', regex=False)\n",
    "df['Permit Type Definition'] = df['Permit Type Definition'].str.strip()\n",
    "\n",
    "# Verificar los valores únicos después de la corrección\n",
    "valores_corregidos = df['Permit Type Definition'].unique()\n",
    "print('Valores únicos después de la corrección en \"Permit Type Definition\":')\n",
    "print(valores_corregidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los valores de la columna 'Permit Type Definition' no habían valores vacíos, pero si datos inconsistentes como espacios o '#' en algunos casos. En el caso de los valores que terminaban con '#', se contaron cuantas veces estaban sin y cuantas con. Como eran significativamente más los que no tenían el '#' se decidió quitar el '#'. Por lo tanto, se eliminaron estos espacios al principio y al final de los registros así como también los '#' que tenían algunos registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Permit Creation Date\":\n",
      "['05/23/2017' '05/31/2013' '05/10/2017' ... '2017-02-10' '2016-11-14'\n",
      " '2013-03-06']\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Permit Creation Date\n",
    "valores_unicos = df['Permit Creation Date'].unique()\n",
    "print('Valores únicos en \"Permit Creation Date\":')\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Permit Creation Date\":\n",
      "['05/23/2017' '05/31/2013' '05/10/2017' ... '02/04/2016' '11/17/2015'\n",
      " '03/28/2012']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Permit Creation Date\n",
    "duplicados = df[df.duplicated(subset=['Permit Creation Date'], keep=False)]\n",
    "print('Valores duplicados en \"Permit Creation Date\":')\n",
    "print(duplicados['Permit Creation Date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\3837153806.py:5: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Permit Creation Date'] = pd.to_datetime(df['Permit Creation Date'], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos después de la conversión en \"Permit Creation Date\":\n",
      "['23/05/2017' '31/05/2013' '10/05/2017' ... nan '26/12/2012' '28/03/2012']\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar guiones '-' por barras '/' en la columna 'Permit Creation Date'\n",
    "df['Permit Creation Date'] = df['Permit Creation Date'].str.replace('-', '/')\n",
    "\n",
    "# Intentar convertir las fechas al formato de pandas, ignorando errores\n",
    "df['Permit Creation Date'] = pd.to_datetime(df['Permit Creation Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Formatear todas las fechas al formato 'DD/MM/YYYY'\n",
    "df['Permit Creation Date'] = df['Permit Creation Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Verificar los valores únicos después de la conversión\n",
    "valores_unicos_fechas = df['Permit Creation Date'].unique()\n",
    "print('Valores únicos después de la conversión en \"Permit Creation Date\":')\n",
    "print(valores_unicos_fechas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores NaN en la columna \"Permit Creation Date\": 5\n",
      "First Construction Document Date, Current Status, Current Status Date \n",
      "       First Construction Document Date Current Status Current Status Date\n",
      "20528                        08/08/2016       complete          12/15/2016\n",
      "63125                        10/23/2013       complete          12/02/2013\n",
      "63135                        03/09/2017         issued          03/09/2017\n",
      "65326                        11/14/2016         issued          11/14/2016\n",
      "169478                       03/06/2013       complete          11/12/2013\n"
     ]
    }
   ],
   "source": [
    "# Contar la cantidad de valores NaN en la columna 'Permit Creation Date'\n",
    "nan_count = df['Permit Creation Date'].isna().sum()\n",
    "\n",
    "# Filtrar los registros con valores NaN en la columna 'Permit Creation Date'\n",
    "nan_en_columna = df[df['Permit Creation Date'].isna()]\n",
    "\n",
    "# Seleccionar las columnas de interés para estos registros\n",
    "result = nan_en_columna[['First Construction Document Date', 'Current Status', 'Current Status Date']]\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'Cantidad de valores NaN en la columna \"Permit Creation Date\": {nan_count}')\n",
    "if (nan_count > 0):\n",
    "    print(f'First Construction Document Date, Current Status, Current Status Date \\n{result}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Permit Creation Date First Construction Document Date\n",
      "0           23/05/2017                       05/23/2017\n",
      "1           31/05/2013                       06/03/2013\n",
      "2           10/05/2017                       05/11/2017\n",
      "3           27/10/2014                       10/27/2014\n",
      "4           28/10/2013                       10/28/2013\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar los valores NaN en 'Permit Creation Date' con los valores de 'First Construction Document Date'\n",
    "df['Permit Creation Date'] = df['Permit Creation Date'].fillna(df['First Construction Document Date'])\n",
    "\n",
    "# Verificar los cambios\n",
    "print(df[['Permit Creation Date', 'First Construction Document Date']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los valores de la columna 'Permit Creation Date' no se tuvieron que agregar datos ya que no faltaba ninguno. Lo que sí se cambio fue el formato de algunas fechas, ya que algunas estaban con '-' y otras con '/'. Además, a los pocos valores que eran 'NaN' (5), se les colocó la fecha del primer documento de construcción para tener una fecha aproximada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Block\":\n",
      "['0215' '1810' '5700' ... '4976' '6125' '6757']\n",
      "Cantidad de valores NaN en la columna \"Block\": 0\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Block\n",
    "valores_unicos = df['Block'].unique()\n",
    "print('Valores únicos en \"Block\":')\n",
    "print(valores_unicos)\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Block'\n",
    "nan_count = df['Block'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Block\": {nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Block\":\n",
      "['0215' '1810' '5700' ... '0256T' '5394' '5695']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Block\n",
    "duplicados = df[df.duplicated(subset=['Block'], keep=False)]\n",
    "print('Valores duplicados en \"Block\":')\n",
    "print(duplicados['Block'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los valores de la columna Block, no se cambió nada ya que no faltaban datos y no hay valores 'NaN', pareciendo estar sus valores correctos. Algunos tienen una letra pero puede llegar a ser parte de su dirección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Lot\":\n",
      "['001' '017A' '027' ... '018X' '031H' '030E']\n",
      "Cantidad de valores NaN en la columna \"Lot\": 0\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Lot\n",
    "valores_unicos = df['Lot'].unique()\n",
    "print('Valores únicos en \"Lot\":')\n",
    "print(valores_unicos)\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Lot'\n",
    "nan_count = df['Lot'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Lot\": {nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Lot\":\n",
      "['001' '017A' '027' '005' '051A' '076' '007' '009' '029' '090' '052'\n",
      " '016A' '058' '016' '037' '045' '004' '042' '002' '022' '012' '011' '028'\n",
      " '008' '021' '102' '026' '008B' '108' '020' '043A' '035' '003' '023' '006'\n",
      " '063' '017' '001P' '061' '160' '001X' '070' '009A' '043' '033' '018'\n",
      " '047' '036' '031' '030' '032' '014' '041' '001R' '163' '018B' '010' '046'\n",
      " '056' '073' '013' '074' '065A' '029B' '019' '015' '008A' '079' '024'\n",
      " '086' '038' '025' '031A' '060' '057' '001F' '010A' '001C' '053' '050'\n",
      " '040' '039' '044' '231' '003A' '049' '034' '093' '064' '001A' '080'\n",
      " '033A' '015A' '048' '002A' '640' '098' '123' '001D' '005B' '308' '067'\n",
      " '055' '147' '022A' '007A' '127' '081' '041A' '324' '068' '065' '066'\n",
      " '002O' '020A' '094' '211' '046A' '026A' '013B' '051' '120' '141' '001B'\n",
      " '112' '095' '009C' '157' '248' '077' '010E' '020C' '014A' '355' '183'\n",
      " '125' '118' '078' '003B' '251' '182' '137' '088' '010H' '238' '003N'\n",
      " '024A' '054D' '004B' '277' '250' '012A' '109' '082' '027A' '002D' '008F'\n",
      " '002G' '219' '006G' '119' '001G' '054' '103' '240' '415' '012E' '019A'\n",
      " '005A' '072' '122' '999' '040B' '274' '017I' '023A' '011A' '031B' '177'\n",
      " '089' '027B' '003D' '128' '162' '106' '096' '110' '062' '083' '059' '131'\n",
      " '099' '196' '015C' '021A' '179' '013C' '190' '018D' '136' '002C' '020B'\n",
      " '178' '024B' '075' '009D' '028A' '323' '019C' '014C' '015B' '132' '092'\n",
      " '013A' '006F' '104' '005D' '017B' '038A' '566' '002I' '143' '500' '006A'\n",
      " '025A' '200' '114' '071' '144' '002B' '069' '002H' '001Q' '085' '001O'\n",
      " '001H' '087' '205' '035A' '101' '006E' '008E' '097' '005H' '016B' '018A'\n",
      " '040H' '016I' '176' '016E' '116' '172' '113' '107' '019B' '140' '048A'\n",
      " '003O' '134' '029A' '009G' '233' '267' '001E' '006B' '001I' '002N' '154'\n",
      " '117' '018C' '007D' '367' '121' '004D' '002L' '008C' '145' '004A' '045A'\n",
      " '007C' '091' '105' '188' '049A' '158' '013G' '037B' '054C' '041B' '608'\n",
      " '036A' '025D' '175' '011B' '022L' '037A' '259' '227' '007F' '074A' '014G'\n",
      " '001T' '208' '016F' '007P' '168' '001W' '210' '129' '115' '126' '008D'\n",
      " '013D' '006C' '186' '062A' '003C' '124' '084' '001J' '150' '447' '005C'\n",
      " '004P' '004C' '407' '239' '307' '004E' '181' '503' '020D' '002E' '455'\n",
      " '171' '004G' '156' '016D' '169' '019D' '610' '148' '111' '025B' '005K'\n",
      " '405' '009J' '014B' '005I' '003I' '001K' '271' '009B' '006D' '022D' '151'\n",
      " '187' '152' '006J' '229' '041C' '019E' '027D' '030A' '002J' '023B' '004H'\n",
      " '005F' '007B' '004R' '019G' '166' '133' '614' '002Q' '042A' '138' '320'\n",
      " '192' '012D' '213' '003G' '161' '859' '002F' '278' '270' '034A' '020E'\n",
      " '241' '032A' '012B' '007E' '155' '029C' '326' '279' '130' '193' '039B'\n",
      " '069B' '032F' '257' '365' '034U' '234' '000' '295' '314' '174' '018H'\n",
      " '525' '003M' '322' '243' '266' '306' '020G' '007H' '022P' '021B' '003F'\n",
      " '017E' '273' '325' '165' '022B' '135' '047A' '005E' '100' '018K' '017D'\n",
      " '631' '264' '028B' '167' '209' '364' '047B' '194' '372' '007G' '607'\n",
      " '004J' '153' '223' '039A' '022C' '001L' '040A' '017G' '236' '185' '456'\n",
      " '010D' '200A' '018W' '014D' '203' '225' '009F' '043E' '627' '390' '035B'\n",
      " '146' '006M' '036B' '226' '014E' '022R' '235' '012C' '001U' '011C' '010Q'\n",
      " '021F' '021D' '247' '001V' '018I' '349' '018V' '010G' '195' '022T' '006Q'\n",
      " '412' '001M' '040C' '507' '472' '092A' '014F' '024C' '009I' '024L' '004F'\n",
      " '001N' '197' '003R' '034B' '015J' '032J' '216' '217' '010B' '214' '008L'\n",
      " '032D' '002V' '013F' '180' '972' '016C' '170' '043C' '034V' '745' '044A'\n",
      " '974' '218' '353' '003H' '003E' '008K' '007I' '159' '003K' '002P' '402'\n",
      " '044B' '015D' '004L' '015E' '646' '018G' '380' '077A' '011D' '237' '070A'\n",
      " '280' '024E' '354' '010C' '142' '034F' '001S' '006I' '448' '228' '003J'\n",
      " '220' '199' '561' '352' '189' '496' '318' '198' '002K' '224' '438' '014H'\n",
      " '039C' '004I' '212' '011E' '252' '073A' '005J' '053A' '005G' '023E' '204'\n",
      " '611' '230' '005N' '263' '207' '311' '049B' '006O' '024K' '010F' '139'\n",
      " '282' '049G' '028C' '007J' '018E' '022G' '609' '283' '005Q' '017F' '378'\n",
      " '244' '054A' '035C' '726' '024G' '441' '394' '201' '025E' '002Y' '055B'\n",
      " '049N' '005M' '559' '017C' '012F' '012J' '265' '023C' '191' '305' '313'\n",
      " '028H' '089A' '047C' '011F' '002M' '003P' '025C' '034C' '173' '0060'\n",
      " '026C' '026B' '291' '164' '002R' '049F' '046B' '007S' '268' '007K' '254'\n",
      " '012I' '016J' '149' '005L' '423' '221' '033D' '300' '206' '347' '026D'\n",
      " '294' '013E' '858' '454' '016G' '696' '032B' '004Q' '232' '016T' '022E'\n",
      " '342' '290' '424' '310' '369' '032C' '381' '003Q' '030B' '065G' '009Y'\n",
      " '002S' '021E' '009R' '049J' '012G' '184' '004M' '272' '255' '100A' '060A'\n",
      " '335' '052A' '018F' '332' '016M' '030C' '034S' '002T' '697' '258' '002W'\n",
      " '377' '304' '245' '406' '027C' '049P' '720' '433' '006K' '057A' '010N'\n",
      " '021C' '246' '025F' '007M' '321' '086A' '055A' '022H' '536' '303' '067A'\n",
      " '633' '296' '007N' '973' '024M' '031K' '008G' '016L' '413' '843' '288'\n",
      " '222' '004N' '008S' '495' '052J' '648' '725' '449' '242' '003L' '202'\n",
      " '004K' '302' '399' '009E' '421' '737' '215' '018Q' '368' '015G' '009H'\n",
      " '494' '346' '420' '018J' '058A' '009N' '0172' '006H' '087A' '312' '410'\n",
      " '357' '032E' '021L' '076A' '411' '297' '024F' '261' '018S' '385' '276'\n",
      " '435' '492' '007R' '338' '309' '044D' '530' '301' '040D' '446' '499'\n",
      " '351' '505' '035D' '009M' '256' '344' '090B' '328' '386' '902' '022F'\n",
      " '391' '064A' '043B' '331' '659' '033B' '461' '298' '253' '044C' '009O'\n",
      " '019I' '017N' '017J' '506' '041D' '063A' '339' '031C' '348' '442' '046G'\n",
      " '026F' '084A' '038B' '428' '027E' '0027' '037C' '613' '005S' '056A' '262'\n",
      " '015H' '028F' '006R' '004T' '006S' '483' '370' '414' '005R' '341' '024D'\n",
      " '014M' '014O' '056C' '286' '009K' '599' '008H' '345' '036F' '289' '010R'\n",
      " '036K' '366' '056B' '374' '882' '012H' '036G' '299' '049D' '022J' '249'\n",
      " '383' '021J' '014J' '565' '260' '702' '327' '028G' '001Z' '008X' '016N'\n",
      " '049L' '031H']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Lot\n",
    "duplicados = df[df.duplicated(subset=['Lot'], keep=False)]\n",
    "print('Valores duplicados en \"Lot\":')\n",
    "print(duplicados['Lot'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que la columna anterior 'Block', para 'Lot' no se cambió nada ya que no faltaban datos y no hay valores 'NaN', pareciendo estar sus valores correctos. Algunos tienen una letra pero puede llegar a ser parte de su dirección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Street Number\":\n",
      "[1333 1483  431 ... 4183 6237 4848]\n",
      "Cantidad de valores NaN en la columna \"Street Number\": 0\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Street Number\n",
    "valores_unicos = df['Street Number'].unique()\n",
    "print('Valores únicos en \"Street Number\":')\n",
    "print(valores_unicos)\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Street Number'\n",
    "nan_count = df['Street Number'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Street Number\": {nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Street Number\":\n",
      "[1333 1483  431 ... 4623 3868 4511]\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Street Number\n",
    "duplicados = df[df.duplicated(subset=['Street Number'], keep=False)]\n",
    "print('Valores duplicados en \"Street Number\":')\n",
    "print(duplicados['Street Number'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que las columnas anteriores 'Block' y 'Lot', para 'Street Number' no se cambió nada ya que no faltaban datos y no hay valores 'NaN', pareciendo estar sus valores correctos. Además, como se vio anteriormente, el tipo de dato es int64 indicando que no hay letras en esta columna de numero de calle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Street Number Suffix\":\n",
      "[nan 'B' 'A' 'V' 'D' 'K' 'C' 'F' 'H' 'E' 'L' 'J' 'R' 'P' 'I' 'N' 'G' '½'\n",
      " '0']\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Street Number Suffix\n",
    "valores_unicos = df['Street Number Suffix'].unique()\n",
    "print('Valores únicos en \"Street Number Suffix\":')\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Street Number Suffix\":\n",
      "[nan 'B' 'A' 'V' 'D' 'K' 'C' 'F' 'H' 'E' 'L' 'J' 'R' 'P' 'I' 'N' 'G']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Street Number Suffix\n",
    "duplicados = df[df.duplicated(subset=['Street Number Suffix'], keep=False)]\n",
    "print('Valores duplicados en \"Street Number Suffix\":')\n",
    "print(duplicados['Street Number Suffix'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'Street Number Suffix'\n",
    "df.drop('Street Number Suffix', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hay un 98.89 % de datos faltantes del total de filas, se decidió borrar la columna 'Street Number Suffix' ya que no hay manera razonable de ponerle valores y además hay tantos valores faltantes que no aporta valor significativo al analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Street Name\":\n",
      "['jOnEs' '43rD' 'pReNtIsS' ... 'iGnAcIo' 'fErN' 'rIo']\n",
      "Cantidad de valores NaN en la columna \"Street Name\": 0\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Street Name\n",
    "valores_unicos = df['Street Name'].unique()\n",
    "print('Valores únicos en \"Street Name\":')\n",
    "print(valores_unicos)\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Street Name'\n",
    "nan_count = df['Street Name'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Street Name\": {nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Street Name\":\n",
      "['jOnEs' '43rD' 'pReNtIsS' ... 'aVeNuE I' 'cHuLa' 'lOtTiE BeNnEtT']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Street Name\n",
    "duplicados = df[df.duplicated(subset=['Street Name'], keep=False)]\n",
    "print('Valores duplicados en \"Street Name\":')\n",
    "print(duplicados['Street Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Después de la limpieza:\n",
      "Valores únicos en \"Street Name\":\n",
      "['Jones' '43Rd' 'Prentiss' ... 'Ignacio' 'Fern' 'Rio']\n"
     ]
    }
   ],
   "source": [
    "df['Street Name'] = df['Street Name'].str.title()\n",
    "print(\"\\nDespués de la limpieza:\")\n",
    "valores_unicos = df['Street Name'].unique()\n",
    "print('Valores únicos en \"Street Name\":')\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los valores de la columna 'Street Name' se les corrigió la inconsistencia \n",
    "\n",
    "---\n",
    "\n",
    "de variar letras mayusculas y minusculas en cada palabra de los nombres de las calles. Se las puso todos con la primer letra mayúscula. Por otro lado, no tenía datos NaN o datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Street Suffix\":\n",
      "['St' 'Av' 'Bl' nan 'Wy' 'Dr' 'Hy' 'Tr' 'Rd' 'Ct' 'Pl' 'Pk' 'Ln' 'Cr' 'Pz'\n",
      " 'Al' 'No' 'Rw' 'Wk' 'So' 'Hl' 'Sw']\n",
      "Cantidad de valores NaN en la columna \"Street Suffix\": 2768\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Street Suffix\n",
    "valores_unicos = df['Street Suffix'].unique()\n",
    "print('Valores únicos en \"Street Suffix\":')\n",
    "print(valores_unicos)\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Street Suffix'\n",
    "nan_count = df['Street Suffix'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Street Suffix\": {nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en \"Street Suffix\":\n",
      "['St' 'Av' 'Bl' nan 'Wy' 'Dr' 'Hy' 'Tr' 'Rd' 'Ct' 'Pl' 'Pk' 'Ln' 'Cr' 'Pz'\n",
      " 'Al' 'No' 'Rw' 'Wk' 'So' 'Sw']\n"
     ]
    }
   ],
   "source": [
    "# Encontrar y mostrar los valores duplicados en la columna Street Suffix\n",
    "duplicados = df[df.duplicated(subset=['Street Suffix'], keep=False)]\n",
    "print('Valores duplicados en \"Street Suffix\":')\n",
    "print(duplicados['Street Suffix'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Contar frecuencias de cada valor en la columna\n",
    "suffix_counts = df['Street Suffix'].value_counts()\n",
    "\n",
    "# Crear el histograma\n",
    "suffix_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "# Añadir títulos y etiquetas\n",
    "plt.title('Distribución de Sufijos de Calle')\n",
    "plt.xlabel('Sufijo de Calle')\n",
    "plt.ylabel('Número de Ocurrencias')\n",
    "\n",
    "# Mostrar el histograma\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores NaN en la columna \"Street Suffix\": 0\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar los valores NaN en 'Street Suffix' con el valor 'St'\n",
    "df['Street Suffix'] = df['Street Suffix'].fillna('St')\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Street Suffix'\n",
    "nan_count = df['Street Suffix'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Street Suffix\": {nan_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A los valores NaN de 'Street Suffix', que representaban un 1,3% de todos los registros, se le les colocó 'St'. Se dibujó un histograma con la cantidad de veces que aparecía cada uno, y 'St' era significativamente el más predominante. Por lo tanto, al ser pocos valores comparado al total, se asumieron que eran calles (St de Street)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en \"Unit\":\n",
      "[      nan 0.000e+00 5.010e+02 3.000e+00 7.000e+00 2.000e+00 2.160e+02\n",
      " 2.030e+02 2.020e+02 6.000e+00 1.000e+00 1.100e+01 1.300e+01 3.700e+01\n",
      " 5.050e+02 3.210e+02 1.060e+02 4.000e+00 2.370e+02 1.170e+02 3.100e+01\n",
      " 4.230e+02 3.010e+02 1.050e+02 5.100e+01 2.010e+02 1.040e+02 9.180e+02\n",
      " 1.010e+02 1.401e+03 5.000e+00 3.050e+02 7.010e+02 8.010e+02 1.370e+03\n",
      " 7.050e+02 4.070e+02 1.005e+03 3.600e+02 8.300e+02 8.020e+02 2.040e+02\n",
      " 1.632e+03 1.004e+03 2.360e+02 1.020e+02 4.010e+02 5.070e+02 6.180e+02\n",
      " 1.704e+03 1.602e+03 3.020e+02 6.080e+02 4.100e+02 2.130e+02 4.060e+02\n",
      " 2.200e+01 3.830e+02 9.010e+02 6.170e+02 4.090e+02 3.040e+02 4.020e+02\n",
      " 1.700e+03 1.600e+01 3.270e+02 8.000e+00 1.000e+01 1.150e+03 2.090e+02\n",
      " 3.080e+02 1.116e+03 4.180e+02 2.230e+02 1.030e+02 1.007e+03 7.080e+02\n",
      " 1.233e+03 1.404e+03 2.700e+01 9.000e+00 2.501e+03 4.400e+01 6.070e+02\n",
      " 6.400e+02 5.903e+03 8.160e+02 1.408e+03 4.120e+02 1.700e+01 3.170e+02\n",
      " 3.110e+02 3.101e+03 3.030e+02 2.150e+02 1.800e+01 6.020e+02 1.900e+01\n",
      " 6.010e+02 2.500e+02 3.090e+02 3.500e+01 6.040e+02 1.200e+01 2.100e+01\n",
      " 1.402e+03 4.040e+02 6.030e+02 2.060e+02 8.080e+02 3.400e+01 4.080e+02\n",
      " 9.060e+02 4.150e+02 1.400e+01 3.190e+02 1.201e+03 2.300e+01 1.105e+03\n",
      " 3.260e+02 4.300e+01 3.070e+02 1.703e+03 3.600e+01 2.080e+02 7.030e+02\n",
      " 1.110e+02 1.160e+02 2.900e+03 3.300e+01 2.500e+01 5.480e+02 2.270e+02\n",
      " 4.140e+02 2.203e+03 3.390e+02 1.150e+02 8.170e+02 2.240e+02 2.050e+02\n",
      " 2.800e+01 1.372e+03 2.872e+03 7.600e+01 2.180e+02 2.900e+01 5.020e+02\n",
      " 1.305e+03 4.050e+02 1.202e+03 4.700e+01 7.070e+02 1.080e+02 3.150e+02\n",
      " 1.101e+03 4.006e+03 1.370e+02 3.000e+01 1.407e+03 5.040e+02 4.360e+02\n",
      " 1.015e+03 6.100e+01 5.570e+02 4.030e+02 1.100e+02 6.120e+02 1.207e+03\n",
      " 5.340e+02 1.260e+02 1.608e+03 6.520e+02 4.100e+01 3.160e+02 8.040e+02\n",
      " 2.402e+03 1.120e+02 1.415e+03 1.102e+03 5.300e+01 8.070e+02 1.135e+03\n",
      " 6.230e+02 1.302e+03 1.152e+03 3.290e+02 3.312e+03 3.320e+02 5.700e+02\n",
      " 1.501e+03 5.220e+02 4.901e+03 7.000e+01 1.070e+02 9.040e+02 1.103e+03\n",
      " 3.060e+02 3.200e+01 2.000e+02 1.301e+03 3.800e+01 5.030e+02 5.900e+01\n",
      " 1.208e+03 2.210e+02 2.034e+03 3.230e+02 2.604e+03 1.290e+02 9.050e+02\n",
      " 2.070e+02 4.800e+01 5.213e+03 1.050e+03 4.900e+01 4.690e+02 1.500e+01\n",
      " 4.310e+03 3.680e+02 2.502e+03 5.440e+02 5.120e+02 7.170e+02 2.301e+03\n",
      " 4.110e+02 2.000e+01 2.260e+02 8.420e+02 1.106e+03 1.432e+03 1.601e+03\n",
      " 2.110e+02 2.400e+01 3.000e+02 4.260e+02 3.140e+02 9.090e+02 8.460e+02\n",
      " 3.100e+02 2.100e+02 1.702e+03 5.090e+02 5.580e+02 3.705e+03 4.190e+02\n",
      " 1.792e+03 5.080e+02 1.902e+03 3.202e+03 5.150e+02 3.120e+02 8.240e+02\n",
      " 7.020e+02 1.312e+03 2.190e+02 4.620e+02 7.040e+02 5.204e+03 6.060e+02\n",
      " 2.192e+03 1.604e+03 7.900e+01 3.446e+03 1.140e+03 6.220e+02 3.220e+02\n",
      " 8.090e+02 7.100e+02 4.200e+01 6.510e+02 1.180e+02 1.059e+03 1.090e+02\n",
      " 6.300e+02 2.280e+02 3.200e+02 6.160e+02 9.310e+02 2.650e+03 4.520e+02\n",
      " 1.211e+03 1.690e+02 1.441e+03 1.901e+03 1.115e+03 1.214e+03 4.500e+01\n",
      " 1.250e+02 1.204e+03 5.520e+02 5.602e+03 1.108e+03 1.114e+03 1.420e+02\n",
      " 7.150e+02 3.640e+02 1.006e+03 8.060e+02 4.320e+02 6.340e+02 4.510e+02\n",
      " 8.100e+02 2.610e+02 9.900e+01 9.140e+02 2.202e+03 5.590e+02 9.520e+02\n",
      " 5.550e+02 6.560e+02 1.110e+03 9.030e+02 1.130e+02 1.240e+02 4.706e+03\n",
      " 4.130e+02 2.300e+03 9.020e+02 9.100e+02 8.220e+02 2.600e+01 2.601e+03\n",
      " 1.610e+03 1.505e+03 9.470e+02 2.401e+03 2.570e+02 1.001e+03 1.796e+03\n",
      " 7.090e+02 1.024e+03 6.140e+02 6.050e+02 4.720e+02 1.203e+03 1.511e+03\n",
      " 2.201e+03 2.005e+03 7.250e+02 2.003e+03 1.032e+03 5.060e+02 5.306e+03\n",
      " 5.100e+02 1.003e+03 2.888e+03 8.050e+02 3.540e+02 3.350e+02 1.009e+03\n",
      " 1.107e+03 7.060e+02 2.404e+03 5.700e+01 4.600e+01 1.516e+03 1.210e+03\n",
      " 3.180e+02 4.540e+02 1.431e+03 2.140e+03 3.900e+01 6.800e+01 1.717e+03\n",
      " 1.403e+03 1.140e+02 7.260e+02 6.150e+02 5.000e+01 1.503e+03 2.390e+02\n",
      " 3.903e+03 1.418e+03 1.412e+03 3.130e+02 2.204e+03 5.170e+02 2.214e+03\n",
      " 1.607e+03 4.000e+01 2.101e+03 7.210e+02 2.773e+03 8.230e+02 1.904e+03\n",
      " 1.805e+03 8.570e+02 7.130e+02 1.000e+02 4.409e+03 1.104e+03 5.230e+02\n",
      " 5.180e+02 4.570e+02 3.300e+02 5.005e+03 1.002e+03 1.109e+03 1.200e+02\n",
      " 2.001e+03 6.000e+02 2.725e+03 4.200e+02 1.530e+02 1.519e+03 7.500e+01\n",
      " 6.290e+02 5.412e+03 1.220e+02 1.606e+03 1.800e+03 1.025e+03 1.603e+03\n",
      " 1.409e+03 6.100e+02 2.470e+02 5.190e+02 1.303e+03 4.000e+02 1.249e+03\n",
      " 1.701e+03 1.517e+03 2.904e+03 1.014e+03 5.350e+02 9.000e+02 7.110e+02\n",
      " 2.002e+03 1.309e+03 4.160e+02 7.000e+02 9.650e+02 4.310e+02 9.120e+02\n",
      " 3.330e+02 5.600e+01 2.166e+03 6.003e+03 8.400e+02 1.380e+02 1.406e+03\n",
      " 3.250e+02 8.030e+02 1.221e+03 1.502e+03 5.113e+03 2.704e+03 7.520e+02\n",
      " 6.130e+02 4.280e+02 2.109e+03 9.570e+02 4.600e+02 8.520e+02 7.140e+02\n",
      " 2.350e+02 1.514e+03 1.450e+03 3.510e+02 4.340e+02 4.220e+02 8.700e+01\n",
      " 2.290e+02 6.200e+01 7.200e+01 5.110e+02 2.223e+03 3.560e+02 9.210e+02\n",
      " 1.570e+02 8.400e+01 6.490e+02 2.410e+02 1.124e+03 5.130e+02 9.070e+02\n",
      " 3.460e+02 8.100e+01 6.090e+02 1.618e+03 9.420e+02 3.004e+03 5.370e+02\n",
      " 3.240e+02 2.534e+03 6.250e+02 4.210e+03 5.313e+03 1.230e+03 2.140e+02\n",
      " 1.016e+03 3.103e+03 5.000e+02 3.105e+03 1.047e+03 6.110e+02 3.510e+03\n",
      " 1.304e+03 3.256e+03 5.330e+02 6.210e+02 5.500e+01 1.167e+03 6.470e+02\n",
      " 1.504e+03 1.022e+03 1.449e+03 5.206e+03 5.103e+03 4.309e+03 9.220e+02\n",
      " 6.190e+02 2.031e+03 5.160e+02 4.109e+03 2.530e+02 1.605e+03 1.613e+03\n",
      " 1.500e+03 6.000e+01 2.200e+02 2.303e+03 2.317e+03 4.001e+03 2.220e+02\n",
      " 7.690e+02 2.102e+03 2.801e+03 1.308e+03 2.120e+02 6.360e+02 2.803e+03\n",
      " 1.500e+02 4.300e+02 9.080e+02 3.412e+03 4.460e+02 1.424e+03 1.132e+03\n",
      " 5.604e+03 3.370e+02 3.005e+03 1.543e+03 3.704e+03 2.905e+03 1.043e+03\n",
      " 2.221e+03 4.480e+02 2.400e+03 7.360e+02 7.400e+01 4.410e+03 7.200e+02\n",
      " 1.131e+03 1.000e+03 1.480e+02 2.340e+02 1.411e+03 8.750e+02 7.240e+02\n",
      " 8.120e+02 5.530e+02 3.450e+02 1.801e+03 3.280e+02 1.414e+03 7.320e+02\n",
      " 5.112e+03 4.500e+02 2.805e+03 4.240e+02 1.251e+03 9.000e+01 3.440e+02\n",
      " 8.180e+02 9.200e+02 5.560e+02 6.570e+02 5.270e+02 8.320e+02 1.520e+02\n",
      " 3.401e+03 1.580e+02 6.500e+02 1.026e+03 1.112e+03 1.230e+02 2.070e+03\n",
      " 4.410e+02 9.160e+02 3.801e+03 1.212e+03 7.120e+02 2.103e+03 3.360e+02\n",
      " 9.320e+02 7.160e+02 5.400e+01 1.011e+03 4.660e+02 5.413e+03 4.110e+03\n",
      " 6.004e+03 2.526e+03 9.300e+02 3.580e+02 5.140e+02 3.861e+03 1.802e+03\n",
      " 2.170e+02 1.806e+03 9.110e+02 5.312e+03 1.510e+03 1.540e+02 1.508e+03\n",
      " 1.790e+03 8.590e+02 4.730e+02 6.260e+02 1.253e+03 1.270e+02 1.307e+03\n",
      " 7.800e+01 7.570e+02 3.254e+03 4.113e+03 5.200e+02 2.207e+03 1.206e+03\n",
      " 1.300e+02 6.310e+02 5.310e+02 1.317e+03 4.380e+02 7.230e+02 1.410e+02\n",
      " 1.360e+02 5.212e+03 2.800e+02 6.900e+01 4.170e+02 1.310e+03 9.390e+02\n",
      " 1.506e+03 8.000e+02 2.700e+03 2.250e+02 5.106e+03 1.120e+03 3.201e+03\n",
      " 1.808e+03 6.700e+01 8.720e+02 4.209e+03 5.210e+02 4.270e+02 4.004e+03\n",
      " 1.609e+03 1.190e+02 7.370e+02]\n",
      "Cantidad de valores NaN en la columna \"Unit\": 169430\n",
      "Remplazando valores nulos por -1\n",
      "Ahorea la cantidad de valores NaN de la columna \"Unit\" es: 0\n"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos en la columna Unit\n",
    "valores_unicos = df['Unit'].unique()\n",
    "print('Valores únicos en \"Unit\":')\n",
    "print(valores_unicos)\n",
    "\n",
    "# Contar la cantidad de valores NaN en la columna 'Unit'\n",
    "nan_count = df['Unit'].isna().sum()\n",
    "print(f'Cantidad de valores NaN en la columna \"Unit\": {nan_count}')\n",
    "\n",
    "## voy a remplazar los valores nulos por un -1\n",
    "print('Remplazando valores nulos por -1')\n",
    "df['Unit'] = df['Unit'].fillna(-1)\n",
    "\n",
    "nan_count = df['Unit'].isna().sum()\n",
    "print(f'Ahorea la cantidad de valores NaN de la columna \"Unit\" es: {nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'C' \"RESID'L\" 'D' 'E' 'WEST' 'F' 'HOA' 'A' 'UPPER UNIT' 'B' 'H'\n",
      " 'EAST' 'GPHA' '1/F' 'FRONT' 'Garage' 'UPPER' 'LOWER UNIT' 'O' 'N'\n",
      " 'RESDL/REAR' 'CHILD DEV' 'RESIDENTIA' 'REAR UNIT' 'COMMERCIAL' 'BLDG 157'\n",
      " 'RETAIL 1' 'W' 'M301' 'C132' 'J' 'M' 'COMML' 'BLDG 3E' 'OFFICE' '-A'\n",
      " 'COML' 'FRONT BLDG' 'REAR' 'C-2001' 'M202' 'BLDG 1' 'C101' 'LOWER COML'\n",
      " 'FRNT BLDG' 'PH-1' 'P' 'Y' 'LEVEL ONE' '1ST FLOOR' 'TH1' 'C103' 'C1'\n",
      " 'LOWER' 'FRONT UNIT' 'R-1' 'K' 'G' 'C102' 'COMML-3' 'TH2' 'C-1' 'A102'\n",
      " 'S' 'T' 'Commercial' 'COMMON ARE' 'BLDG 229' 'UPPR COMML' 'CU-3' 'I'\n",
      " '1/F FRONT' 'STORE' 'REAR BLDG' 'R' 'BLDG 449' 'OFFICE 2/F' 'B-A'\n",
      " 'COMML 1' 'PH-4' 'M1' 'COM-1' 'BLD 7' '1503B' '-B' 'Parcel B'\n",
      " 'FRNT RIGHT' 'STUDIO/TEC' 'TENTATIVE' 'RESIDENCE' 'PH1A' 'COMML-2' '0'\n",
      " 'BLDG C' 'BLDG 3F' 'M101' 'C-2' \"COM'L\" '1/2' 'C-4' 'D4' 'U' 'RESIDL 3/F'\n",
      " 'LEASE OFF' 'Parcel C' 'L' 'C100' 'PH2B' 'LEAS OFFIC' 'REAR G/F' '407'\n",
      " 'BLDG 201' 'U-PH3' 'BLDG 3' '3/F' 'PH' 'UTILITY' '3RD FLOOR' 'FRNT ENTRA'\n",
      " 'PH C' '3/F FRONT' 'BSM OFFICE' '2/F' 'MIDDLE' 'BLDG. 3' '1A-4' 'COMML-1'\n",
      " 'BASEMENT' 'PH1E' 'BLDG A' 'HMETER' 'PARKING' 'TOP' 'PARCEL A' 'BLDG E'\n",
      " 'UPPER LEVE' 'W122' 'THEATRE' 'CU-2' 'D3' 'COM-2' 'A104' 'BLDG 2'\n",
      " 'BLDG D' 'PH1C' 'FC1' 'CML A' \"RES'L\" 'B20H' 'PIER 3' 'PIER 2' '#R-2'\n",
      " 'BLDG B' 'UP FRT BLD' 'Parcel D' 'Parcel A' \"COM'L 1/F\" 'RETAIL 2'\n",
      " 'LEVEL 4' 'PH1' 'A100' '2ND FLOOR' \"COMM'\" 'PIER 1']\n"
     ]
    }
   ],
   "source": [
    "unit_suffix_values = df['Unit Suffix'].unique()\n",
    "print(unit_suffix_values)\n",
    "\n",
    "# Imprimir la cantidad de datos nulos en Unit Suffix\n",
    "#print(f'Cantidad de valores nulos {df['Unit Suffix'].isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna Unit Suffix\n",
    "df = df.drop(columns=['Unit Suffix'])\n",
    "\n",
    "#Como hay mas de un 99% de datos faltantes del total de filas,\n",
    "#se decidió borrar la columna 'Unit Suffix' ya que no hay manera\n",
    "#razonable de ponerle valores y además hay tantos valores faltantes\n",
    "#que no aporta valor significativo al analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 134273 unique values in the Description column\n",
      "There are 290 missing values in the Description column\n",
      "['street space'\n",
      " 'remodel kitchen: replace countertop, cabinets, sink, stove, hardwood floor & lighting.'\n",
      " 'replacement of 4 windows; 2 located in lightwell and 2 at front. replaceing existing vinyl windows with new wood-clad windows. no horizontal mullion in living room window'\n",
      " ...\n",
      " 'replace rotten wooden moldings in kind front stairs less than 50% replace'\n",
      " 'revision to pa 2016-0926-8773; remove (e) storefront & doors, remove floor, ceiling & wall finishes for new. new storefront, (n) wall & ceiling finishes, (n) flooring with waterproofing in a (n) alcove. mep under pa#201503100377'\n",
      " '16th floor - (4) evacuation plans.']\n",
      "There are 290 missing values in the Description column\n",
      "There are 0 missing values in the Description column\n"
     ]
    }
   ],
   "source": [
    "description_values = df['Description'].unique()\n",
    "print('There are', len(description_values), 'unique values in the Description column')\n",
    "\n",
    "# Faltantes en la columna Description\n",
    "missing_values = df['Description'].isnull().sum()\n",
    "print('There are', missing_values, 'missing values in the Description column')\n",
    "\n",
    "print(description_values)\n",
    "\n",
    "# Faltantes en la columna Description\n",
    "missing_values = df['Description'].isnull().sum()\n",
    "print('There are', missing_values, 'missing values in the Description column')\n",
    "\n",
    "# cambio los nulos por 'no hay descripcion'\n",
    "df['Description'] = df['Description'].fillna('No description')\n",
    "\n",
    "# Faltantes en la columna Description\n",
    "missing_values = df['Description'].isnull().sum()\n",
    "print('There are', missing_values, 'missing values in the Description column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['issued' 'complete' 'filed' 'approved' 'withdrawn' 'reinstated'\n",
      " 'cancelled' 'revoked' 'expired' 'plancheck' 'suspend' 'incomplete'\n",
      " 'disapproved' 'appeal']\n",
      "Cantidad de valores nulos en \"Current Status\": 0\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['Current Status'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "# Valores nulos\n",
    "nan_count = df['Current Status'].isnull().sum()\n",
    "print(f'Cantidad de valores nulos en \"Current Status\": {nan_count}')\n",
    "\n",
    "# parece estar bien, no hay cosas que se refieran a lo mismo pero que esten escritas de manera diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05/23/2017' '08/28/2013' '05/11/2017' ... '03/23/2013' '07/15/2017'\n",
      " '11/02/2014']\n",
      "Current Status Date\n",
      "09/15/2017    474\n",
      "09/14/2017    404\n",
      "06/15/2016    371\n",
      "02/22/2018    364\n",
      "02/23/2018    363\n",
      "             ... \n",
      "03/27/2016      1\n",
      "08/13/2016      1\n",
      "12/25/2014      1\n",
      "07/15/2017      1\n",
      "11/02/2014      1\n",
      "Name: count, Length: 1307, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2094803411.py:10: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Current Status Date'] = pd.to_datetime(df['Current Status Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23/05/2017' '28/08/2013' '11/05/2017' ... '23/03/2013' '15/07/2017'\n",
      " '02/11/2014']\n"
     ]
    }
   ],
   "source": [
    "unique_current_status_dates = df['Current Status Date'].unique()\n",
    "print(unique_current_status_dates)\n",
    "\n",
    "print(df['Current Status Date'].value_counts())\n",
    "\n",
    "#imprimir los faltantes\n",
    "#print(f'Faltantes current ststus date: {df['Current Status Date'].isnull().sum()}')\n",
    "\n",
    "# quiero que el formato sea dd/mm/yyyy\n",
    "df['Current Status Date'] = pd.to_datetime(df['Current Status Date'], dayfirst=True, errors='coerce')\n",
    "df['Current Status Date'] = df['Current Status Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "#imprimir los unicos\n",
    "print(df['Current Status Date'].unique())\n",
    "\n",
    "\n",
    "#no hay valores nulos en la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05/23/2017' '05/31/2013' '05/10/2017' ... '05/02/2013' '02/04/2016'\n",
      " '11/17/2015']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\1020984054.py:8: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Filed Date'] = pd.to_datetime(df['Filed Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23/05/2017' '31/05/2013' '10/05/2017' ... '02/05/2013' '04/02/2016'\n",
      " '17/11/2015']\n"
     ]
    }
   ],
   "source": [
    "unique_filed_dates = df['Filed Date'].unique()\n",
    "print(unique_filed_dates)\n",
    "\n",
    "#imprimir los faltantes\n",
    "#print(f'Faltantes filed date: {df['Filed Date'].isnull().sum()}')\n",
    "\n",
    "# quiero que el formato sea dd/mm/yyyy\n",
    "df['Filed Date'] = pd.to_datetime(df['Filed Date'], dayfirst=True, errors='coerce')\n",
    "df['Filed Date'] = df['Filed Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "unique_filed_dates = df['Filed Date'].unique()\n",
    "print(unique_filed_dates)\n",
    "\n",
    "#no hay valores nulos en la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05/23/2017' '06/03/2013' '05/11/2017' ... '05/24/2016' '06/05/2015'\n",
      " '12/12/2015']\n",
      "Missing values in 'Issued Date' column: 14942\n",
      "Issued Date\n",
      "06/15/2016    341\n",
      "07/26/2016    274\n",
      "12/18/2015    272\n",
      "12/10/2015    234\n",
      "11/07/2017    233\n",
      "             ... \n",
      "12/24/2014     64\n",
      "05/24/2016     63\n",
      "12/26/2014     55\n",
      "12/31/2015     54\n",
      "12/12/2015      2\n",
      "Name: count, Length: 1289, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\1363350698.py:13: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Issued Date'] = pd.to_datetime(df['Issued Date'], dayfirst=True,errors='coerce')\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\1363350698.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Issued Date'].fillna(fecha_minima, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issued Date\n",
      "02/01/2013    15010\n",
      "15/06/2016      341\n",
      "26/07/2016      274\n",
      "18/12/2015      272\n",
      "10/12/2015      234\n",
      "              ...  \n",
      "03/07/2015       64\n",
      "24/05/2016       63\n",
      "26/12/2014       55\n",
      "31/12/2015       54\n",
      "12/12/2015        2\n",
      "Name: count, Length: 1289, dtype: int64\n",
      "Missing values in 'Issued Date' column: 0\n"
     ]
    }
   ],
   "source": [
    "unique_issued_dates = df['Issued Date'].unique()\n",
    "print(unique_issued_dates)\n",
    "\n",
    "# imprimir los valores nulos de la columna 'Issued Date'\n",
    "missing_values = df['Issued Date'].isnull().sum()\n",
    "print(f\"Missing values in 'Issued Date' column: {missing_values}\")\n",
    "\n",
    "#imprimir el count\n",
    "print(df['Issued Date'].value_counts())\n",
    "\n",
    "#voy a llenar los faltantes con la fecha minima\n",
    "\n",
    "df['Issued Date'] = pd.to_datetime(df['Issued Date'], dayfirst=True,errors='coerce')\n",
    "\n",
    "fecha_minima = df['Issued Date'].min()\n",
    "df['Issued Date'].fillna(fecha_minima, inplace=True)\n",
    "\n",
    "df['Issued Date'] = df['Issued Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "#imprimir el count\n",
    "print(df['Issued Date'].value_counts())\n",
    "\n",
    "# imprimir los valores nulos de la columna 'Issued Date'\n",
    "missing_values = df['Issued Date'].isnull().sum()\n",
    "print(f\"Missing values in 'Issued Date' column: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan '08/28/2013' '12/31/2014' ... '01/04/2013' '03/23/2013' '11/02/2014']\n",
      "Missing values in 'Completed Date' column: 101715\n",
      "Completed Date\n",
      "10/30/2015    206\n",
      "01/02/2014    169\n",
      "12/20/2017    162\n",
      "11/26/2013    161\n",
      "10/10/2017    160\n",
      "             ... \n",
      "03/23/2013      3\n",
      "01/04/2013      2\n",
      "01/07/2013      1\n",
      "12/25/2014      1\n",
      "11/02/2014      1\n",
      "Name: count, Length: 1300, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\3689320843.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Completed Date'].fillna('01/01/1900', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Date\n",
      "01/01/1900    101715\n",
      "01/02/2014       169\n",
      "10/10/2017       160\n",
      "12/02/2015       157\n",
      "01/10/2017       148\n",
      "               ...  \n",
      "04/09/2017         3\n",
      "04/02/2016         3\n",
      "01/04/2013         2\n",
      "01/07/2013         1\n",
      "11/02/2014         1\n",
      "Name: count, Length: 514, dtype: int64\n",
      "Missing values in 'Completed Date' column: 59467\n"
     ]
    }
   ],
   "source": [
    "unique_completed_dates = df['Completed Date'].unique()\n",
    "print(unique_completed_dates)\n",
    "\n",
    "# imprimir los valores nulos de la columna 'Completed Date'\n",
    "missing_values = df['Completed Date'].isnull().sum()\n",
    "print(f\"Missing values in 'Completed Date' column: {missing_values}\")\n",
    "\n",
    "#imprimir el count\n",
    "print(df['Completed Date'].value_counts())\n",
    "\n",
    "#voy a llenar los faltantes con '01/01/1900'\n",
    "df['Completed Date'].fillna('01/01/1900', inplace=True)\n",
    "\n",
    "#quiero que el formato sea dd/mm/yyyy\n",
    "df['Completed Date'] = pd.to_datetime(df['Completed Date'], dayfirst=True,errors='coerce')\n",
    "df['Completed Date'] = df['Completed Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "#imprimir el count\n",
    "print(df['Completed Date'].value_counts())\n",
    "\n",
    "# imprimir los valores nulos de la columna 'Completed Date'\n",
    "missing_values = df['Completed Date'].isnull().sum()\n",
    "print(f\"Missing values in 'Completed Date' column: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05/23/2017' '06/03/2013' '05/11/2017' ... '02/04/2016' '05/24/2016'\n",
      " '06/05/2015']\n",
      "Missing values in 'First Construction Document Date' column: 14948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\1802906570.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['First Construction Document Date'].fillna('01/01/1900', inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\1802906570.py:13: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['First Construction Document Date'] = pd.to_datetime(df['First Construction Document Date'], dayfirst=True,errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Construction Document Date\n",
      "01/01/1900    14948\n",
      "07/11/2016      339\n",
      "01/11/2016      254\n",
      "10/12/2015      236\n",
      "07/11/2017      235\n",
      "              ...  \n",
      "03/07/2015       65\n",
      "24/12/2014       62\n",
      "31/12/2015       56\n",
      "26/12/2014       53\n",
      "24/05/2016       42\n",
      "Name: count, Length: 1289, dtype: int64\n",
      "Missing values in 'First Construction Document Date' column: 0\n"
     ]
    }
   ],
   "source": [
    "# imprimir los valores únicos de la columna 'First Construction Document Date'\n",
    "unique_first_construction_dates = df['First Construction Document Date'].unique()\n",
    "print(unique_first_construction_dates)\n",
    "\n",
    "# imprimir los valores nulos de la columna 'First Construction Document Date'\n",
    "missing_values = df['First Construction Document Date'].isnull().sum()\n",
    "print(f\"Missing values in 'First Construction Document Date' column: {missing_values}\")\n",
    "\n",
    "#voy a llenar los faltantes con '01/01/1900'\n",
    "df['First Construction Document Date'].fillna('01/01/1900', inplace=True)\n",
    "\n",
    "#quiero que el formato sea dd/mm/yyyy\n",
    "df['First Construction Document Date'] = pd.to_datetime(df['First Construction Document Date'], dayfirst=True,errors='coerce')\n",
    "df['First Construction Document Date'] = df['First Construction Document Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "#imprimir el count\n",
    "print(df['First Construction Document Date'].value_counts())\n",
    "\n",
    "# imprimir los valores nulos de la columna 'First Construction Document Date'\n",
    "missing_values = df['First Construction Document Date'].isnull().sum()\n",
    "print(f\"Missing values in 'First Construction Document Date' column: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Y']\n",
      "Missing values in 'Structural Notification' column: 191988\n",
      "[False  True]\n",
      "Missing values in 'Structural Notification' column: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2676685458.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Structural Notification'].fillna(False, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2676685458.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Structural Notification'] = df['Structural Notification'].replace('Y', True)\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['Structural Notification'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "# imprimir los valores nulos de la columna 'Structural Notification'\n",
    "missing_values = df['Structural Notification'].isnull().sum()\n",
    "print(f\"Missing values in 'Structural Notification' column: {missing_values}\")\n",
    "\n",
    "# cambiar nulos por False\n",
    "df['Structural Notification'].fillna(False, inplace=True)\n",
    "\n",
    "# cambiar los valores 'Y' por True\n",
    "df['Structural Notification'] = df['Structural Notification'].replace('Y', True)\n",
    "\n",
    "# imprimir los valores unicos de la columna 'Structural Notification'\n",
    "unique_values = df['Structural Notification'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "# imprimir los valores nulos de la columna 'Structural Notification'\n",
    "missing_values = df['Structural Notification'].isnull().sum()\n",
    "print(f\"Missing values in 'Structural Notification' column: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198845\n",
      "Number of Existing Stories\n",
      " 2     52772\n",
      " 3     45741\n",
      "-1     42788\n",
      " 4     16055\n",
      " 1      8794\n",
      "       ...  \n",
      " 47        4\n",
      " 56        4\n",
      " 49        3\n",
      " 62        2\n",
      " 78        1\n",
      "Name: count, Length: 63, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Number of Existing Stories'].fillna(-1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Proposed Stories\n",
      " 2     51877\n",
      " 3     47249\n",
      "-1     39377\n",
      " 4     17890\n",
      " 1      8638\n",
      "       ...  \n",
      " 56       11\n",
      " 47        4\n",
      " 62        4\n",
      " 49        3\n",
      " 78        1\n",
      "Name: count, Length: 63, dtype: int64\n",
      "bool\n",
      "[False  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Voluntary Soft-Story Retrofit'].fillna(False, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fire Only Permit'].fillna(False, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:65: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Permit Expiration Date'] = pd.to_datetime(df['Permit Expiration Date'], dayfirst=True,errors='coerce')\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Permit Expiration Date'].fillna(fecha_maxima, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool\n",
      "[False  True]\n",
      "Fire Only Permit\n",
      "False    180082\n",
      "True      18828\n",
      "Name: count, dtype: int64\n",
      "Permit Expiration Date\n",
      "02/28/2018    302\n",
      "02/24/2018    239\n",
      "05/31/2018    234\n",
      "05/04/2018    228\n",
      "06/21/2018    228\n",
      "             ... \n",
      "10/01/2021      1\n",
      "05/08/2021      1\n",
      "02/25/2019      1\n",
      "04/12/2022      1\n",
      "01/06/2020      1\n",
      "Name: count, Length: 2232, dtype: int64\n",
      "object\n",
      "0\n",
      "datetime64[ns]\n",
      "Permit Expiration Date\n",
      "21/02/2024    51885\n",
      "28/02/2018      302\n",
      "24/02/2018      239\n",
      "31/05/2018      234\n",
      "21/06/2018      228\n",
      "              ...  \n",
      "08/05/2021        1\n",
      "25/02/2019        1\n",
      "12/04/2022        1\n",
      "26/09/2020        1\n",
      "06/01/2020        1\n",
      "Name: count, Length: 2232, dtype: int64\n",
      "38068\n",
      "Estimated Cost\n",
      "1.00         17014\n",
      "10000.00      6695\n",
      "5000.00       6437\n",
      "20000.00      5702\n",
      "15000.00      4779\n",
      "             ...  \n",
      "125095.00        1\n",
      "28126.00         1\n",
      "5966.53          1\n",
      "12440.00         1\n",
      "648405.00        1\n",
      "Name: count, Length: 11395, dtype: int64\n",
      "0\n",
      "Estimated Cost\n",
      "189002.61    55082\n",
      "10000.00      6695\n",
      "5000.00       6437\n",
      "20000.00      5702\n",
      "15000.00      4779\n",
      "             ...  \n",
      "125095.00        1\n",
      "28126.00         1\n",
      "5966.53          1\n",
      "12440.00         1\n",
      "648405.00        1\n",
      "Name: count, Length: 11395, dtype: int64\n",
      "2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:93: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Estimated Cost'].fillna(media, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:96: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Estimated Cost'].replace([0, 1], media, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:120: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Revised Cost'].replace([0, 1], media_revisada, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:125: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Existing Use'].fillna(\"Desconocido\",inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42441\n",
      "Proposed Use\n",
      "1 family dwelling       46348\n",
      "apartments              43035\n",
      "office                  23963\n",
      "2 family dwelling       22062\n",
      "retail sales             5079\n",
      "                        ...  \n",
      "temple                      2\n",
      "dairies/dairy equip.        1\n",
      "orphanage                   1\n",
      "roofing materials           1\n",
      "not applicable              1\n",
      "Name: count, Length: 94, dtype: int64\n",
      "0\n",
      "Proposed Use\n",
      "1 family dwelling       46531\n",
      "apartments              43282\n",
      "Desconocido             38806\n",
      "office                  24524\n",
      "2 family dwelling       22104\n",
      "                        ...  \n",
      "temple                      2\n",
      "dairies/dairy equip.        1\n",
      "orphanage                   1\n",
      "roofing materials           1\n",
      "not applicable              1\n",
      "Name: count, Length: 104, dtype: int64\n",
      "51543\n",
      "Existing Units\n",
      "1.00      47347\n",
      "0.00      29135\n",
      "2.00      21805\n",
      "3.00       8616\n",
      "6.00       6066\n",
      "          ...  \n",
      "550.00        1\n",
      "211.00        1\n",
      "159.00        1\n",
      "289.00        1\n",
      "674.00        1\n",
      "Name: count, Length: 348, dtype: int64\n",
      "0.0\n",
      "50915\n",
      "Proposed Units\n",
      "1.00      46914\n",
      "0.00      26885\n",
      "2.00      22892\n",
      "3.00       9347\n",
      "6.00       5872\n",
      "          ...  \n",
      "213.00        1\n",
      "316.00        1\n",
      "289.00        1\n",
      "504.00        1\n",
      "241.00        1\n",
      "Name: count, Length: 368, dtype: int64\n",
      "Resultado: \n",
      "0\n",
      "Proposed Units\n",
      "1.00      95601\n",
      "0.00      28633\n",
      "2.00      22944\n",
      "3.00       9371\n",
      "6.00       5903\n",
      "          ...  \n",
      "339.00        1\n",
      "211.00        1\n",
      "159.00        1\n",
      "504.00        1\n",
      "241.00        1\n",
      "Name: count, Length: 370, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2228448232.py:163: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Existing Units'].fillna(moda_unidades,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "                          #Number of Existing Stories---------------------------------------------------------------------------------------------------------------------------\n",
    "#Number of Existing Stories float64\n",
    "#Falta Number of Existing Stories 42788\n",
    "\n",
    "# Evaluar datos duplicados\n",
    "duplicados = df['Number of Existing Stories'].duplicated().sum()\n",
    "print(duplicados)\n",
    "\n",
    "#Dado este caso, voy a cambiar los NaN por -1, dado que algunos casos no aplican a la idea de pisos\n",
    "# Sustituir los NaN en 'Number of Existing Stories' por -1\n",
    "df['Number of Existing Stories'].fillna(-1, inplace=True)\n",
    "\n",
    "#por otro lado hay valores decimales, como 2.5, pasaremos a INt\n",
    "df['Number of Existing Stories'] = np.floor(df['Number of Existing Stories']).astype(int)\n",
    "\n",
    "print(df['Number of Existing Stories'].value_counts())\n",
    "\n",
    "                        #'Number of Proposed Stories'------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "df['Number of Proposed Stories'] = df['Number of Proposed Stories'].combine_first(df['Number of Existing Stories'])\n",
    "\n",
    "\n",
    "# Asegurarse de que la columna sea del tipo adecuado (numérico)\n",
    "df['Number of Proposed Stories'] = pd.to_numeric(df['Number of Proposed Stories'], errors='coerce')\n",
    "\n",
    "\n",
    "# Redondear los valores decimales a enteros\n",
    "df['Number of Proposed Stories'] = np.floor(df['Number of Proposed Stories']).astype(int)\n",
    "\n",
    "# Mostrar la frecuencia de los valores\n",
    "print(df['Number of Proposed Stories'].value_counts())\n",
    "\n",
    "#Voluntary Soft-Story Retrofit-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "df['Voluntary Soft-Story Retrofit'].fillna(False, inplace=True)\n",
    "\n",
    "# Paso 3: Reemplazar 'Y' con True y otros valores con False\n",
    "df['Voluntary Soft-Story Retrofit'] = df['Voluntary Soft-Story Retrofit'].apply(lambda x: True if x == 'Y' else False)\n",
    "\n",
    "# Comprobar que los cambios se han realizado correctamente\n",
    "print(df['Voluntary Soft-Story Retrofit'].dtype)  # Debería mostrar dtype('bool')\n",
    "print(df['Voluntary Soft-Story Retrofit'].unique())  # Debería mostrar [True, False]\n",
    "\n",
    "#Fire Only Permit-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "df['Fire Only Permit'].fillna(False, inplace=True)\n",
    "\n",
    "# Paso 3: Reemplazar 'Y' con True y otros valores con False\n",
    "df['Fire Only Permit'] = df['Fire Only Permit'].apply(lambda x: True if x == 'Y' else False)\n",
    "\n",
    "# Comprobar que los cambios se han realizado correctamente\n",
    "print(df['Fire Only Permit'].dtype)  # Debería mostrar dtype('bool')\n",
    "print(df['Fire Only Permit'].unique())  # Debería mostrar [True, False]\n",
    "\n",
    "print(df['Fire Only Permit'].value_counts())\n",
    "\n",
    "#Permit Expiration Date -----------------------------------------------------------------------------------------------------------------------------------\n",
    "print(df['Permit Expiration Date'].value_counts())\n",
    "print(df['Permit Expiration Date'].dtype)\n",
    "df['Permit Expiration Date'] = pd.to_datetime(df['Permit Expiration Date'], dayfirst=True,errors='coerce')\n",
    "\n",
    "#print(df['Permit Expiration Date'].value_counts())\n",
    "\n",
    "fecha_maxima = df['Permit Expiration Date'].max()\n",
    "\n",
    "df['Permit Expiration Date'].fillna(fecha_maxima, inplace=True)\n",
    "\n",
    "print(df['Permit Expiration Date'].isna().sum())\n",
    "print(df['Permit Expiration Date'].dtype)\n",
    "\n",
    "df['Permit Expiration Date'] = df['Permit Expiration Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "print(df['Permit Expiration Date'].value_counts())\n",
    "\n",
    "#Estimated Cost-------------------------------------------------------------------------------\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "#El valor minimo es 1.0\n",
    "print(df['Estimated Cost'].isna().sum())\n",
    "print(df['Estimated Cost'].value_counts())\n",
    "\n",
    "#Aparece que uno de los precios es 1 y 0, es un claro outliers\n",
    "valores_excluir = [1, 0]\n",
    "\n",
    "media = df.loc[~df['Estimated Cost'].isin(valores_excluir), 'Estimated Cost'].mean()\n",
    "\n",
    "\n",
    "df['Estimated Cost'].fillna(media, inplace=True)\n",
    "\n",
    "#Remplazo 0 y 1 con la media\n",
    "df['Estimated Cost'].replace([0, 1], media, inplace=True)\n",
    "\n",
    "print(df['Estimated Cost'].isna().sum())\n",
    "\n",
    "\n",
    "print(df['Estimated Cost'].value_counts())\n",
    "print(df['Estimated Cost'].min())\n",
    "\n",
    "\n",
    "#Revised Cost------------------------------------------------------------------\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Excluir valores específicos antes de calcular la media\n",
    "valores_a_excluir = [1, 0]  # El costo no pueden ser 0 dolares o 1 dolar\n",
    "\n",
    "#Rellenaremos los NaN con los valores iniciales de la columna anterior\n",
    "# Si hay valores NaN en 'Revised Cost', los rellenamos con los valores de 'Estimated Cost'\n",
    "df['Revised Cost'] = df['Revised Cost'].combine_first(df['Estimated Cost'])\n",
    "\n",
    "\n",
    "#Tomo la media sin contar los Outliers como 0 y 1\n",
    "media_revisada = df.loc[~df['Revised Cost'].isin(valores_a_excluir), 'Revised Cost'].mean()\n",
    "\n",
    "#Remplazo 0 y 1 con la media\n",
    "df['Revised Cost'].replace([0, 1], media_revisada, inplace=True)\n",
    "\n",
    "#Existing Use----------------------------------------------------------------------------------\n",
    "\n",
    "#Para los casos en los que no sabemos dado que es NaN, usaremos \"Desconocido\"\n",
    "df['Existing Use'].fillna(\"Desconocido\",inplace=True)\n",
    "\n",
    "#Usando la función Unique(), vemos que casos son claros de errores de escritura\n",
    "#df['Existing Use'] = df['Existing Use'].replace('palabra_antigua', 'palabra_nueva')\n",
    "df['Existing Use'] = df['Existing Use'].replace('nursing home non amb', 'nursing home non-ambulatory')\n",
    "df['Existing Use'] = df['Existing Use'].replace('food/beverage hndlng', 'food/beverage handlng')\n",
    "df['Existing Use'] = df['Existing Use'].replace('filling/service stn', 'filling/service station')\n",
    "df['Existing Use'] = df['Existing Use'].replace('prkng garage/private', 'parking garage/private')\n",
    "df['Existing Use'] = df['Existing Use'].replace('warehouse,no frnitur', 'warehouse,no furniture')\n",
    "\n",
    "df['Existing Use'] = df['Existing Use'].replace('clinics-medic/dental', 'clinics-medical/dental')\n",
    "df['Existing Use'] = df['Existing Use'].replace('misc group residns.', 'miscellaneous group residences')\n",
    "df['Existing Use'] = df['Existing Use'].replace('recreation bldg', 'recreation building')\n",
    "df['Existing Use'] = df['Existing Use'].replace('prkng garage/public', 'parking garage/public')\n",
    "df['Existing Use'] = df['Existing Use'].replace('public assmbly other', 'public assembly other')\n",
    "\n",
    "df['Existing Use'] = df['Existing Use'].replace('phone xchnge/equip', 'phone exchange/equipment')\n",
    "df['Existing Use'] = df['Existing Use'].replace('dairies/dairy equip.', 'dairies/dairy equipment')\n",
    "\n",
    "df['Existing Use'].unique()\n",
    "\n",
    "#Proposed Use--------------------------------------------------------------------------------\n",
    "print(df['Proposed Use'].isna().sum())\n",
    "print(df['Proposed Use'].value_counts())\n",
    "\n",
    "df['Proposed Use'] = df['Proposed Use'].combine_first(df['Existing Use'])\n",
    "\n",
    "print(df['Proposed Use'].isna().sum())\n",
    "print(df['Proposed Use'].value_counts())\n",
    "\n",
    "#Existing Units --------------------------------------------------\n",
    "print(df['Existing Units'].isna().sum())\n",
    "print(df['Existing Units'].value_counts())\n",
    "\n",
    "print(df['Existing Units'].min())\n",
    "\n",
    "moda_unidades = df['Existing Units'].mode()[0]\n",
    "\n",
    "df['Existing Units'].fillna(moda_unidades,inplace=True)\n",
    "\n",
    "#Proposed Units-------------------------------------------------------------\n",
    "print(df['Proposed Units'].isna().sum())\n",
    "print(df['Proposed Units'].value_counts())\n",
    "df['Proposed Units'] = df['Proposed Units'].combine_first(df['Existing Units'])\n",
    "print(\"Resultado: \")\n",
    "print(df['Proposed Units'].isna().sum())\n",
    "print(df['Proposed Units'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Construction Type Description     object\n",
      "Proposed Construction Type                float64\n",
      "Proposed Construction Type Description     object\n",
      "Site Permit                                object\n",
      "Supervisor District                        object\n",
      "Neighborhoods - Analysis Boundaries        object\n",
      "Zipcode                                   float64\n",
      "Location                                   object\n",
      "Record ID                                   int64\n",
      "dtype: object\n",
      "       TIDF Compliance\n",
      "9633                 P\n",
      "153926               Y\n",
      "No duplicate TIDF Compliance found.\n",
      "bool\n",
      "[False  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2556293574.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TIDF Compliance'].fillna(False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar un rango de columnas por índice\n",
    "rango_columnas = df.iloc[:, 32:43]  # El índice 43 es excluyente, por lo que esto selecciona columnas de la 32 a la 42\n",
    "\n",
    "# Encontrar duplicados en el rango de columnas seleccionado\n",
    "#duplicados_rango = rango_columnas[rango_columnas.duplicated()]\n",
    "#print(\"Duplicados en el rango de columnas del índice 32 al 42:\")\n",
    "#print(duplicados_rango)\n",
    "\n",
    "#print(df.dtypes)\n",
    "print(rango_columnas.dtypes)\n",
    "\n",
    "# Find duplicate permit numbers\n",
    "duplicate_TIDF_Compliance = df[df.duplicated(subset='TIDF Compliance', keep=False) & df['TIDF Compliance'].notna()]\n",
    "\n",
    "#HAY MUCHOS VALORES NAN PERO NINGUNO DUPLICADO\n",
    "tidf_null = df[df['TIDF Compliance'].isna()]\n",
    "tidf_not_null = df[df['TIDF Compliance'].notna()]\n",
    "print(tidf_not_null[['TIDF Compliance']])\n",
    "\n",
    "# Print duplicate permit numbers\n",
    "if len(duplicate_TIDF_Compliance) > 0:\n",
    "    print(\"Duplicate TIDF Compliance found:\")\n",
    "    #print(duplicate_TIDF_Compliance[['Record ID', 'Permit Number', 'Street Number', 'Street Name']])\n",
    "\n",
    "\n",
    "# Sort the duplicate permits by record ID\n",
    "#duplicate_TIDF_Compliance = duplicate_TIDF_Compliance.sort_values(by='Record ID')\n",
    "\n",
    "# Print the sorted duplicate permit numbers\n",
    "if len(duplicate_TIDF_Compliance) > 0:\n",
    "    print(\"Sorted duplicate TIDF Compliance found:\")\n",
    "    print(duplicate_TIDF_Compliance[['TIDF Compliance', 'Record ID',]])\n",
    "else:\n",
    "    print(\"No duplicate TIDF Compliance found.\")\n",
    "\n",
    "\n",
    "# SE PROCEDE A RELLENAR LOS NULL QUE SON CASI TODOS CON FALSE, Y SE CAMBIA UNA P A UNA Y; LAS Y SE REEMPLAZAN POR TRUE PARA QUE EL TIPO DE DATO SEA BOOLEAN\n",
    "\n",
    "# Paso 1: Rellenar valores NaN con False\n",
    "df['TIDF Compliance'].fillna(False, inplace=True)\n",
    "\n",
    "# Paso 2: Reemplazar 'P' con 'Y'\n",
    "df['TIDF Compliance'].replace('P', 'Y', inplace=True)\n",
    "\n",
    "# Paso 3: Reemplazar 'Y' con True y otros valores con False\n",
    "df['TIDF Compliance'] = df['TIDF Compliance'].apply(lambda x: True if x == 'Y' else False)\n",
    "\n",
    "# Comprobar que los cambios se han realizado correctamente\n",
    "print(df['TIDF Compliance'].dtype)  # Debería mostrar dtype('bool')\n",
    "print(df['TIDF Compliance'].unique())  # Debería mostrar [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate 'Construction Type' found:\n",
      "        Existing Construction Type      Record ID\n",
      "0                              NaN  1464153232862\n",
      "6                              NaN  1347642247334\n",
      "7                              NaN  1463876236318\n",
      "10                             NaN  1345693499144\n",
      "18                             NaN   139996984337\n",
      "...                            ...            ...\n",
      "198891                         NaN  1292405246910\n",
      "198895                         NaN  1308370472904\n",
      "198896                         NaN   148985877418\n",
      "198901                         NaN  1492023118112\n",
      "198904                         NaN  1407979197645\n",
      "\n",
      "[43369 rows x 2 columns]\n",
      "Duplicate 'Construction Type' found:\n",
      "       Existing Construction Type Description      Record ID\n",
      "0                                         NaN  1464153232862\n",
      "6                                         NaN  1347642247334\n",
      "7                                         NaN  1463876236318\n",
      "10                                        NaN  1345693499144\n",
      "18                                        NaN   139996984337\n",
      "...                                       ...            ...\n",
      "198891                                    NaN  1292405246910\n",
      "198895                                    NaN  1308370472904\n",
      "198896                                    NaN   148985877418\n",
      "198901                                    NaN  1492023118112\n",
      "198904                                    NaN  1407979197645\n",
      "\n",
      "[43370 rows x 2 columns]\n",
      "No records found with null 'Existing Construction Type' and non-null 'Existing Construction Type Description'.\n",
      "Records with null 'Existing Construction Type Description' and non-null 'Existing Construction Type':\n",
      "           Record ID  Existing Construction Type  \\\n",
      "71803  1327175365562                   -99999.00   \n",
      "\n",
      "      Existing Construction Type Description  \n",
      "71803                                    NaN  \n",
      "Valores únicos en 'Existing Construction Type':\n",
      "[        nan  5.0000e+00  3.0000e+00  1.0000e+00  2.0000e+00  4.0000e+00\n",
      " -9.9999e+04  9.9999e+04]\n",
      "\n",
      "Valores únicos en 'Existing Construction Type Description':\n",
      "[nan 'wood frame (5)' 'constr type 3' 'constr type 1' 'constr type 2'\n",
      " 'constr type 4' ' constr type 1 ' ' constr type 3 ' ' wood frame (5) ']\n",
      "79768     wood frame (5)\n",
      "175583    wood frame (5)\n",
      "185291    wood frame (5)\n",
      "Name: Existing Construction Type Description, dtype: object\n",
      "           Record ID  Existing Construction Type  \\\n",
      "71803  1327175365562                       99999   \n",
      "\n",
      "      Existing Construction Type Description  \n",
      "71803                             Wood Frame  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\3926144628.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solo_null_construction_type_des['Existing Construction Type'] = 99999\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\3926144628.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  solo_null_construction_type_des['Existing Construction Type Description'] = 'Wood Frame'\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\3926144628.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Existing Construction Type'].fillna(-1, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\3926144628.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Existing Construction Type Description'].fillna('NON AVAILABLE', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Find null values in the 'Construction Type' column BUSCO LOS NULOS\n",
    "duplicate_construction_type = df[df['Existing Construction Type'].isna()]\n",
    "\n",
    "# Print null 'Construction Type' values\n",
    "if len(duplicate_construction_type) > 0:\n",
    "    print(\"Duplicate 'Construction Type' found:\")\n",
    "    print(duplicate_construction_type[['Existing Construction Type', 'Record ID']])\n",
    "else:\n",
    "    print(\"No duplicate 'Construction Type' found.\")\n",
    "\n",
    "# Find duplicate values in the 'Construction Type exisitng description' column BUSCO LOS NULOS\n",
    "duplicate_construction_type_des = df[df['Existing Construction Type Description'].isna()]\n",
    "\n",
    "# Print duplicate 'Construction Type' values\n",
    "if len(duplicate_construction_type_des) > 0:\n",
    "    print(\"Duplicate 'Construction Type' found:\")\n",
    "    print(duplicate_construction_type_des[['Existing Construction Type Description', 'Record ID']])\n",
    "else:\n",
    "    print(\"No duplicate 'Construction Type' found.\")\n",
    "\n",
    "# BUSCO LOS NULOS EN UNO Y NO EN OTRO: INCOSISTENCIA\n",
    "\n",
    "# Encontrar 'Record ID' con valores nulos solo en 'Existing Construction Type'\n",
    "solo_null_construction_type = df[df['Existing Construction Type'].isna() & df['Existing Construction Type Description'].notna()]\n",
    "\n",
    "# Encontrar 'Record ID' con valores nulos solo en 'Existing Construction Type Description'\n",
    "solo_null_construction_type_des = df[df['Existing Construction Type'].notna() & df['Existing Construction Type Description'].isna()]\n",
    "\n",
    "# Imprimir 'Record ID' con valores nulos solo en 'Existing Construction Type'\n",
    "if len(solo_null_construction_type) > 0:\n",
    "    print(\"Records with null 'Existing Construction Type' and non-null 'Existing Construction Type Description':\")\n",
    "    print(solo_null_construction_type[['Record ID', 'Existing Construction Type', 'Existing Construction Type Description']])\n",
    "else:\n",
    "    print(\"No records found with null 'Existing Construction Type' and non-null 'Existing Construction Type Description'.\")\n",
    "\n",
    "# Imprimir 'Record ID' con valores nulos solo en 'Existing Construction Type Description'\n",
    "if len(solo_null_construction_type_des) > 0:\n",
    "    print(\"Records with null 'Existing Construction Type Description' and non-null 'Existing Construction Type':\")\n",
    "    print(solo_null_construction_type_des[['Record ID', 'Existing Construction Type', 'Existing Construction Type Description']])\n",
    "else:\n",
    "    print(\"No records found with null 'Existing Construction Type Description' and non-null 'Existing Construction Type'.\")\n",
    "\n",
    "\n",
    "# Mostrar valores únicos de la columna 'Existing Construction Type'\n",
    "valores_unicos_tipo = df['Existing Construction Type'].unique()\n",
    "print(\"Valores únicos en 'Existing Construction Type':\")\n",
    "print(valores_unicos_tipo)\n",
    "\n",
    "# Mostrar valores únicos de la columna 'Existing Construction Type Description'\n",
    "valores_unicos_descripcion = df['Existing Construction Type Description'].unique()\n",
    "print(\"\\nValores únicos en 'Existing Construction Type Description':\")\n",
    "print(valores_unicos_descripcion)\n",
    "\n",
    "# Filtrar filas donde 'Existing Construction Type' es igual a 99999\n",
    "filtered_rows = df[df['Existing Construction Type'] == 99999]\n",
    "\n",
    "# Imprimir la columna 'Existing Construction Type Description' de las filas filtradas\n",
    "print(filtered_rows['Existing Construction Type Description'])\n",
    "\n",
    "\n",
    "# HAY TRES FILAS CON 99999 Y TODAS COINCIDEN CON LA DESCRIPCION wood frame; HAY UNA FILA CON -99999 SIN DESCRIPCION, LE CAMBIO EL NUMERO Y PONGO 99999 Y DESCRIPCION WOOD FRAME\n",
    "\n",
    "# Cambiar el valor de 'Existing Construction Type' a 99999\n",
    "solo_null_construction_type_des['Existing Construction Type'] = 99999\n",
    "\n",
    "# Cambiar el valor de 'Existing Construction Type Description' a 'Wood Frame'\n",
    "solo_null_construction_type_des['Existing Construction Type Description'] = 'Wood Frame'\n",
    "\n",
    "# Imprimir las filas modificadas para verificar los cambios\n",
    "print(solo_null_construction_type_des[['Record ID', 'Existing Construction Type', 'Existing Construction Type Description']])\n",
    "\n",
    "\n",
    "# CAMBIO LOS VALORES NAN A -1 EN \"EXISTING CONSTRUCTION TYPE\" Y DESCRIPTION A \"NON AVAIVABLE\"\n",
    "\n",
    "# Cambiar los valores NaN en 'Existing Construction Type' a -1\n",
    "df['Existing Construction Type'].fillna(-1, inplace=True)\n",
    "\n",
    "# Cambiar los valores NaN en 'Existing Construction Type Description' a 'NON AVAILABLE'\n",
    "df['Existing Construction Type Description'].fillna('NON AVAILABLE', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with null 'Proposed Construction Type':\n",
      "        Proposed Construction Type      Record ID\n",
      "0                              NaN  1464153232862\n",
      "6                              NaN  1347642247334\n",
      "7                              NaN  1463876236318\n",
      "16                             NaN  1317862102479\n",
      "18                             NaN   139996984337\n",
      "...                            ...            ...\n",
      "198891                         NaN  1292405246910\n",
      "198895                         NaN  1308370472904\n",
      "198896                         NaN   148985877418\n",
      "198901                         NaN  1492023118112\n",
      "198904                         NaN  1407979197645\n",
      "\n",
      "[43165 rows x 2 columns]\n",
      "Records with null 'Proposed Construction Type Description':\n",
      "       Proposed Construction Type Description      Record ID\n",
      "0                                         NaN  1464153232862\n",
      "6                                         NaN  1347642247334\n",
      "7                                         NaN  1463876236318\n",
      "16                                        NaN  1317862102479\n",
      "18                                        NaN   139996984337\n",
      "...                                       ...            ...\n",
      "198891                                    NaN  1292405246910\n",
      "198895                                    NaN  1308370472904\n",
      "198896                                    NaN   148985877418\n",
      "198901                                    NaN  1492023118112\n",
      "198904                                    NaN  1407979197645\n",
      "\n",
      "[43165 rows x 2 columns]\n",
      "No records found with null 'Proposed Construction Type' and non-null 'Proposed Construction Type Description'.\n",
      "No records found with null 'Proposed Construction Type Description' and non-null 'Proposed Construction Type'.\n",
      "Valores únicos en 'Proposed Construction Type':\n",
      "[nan  5.  3.  2.  1.  4.]\n",
      "\n",
      "Valores únicos en 'Proposed Construction Type Description':\n",
      "[nan 'wood frame (5)' 'constr type 3' 'constr type 2' 'constr type 1'\n",
      " 'constr type 4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\469812242.py:58: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Proposed Construction Type'].fillna(-1, inplace=True)\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\469812242.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Proposed Construction Type Description'].fillna('NON AVAILABLE', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Buscar valores nulos en 'Proposed Construction Type'\n",
    "duplicate_proposed_construction_type = df[df['Proposed Construction Type'].isna()]\n",
    "\n",
    "# Imprimir registros con valores nulos en 'Proposed Construction Type'\n",
    "if len(duplicate_proposed_construction_type) > 0:\n",
    "    print(\"Records with null 'Proposed Construction Type':\")\n",
    "    print(duplicate_proposed_construction_type[['Proposed Construction Type', 'Record ID']])\n",
    "else:\n",
    "    print(\"No records found with null 'Proposed Construction Type'.\")\n",
    "\n",
    "# Buscar valores nulos en 'Proposed Construction Type Description'\n",
    "duplicate_proposed_construction_type_des = df[df['Proposed Construction Type Description'].isna()]\n",
    "\n",
    "# Imprimir registros con valores nulos en 'Proposed Construction Type Description'\n",
    "if len(duplicate_proposed_construction_type_des) > 0:\n",
    "    print(\"Records with null 'Proposed Construction Type Description':\")\n",
    "    print(duplicate_proposed_construction_type_des[['Proposed Construction Type Description', 'Record ID']])\n",
    "else:\n",
    "    print(\"No records found with null 'Proposed Construction Type Description'.\")\n",
    "\n",
    "# Buscar inconsistencias: valores nulos en una columna pero no en la otra\n",
    "\n",
    "# Encontrar 'Record ID' con valores nulos solo en 'Proposed Construction Type'\n",
    "solo_null_proposed_construction_type = df[df['Proposed Construction Type'].isna() & df['Proposed Construction Type Description'].notna()]\n",
    "\n",
    "# Encontrar 'Record ID' con valores nulos solo en 'Proposed Construction Type Description'\n",
    "solo_null_proposed_construction_type_des = df[df['Proposed Construction Type'].notna() & df['Proposed Construction Type Description'].isna()]\n",
    "\n",
    "# Imprimir 'Record ID' con valores nulos solo en 'Proposed Construction Type'\n",
    "if len(solo_null_proposed_construction_type) > 0:\n",
    "    print(\"Records with null 'Proposed Construction Type' and non-null 'Proposed Construction Type Description':\")\n",
    "    print(solo_null_proposed_construction_type[['Record ID', 'Proposed Construction Type', 'Proposed Construction Type Description']])\n",
    "else:\n",
    "    print(\"No records found with null 'Proposed Construction Type' and non-null 'Proposed Construction Type Description'.\")\n",
    "\n",
    "# Imprimir 'Record ID' con valores nulos solo en 'Proposed Construction Type Description'\n",
    "if len(solo_null_proposed_construction_type_des) > 0:\n",
    "    print(\"Records with null 'Proposed Construction Type Description' and non-null 'Proposed Construction Type':\")\n",
    "    print(solo_null_proposed_construction_type_des[['Record ID', 'Proposed Construction Type', 'Proposed Construction Type Description']])\n",
    "else:\n",
    "    print(\"No records found with null 'Proposed Construction Type Description' and non-null 'Proposed Construction Type'.\")\n",
    "\n",
    "\n",
    "# Mostrar valores únicos de la columna 'Existing Construction Type'\n",
    "valores_unicos_tipo_p = df['Proposed Construction Type'].unique()\n",
    "print(\"Valores únicos en 'Proposed Construction Type':\")\n",
    "print(valores_unicos_tipo_p)\n",
    "\n",
    "# Mostrar valores únicos de la columna 'Existing Construction Type Description'\n",
    "valores_unicos_descripcion_p = df['Proposed Construction Type Description'].unique()\n",
    "print(\"\\nValores únicos en 'Proposed Construction Type Description':\")\n",
    "print(valores_unicos_descripcion_p)\n",
    "\n",
    "\n",
    "# CAMBIO LOS VALORES NAN A -1 EN \"EXISTING CONSTRUCTION TYPE\" Y  EN DESCRIPTION A \"NON AVAIVABLE\"\n",
    "\n",
    "# Cambiar los valores NaN en 'Existing Construction Type' a -1\n",
    "df['Proposed Construction Type'].fillna(-1, inplace=True)\n",
    "\n",
    "# Cambiar los valores NaN en 'Existing Construction Type Description' a 'NON AVAILABLE'\n",
    "df['Proposed Construction Type Description'].fillna('NON AVAILABLE', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate 'Site Permit' found:\n",
      "       Site Permit      Record ID\n",
      "10               Y  1345693499144\n",
      "138              Y  1328538204136\n",
      "180              Y  1445840284463\n",
      "200              Y   143211977531\n",
      "218              Y   145562596098\n",
      "...            ...            ...\n",
      "198691           Y  1410062205386\n",
      "198793           Y  1401740453088\n",
      "198814           Y  1412876457991\n",
      "198839           Y  1347093499186\n",
      "198840           Y  1374372490432\n",
      "\n",
      "[5360 rows x 2 columns]\n",
      "Valores únicos en 'Site Permit':\n",
      "[nan 'Y']\n",
      "bool\n",
      "[False  True]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in 'Site Permit'\n",
    "duplicate_site_permit = df[df.duplicated(subset='Site Permit', keep=False) & df['Site Permit'].notna()]\n",
    "\n",
    "# Print duplicate values in 'Site Permit'\n",
    "if len(duplicate_site_permit) > 0:\n",
    "    print(\"Duplicate 'Site Permit' found:\")\n",
    "    print(duplicate_site_permit[['Site Permit', 'Record ID']])\n",
    "else:\n",
    "    print(\"No duplicate 'Site Permit' found.\")\n",
    "\n",
    "valores_unicos_sp=df['Site Permit'].unique()\n",
    "print(\"Valores únicos en 'Site Permit':\")\n",
    "print(valores_unicos_sp)\n",
    "\n",
    "# Reemplazar 'Y' con True y otros valores con False y cambiar a boolean\n",
    "df['Site Permit'] = df['Site Permit'].apply(lambda x: True if x == 'Y' else False)\n",
    "\n",
    "# Comprobar que los cambios se han realizado correctamente\n",
    "print(df['Site Permit'].dtype)  # Debería mostrar dtype('bool')\n",
    "print(df['Site Permit'].unique())  # Debería mostrar [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate 'Supervisor District' found:\n",
      "       Supervisor District      Record ID\n",
      "0                      3.0  1464153232862\n",
      "1                      4.0  1306559115258\n",
      "2                      9.0  1462579187173\n",
      "3                      5.0   136037778128\n",
      "4                      9.0  1322242163712\n",
      "...                    ...            ...\n",
      "198905                7.00  1418495226171\n",
      "198906               10.00  1400885168656\n",
      "198907               10.00  1431897172643\n",
      "198908                3.00  1449660232064\n",
      "198909                6.00  1420790164534\n",
      "\n",
      "[197188 rows x 2 columns]\n",
      "Valores únicos en 'Supervisor District':\n",
      "['3.0' '4.0' '9.0' '5.0' '8.0' '2.0' '6.0' '10.0' '1.0' '7.0' '11.0' nan\n",
      " 'quince' 7.0 5.0 3.0 11.0 4.0 8.0 2.0 9.0 6.0 1.0 10.0 'veinte' 'diez']\n",
      "float64\n",
      "Valores únicos en 'Supervisor District':\n",
      "[ 3.  4.  9.  5.  8.  2.  6. 10.  1.  7. 11. nan 15. 20.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\171004858.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Supervisor District'].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in 'Supervisor District'\n",
    "duplicate_supervisor_district = df[df.duplicated(subset='Supervisor District', keep=False) & df['Supervisor District'].notna()]\n",
    "\n",
    "# Print duplicate values in 'Supervisor District'\n",
    "if len(duplicate_supervisor_district) > 0:\n",
    "    print(\"Duplicate 'Supervisor District' found:\")\n",
    "    print(duplicate_supervisor_district[['Supervisor District', 'Record ID']])\n",
    "else:\n",
    "    print(\"No duplicate 'Supervisor District' found.\")\n",
    "\n",
    "valores_unicos_sd=df['Supervisor District'].unique()\n",
    "print(\"Valores únicos en 'Supervisor District':\")\n",
    "print(valores_unicos_sd)\n",
    "\n",
    "# HAY VALORES QUE SON LOS NUMEROS ESCRITOS, LOS REEMPLAZO POR EL NUMERO\n",
    "\n",
    "# Reemplazar valores de 'Supervisor District' que contienen texto con el número correspondiente, hay numeros que aparecen como texto\n",
    "\n",
    "df['Supervisor District'] = df['Supervisor District'].replace({\"quince\": 15, \"veinte\":20, \"diez\":10})\n",
    "\n",
    "#Cambiar los \"numeros\" a numeros\n",
    "df['Supervisor District'] = pd.to_numeric(df['Supervisor District'], errors='coerce')\n",
    "print(df['Supervisor District'].dtype)\n",
    "\n",
    "valores_unicos_sd=df['Supervisor District'].unique()\n",
    "print(\"Valores únicos en 'Supervisor District':\")\n",
    "print(valores_unicos_sd)\n",
    "\n",
    "# Reemplazar valores nulos en 'Supervisor District' con -1\n",
    "df['Supervisor District'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate 'Neighborhoods - Analysis Boundaries' found:\n",
      "       Neighborhoods - Analysis Boundaries      Record ID\n",
      "0                                 Nob Hill  1464153232862\n",
      "1                          Sunset/Parkside  1306559115258\n",
      "2                           Bernal Heights  1462579187173\n",
      "3                          Pacific Heights   136037778128\n",
      "4                                  Mission  1322242163712\n",
      "...                                    ...            ...\n",
      "198905                           Lakeshore  1418495226171\n",
      "198906                        Potrero Hill  1400885168656\n",
      "198907                             Mission  1431897172643\n",
      "198908                           Chinatown  1449660232064\n",
      "198909      Financial District/South Beach  1420790164534\n",
      "\n",
      "[197185 rows x 2 columns]\n",
      "Valores únicos en 'Neighborhoods - Analysis Boundaries':\n",
      "['Nob Hill' 'Sunset/Parkside' 'Bernal Heights' 'Pacific Heights' 'Mission'\n",
      " 'Castro/Upper Market' 'Financial District/South Beach' 'Chinatown'\n",
      " 'South of Market' 'Inner Richmond' 'Bayview Hunters Point'\n",
      " 'Outer Richmond' 'Marina' 'North Beach' 'Russian Hill' 'Haight Ashbury'\n",
      " 'Presidio Heights' 'Glen Park' 'West of Twin Peaks' 'Excelsior'\n",
      " 'Noe Valley' 'Potrero Hill' 'Twin Peaks' 'Seacliff' 'Hayes Valley'\n",
      " 'Western Addition' 'Outer Mission' 'Inner Sunset'\n",
      " 'Oceanview/Merced/Ingleside' 'Tenderloin' 'Lakeshore' 'Lone Mountain/USF'\n",
      " 'Mission Bay' nan 'Visitacion Valley' 'Portola' 'Japantown'\n",
      " 'McLaren Park' 'Treasure Island' 'Lincoln Park' 'Presidio'\n",
      " 'Golden Gate Park']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\2701242411.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Neighborhoods - Analysis Boundaries'].fillna('NON AVAILABLE', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in 'Neighborhoods - Analysis Boundaries'\n",
    "duplicate_neighborhoods = df[df.duplicated(subset='Neighborhoods - Analysis Boundaries', keep=False) & df['Neighborhoods - Analysis Boundaries'].notna()]\n",
    "\n",
    "# Print duplicate values in 'Neighborhoods - Analysis Boundaries'\n",
    "if len(duplicate_neighborhoods) > 0:\n",
    "    print(\"Duplicate 'Neighborhoods - Analysis Boundaries' found:\")\n",
    "    print(duplicate_neighborhoods[['Neighborhoods - Analysis Boundaries', 'Record ID']])\n",
    "else:\n",
    "    print(\"No duplicate 'Neighborhoods - Analysis Boundaries' found.\")\n",
    "\n",
    "valores_unicos_nb=df['Neighborhoods - Analysis Boundaries'].unique()\n",
    "print(\"Valores únicos en 'Neighborhoods - Analysis Boundaries':\")\n",
    "print(valores_unicos_nb)\n",
    "\n",
    "# Reemplazar valores nulos en 'Neighborhoods - Analysis Boundaries' con 'NON AVAILABLE'\n",
    "\n",
    "df['Neighborhoods - Analysis Boundaries'].fillna('NON AVAILABLE', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate 'Zipcode' found:\n",
      "        Zipcode      Record ID\n",
      "0      94109.00  1464153232862\n",
      "1      94122.00  1306559115258\n",
      "2      94110.00  1462579187173\n",
      "3      94115.00   136037778128\n",
      "4      94110.00  1322242163712\n",
      "...         ...            ...\n",
      "198905 94132.00  1418495226171\n",
      "198906 94107.00  1400885168656\n",
      "198907 94110.00  1431897172643\n",
      "198908 94133.00  1449660232064\n",
      "198909 94105.00  1420790164534\n",
      "\n",
      "[197194 rows x 2 columns]\n",
      "Valores únicos en 'Zipcode':\n",
      "[94109. 94122. 94110. 94115. 94114. 94105. 94111. 94107. 94118. 94124.\n",
      " 94108. 94121. 94123. 94133. 94117. 94131. 94127. 94103. 94132. 94112.\n",
      " 94116. 94102. 94158. 94104.    nan 94134. 94130. 94129.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\21122046.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Zipcode'].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in 'Zipcode'\n",
    "duplicate_zipcode = df[df.duplicated(subset='Zipcode', keep=False) & df['Zipcode'].notna()]\n",
    "\n",
    "# Print duplicate values in 'Zipcode'\n",
    "if len(duplicate_zipcode) > 0:\n",
    "    print(\"Duplicate 'Zipcode' found:\")\n",
    "    print(duplicate_zipcode[['Zipcode', 'Record ID']])\n",
    "else:\n",
    "    print(\"No duplicate 'Zipcode' found.\")\n",
    "\n",
    "valores_unicos_zc=df['Zipcode'].unique()\n",
    "print(\"Valores únicos en 'Zipcode':\")\n",
    "print(valores_unicos_zc)\n",
    "\n",
    "# Reemplazar valores nulos en 'Zipcode' con -1\n",
    "df['Zipcode'].fillna(-1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate 'Record ID' found.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in 'Record ID'\n",
    "duplicate_record_id = df[df.duplicated(subset='Record ID', keep=False) & df['Record ID'].notna()]\n",
    "\n",
    "# Print duplicate values in 'Record ID'\n",
    "if len(duplicate_record_id) > 0:\n",
    "    print(\"Duplicate 'Record ID' found:\")\n",
    "    print(duplicate_record_id[['Record ID']])\n",
    "else:\n",
    "    print(\"No duplicate 'Record ID' found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\1002383263.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Aplicar la función str.strip() a todas las celdas de tipo cadena para borrar los espacios al principio y al final de cada celda\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de filas duplicadas: 10\n"
     ]
    }
   ],
   "source": [
    "# Evaluar datos duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "\n",
    "# Mostrar la cantidad de filas duplicadas\n",
    "print(f'\\nCantidad de filas duplicadas: {duplicados}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fila 435:\n",
      "Permit Number                                                                  201304084005\n",
      "Permit Type                                                                               8\n",
      "Permit Type Definition                                               otc alterations permit\n",
      "Permit Creation Date                                                             08/04/2013\n",
      "Block                                                                                  1674\n",
      "Lot                                                                                     023\n",
      "Street Number                                                                          5528\n",
      "Street Name                                                                          Fulton\n",
      "Street Suffix                                                                            St\n",
      "Unit                                                                                   0.00\n",
      "Description                               kitchen cabinet, install 4 cabinets and counte...\n",
      "Current Status                                                                     complete\n",
      "Current Status Date                                                              26/04/2013\n",
      "Filed Date                                                                       08/04/2013\n",
      "Issued Date                                                                      08/04/2013\n",
      "Completed Date                                                                          NaN\n",
      "First Construction Document Date                                                 08/04/2013\n",
      "Structural Notification                                                               False\n",
      "Number of Existing Stories                                                                3\n",
      "Number of Proposed Stories                                                                3\n",
      "Voluntary Soft-Story Retrofit                                                         False\n",
      "Fire Only Permit                                                                      False\n",
      "Permit Expiration Date                                                           03/04/2014\n",
      "Estimated Cost                                                                      3000.00\n",
      "Revised Cost                                                                        3000.00\n",
      "Existing Use                                                              2 family dwelling\n",
      "Existing Units                                                                         2.00\n",
      "Proposed Use                                                              2 family dwelling\n",
      "Proposed Units                                                                         2.00\n",
      "Plansets                                                                               0.00\n",
      "TIDF Compliance                                                                       False\n",
      "Existing Construction Type                                                             5.00\n",
      "Existing Construction Type Description                                       wood frame (5)\n",
      "Proposed Construction Type                                                             5.00\n",
      "Proposed Construction Type Description                                       wood frame (5)\n",
      "Site Permit                                                                           False\n",
      "Supervisor District                                                                    1.00\n",
      "Neighborhoods - Analysis Boundaries                                          Outer Richmond\n",
      "Zipcode                                                                            94121.00\n",
      "Location                                            (37.77250444463134, -122.4911710150991)\n",
      "Record ID                                                                     1301037450797\n",
      "Name: 435, dtype: object\n",
      "\n",
      "Fila 171464:\n",
      "Permit Number                                                                  201304084005\n",
      "Permit Type                                                                               8\n",
      "Permit Type Definition                                               otc alterations permit\n",
      "Permit Creation Date                                                             08/04/2013\n",
      "Block                                                                                  1674\n",
      "Lot                                                                                     023\n",
      "Street Number                                                                          5528\n",
      "Street Name                                                                          Fulton\n",
      "Street Suffix                                                                            St\n",
      "Unit                                                                                   0.00\n",
      "Description                               kitchen cabinet, install 4 cabinets and counte...\n",
      "Current Status                                                                     complete\n",
      "Current Status Date                                                              26/04/2013\n",
      "Filed Date                                                                       08/04/2013\n",
      "Issued Date                                                                      08/04/2013\n",
      "Completed Date                                                                          NaN\n",
      "First Construction Document Date                                                 08/04/2013\n",
      "Structural Notification                                                               False\n",
      "Number of Existing Stories                                                                3\n",
      "Number of Proposed Stories                                                                3\n",
      "Voluntary Soft-Story Retrofit                                                         False\n",
      "Fire Only Permit                                                                      False\n",
      "Permit Expiration Date                                                           03/04/2014\n",
      "Estimated Cost                                                                      3000.00\n",
      "Revised Cost                                                                        3000.00\n",
      "Existing Use                                                              2 family dwelling\n",
      "Existing Units                                                                         2.00\n",
      "Proposed Use                                                              2 family dwelling\n",
      "Proposed Units                                                                         2.00\n",
      "Plansets                                                                               0.00\n",
      "TIDF Compliance                                                                       False\n",
      "Existing Construction Type                                                             5.00\n",
      "Existing Construction Type Description                                       wood frame (5)\n",
      "Proposed Construction Type                                                             5.00\n",
      "Proposed Construction Type Description                                       wood frame (5)\n",
      "Site Permit                                                                           False\n",
      "Supervisor District                                                                    1.00\n",
      "Neighborhoods - Analysis Boundaries                                          Outer Richmond\n",
      "Zipcode                                                                            94121.00\n",
      "Location                                            (37.77250444463134, -122.4911710150991)\n",
      "Record ID                                                                     1301037450797\n",
      "Name: 171464, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Imprimir la fila 437\n",
    "print(\"Fila 435:\")\n",
    "print(df.iloc[435])\n",
    "\n",
    "# Imprimir la fila 171466\n",
    "print(\"\\nFila 171464:\")\n",
    "print(df.iloc[171464])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas duplicadas basándose en todas las columnas\n",
    "df = df.drop_duplicates(keep='first')\n",
    "\n",
    "# Evaluar datos duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "\n",
    "# Mostrar la cantidad de filas duplicadas\n",
    "print(f'\\nCantidad de filas duplicadas: {duplicados}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Street Number      Unit  Number of Existing Stories  \\\n",
      "count      198900.00 198900.00                   198900.00   \n",
      "mean         1121.73     10.79                        4.26   \n",
      "std          1135.77    129.01                        8.11   \n",
      "min             0.00     -1.00                       -1.00   \n",
      "25%           235.00     -1.00                        1.00   \n",
      "50%           710.00     -1.00                        2.00   \n",
      "75%          1700.00     -1.00                        3.00   \n",
      "max          8400.00   6004.00                       78.00   \n",
      "\n",
      "       Number of Proposed Stories  Estimated Cost  Revised Cost  \\\n",
      "count                   198900.00       198900.00     198900.00   \n",
      "mean                         4.41       188959.41     212972.76   \n",
      "std                          8.17      3264137.42    3651801.05   \n",
      "min                         -1.00            2.00          0.01   \n",
      "25%                          2.00         8000.00       9000.00   \n",
      "50%                          2.00        30000.00      38687.00   \n",
      "75%                          4.00       189002.61     213015.05   \n",
      "max                         78.00    537958646.00  780500000.00   \n",
      "\n",
      "       Existing Units  Proposed Units  \n",
      "count       198900.00       198900.00  \n",
      "mean            11.87           12.82  \n",
      "std             64.43           66.27  \n",
      "min              0.00            0.00  \n",
      "25%              1.00            1.00  \n",
      "50%              1.00            1.00  \n",
      "75%              2.00            3.00  \n",
      "max           1907.00         1911.00  \n",
      "  Permit Number  Permit Type  Permit Type Definition Permit Creation Date  \\\n",
      "0       M788927            8  otc alterations permit           23/05/2017   \n",
      "1  201305318356            8  otc alterations permit           31/05/2013   \n",
      "2  201705106205            8  otc alterations permit           10/05/2017   \n",
      "3  201410279983            8  otc alterations permit           27/10/2014   \n",
      "4  201310280388            8  otc alterations permit           28/10/2013   \n",
      "\n",
      "  Block   Lot  Street Number Street Name Street Suffix  Unit  ...  \\\n",
      "0  0215   001           0.16       Jones            St  0.00  ...   \n",
      "1  1810  017A           0.18        43Rd            Av  0.00  ...   \n",
      "2  5700   027           0.05    Prentiss            St  0.00  ...   \n",
      "3  0661   005           0.24        Bush            St  0.00  ...   \n",
      "4  3642  051A           0.10        Capp            St  0.00  ...   \n",
      "\n",
      "  Existing Construction Type Existing Construction Type Description  \\\n",
      "0                      -1.00                          NON AVAILABLE   \n",
      "1                       5.00                         wood frame (5)   \n",
      "2                       5.00                         wood frame (5)   \n",
      "3                       5.00                         wood frame (5)   \n",
      "4                       5.00                         wood frame (5)   \n",
      "\n",
      "  Proposed Construction Type Proposed Construction Type Description  \\\n",
      "0                      -1.00                          NON AVAILABLE   \n",
      "1                       5.00                         wood frame (5)   \n",
      "2                       5.00                         wood frame (5)   \n",
      "3                       5.00                         wood frame (5)   \n",
      "4                       5.00                         wood frame (5)   \n",
      "\n",
      "  Site Permit Supervisor District Neighborhoods - Analysis Boundaries  \\\n",
      "0       False                3.00                            Nob Hill   \n",
      "1       False                4.00                     Sunset/Parkside   \n",
      "2       False                9.00                      Bernal Heights   \n",
      "3       False                5.00                     Pacific Heights   \n",
      "4       False                9.00                             Mission   \n",
      "\n",
      "   Zipcode                                   Location      Record ID  \n",
      "0 94109.00   (37.79362102799777, -122.41488237355445)  1464153232862  \n",
      "1 94122.00  (37.759041020475465, -122.50286985467523)  1306559115258  \n",
      "2 94110.00   (37.73778863007536, -122.41197863877355)  1462579187173  \n",
      "3 94115.00   (37.78762264983362, -122.43099126735969)   136037778128  \n",
      "4 94110.00   (37.75275550565926, -122.41707462095194)  1322242163712  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Seleccionar las columnas numéricas del DataFrame\n",
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Definir las columnas que quedan dentro de las discretas y continuas que no deben ser normalizadas\n",
    "columns_to_exclude = ['Zipcode', 'Record ID']\n",
    "\n",
    "# Asegurarse de que las columnas a excluir están presentes en el DataFrame\n",
    "columns_to_exclude = [col for col in columns_to_exclude if col in numeric_columns]\n",
    "\n",
    "# Distinguir entre discretas y continuas, excluyendo las columnas especificadas\n",
    "threshold = 20\n",
    "continuous_columns = [col for col in numeric_columns if col not in columns_to_exclude and df[col].nunique() > threshold]\n",
    "\n",
    "# Validación manual\n",
    "print(df[continuous_columns].describe())\n",
    "\n",
    "# Crear un objeto MinMaxScaler para normalizar los datos entre 0 y 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar la normalización a las columnas continuas numéricas\n",
    "df[continuous_columns] = scaler.fit_transform(df[continuous_columns])\n",
    "\n",
    "# Verificar las primeras filas después de la normalización\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Summarize dataset: 100%|██████████████████████████████████████████████████| 276/276 [02:45<00:00,  1.67it/s, Completed]\n",
      "Generate report structure: 100%|█████████████████████████████████████████████████████████| 1/1 [00:44<00:00, 44.35s/it]\n",
      "Render HTML: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.81s/it]\n",
      "Export report to file: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.14it/s]\n",
      "C:\\Users\\P\\AppData\\Local\\Temp\\ipykernel_15856\\1522364813.py:13: DtypeWarning: Columns (22,32,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfOriginal = pd.read_csv('permisos_construccion.csv')\n",
      "Summarize dataset: 100%|██████████████████████████████████████████████████| 222/222 [02:42<00:00,  1.37it/s, Completed]\n",
      "Generate report structure: 100%|█████████████████████████████████████████████████████████| 1/1 [00:47<00:00, 47.34s/it]\n",
      "Render HTML: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.90s/it]\n",
      "Export report to file: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Se instala librería\n",
    "#!pip install ydata_profiling\n",
    "# Importaciones\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Se ejecuta reporte\n",
    "profile = ProfileReport(df, title=\"Reporte del Analisis\", explorative=True)\n",
    "# Se guarda reporte como html\n",
    "profile.to_file(output_file=\"ProfilingDatasetNuevo_html.html\")\n",
    "\n",
    "# Se lee el csv original\n",
    "dfOriginal = pd.read_csv('permisos_construccion.csv')\n",
    "# Se ejecuta reporte\n",
    "profile = ProfileReport(dfOriginal, title=\"Reporte de Datos Originales\", explorative=True)\n",
    "# Se guarda reporte como html\n",
    "profile.to_file(output_file=\"ProfilingDatasetOriginal_html.html\")\n",
    "# Se guarda reporte como json\n",
    "#profile.to_file(output_file=\"ProfilingDatasetOriginal_json.json”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
